{"seed:1": {"lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-quarel_do_not_use": [0.015646494229634603, 0.015646022160847983, 0.015644335746765138, 0.015641420682271322, 0.01563724676767985, 0.015631785392761232, 0.015624987284342447, 0.015616809527079265, 0.015607207616170248, 0.015596151351928711, 0.015583588282267252, 0.015569486618041993, 0.015553805033365885, 0.015536511739095052, 0.015517551104227702, 0.015496838887532552, 0.015474438667297363, 0.015450263023376464, 0.015424017906188964, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.01593544324239095, 0.015908042589823406, 0.015880502065022787, 0.01585280100504557, 0.015824923515319823, 0.015796823501586912, 0.01576846917470296, 0.015739811261494954, 0.01571082274119059, 0.015681495666503908, 0.015651777585347495, 0.015621593793233236, 0.015590850512186687, 0.015559624036153158, 0.015527990659077963, 0.015495994885762532, 0.01546348253885905, 0.01543001651763916, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.01615682601928711, 0.016114803949991863, 0.016073214213053386, 0.016031869252522788, 0.015990363756815593, 0.015949773788452148, 0.015909992853800455, 0.01587021032969157, 0.015830278396606445, 0.015789934794108073, 0.015748826662699382, 0.01570703347524007, 0.015664841334025067, 0.015622062683105469, 0.015578471819559733, 0.015534124374389648, 0.015489060084025065, 0.015442973772684733, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-wiki_qa_found_on_google": [0.01600154399871826, 0.015984999338785808, 0.015967032114664714, 0.01594759782155355, 0.01592666467030843, 0.01590419133504232, 0.015880149205525718, 0.01585447311401367, 0.015827109018961588, 0.015798004468282063, 0.01576711654663086, 0.015734429359436034, 0.015699896812438965, 0.01566340128580729, 0.015624740918477376, 0.015583826700846353, 0.015540564854939778, 0.01549484411875407, 0.015446491241455078, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-glue_wnli": [0.015789286295572916, 0.015773940086364745, 0.01575821081797282, 0.015742058753967284, 0.01572550137837728, 0.015708535512288412, 0.015691148440043132, 0.015673294067382812, 0.01565484364827474, 0.015635660489400228, 0.015615639686584472, 0.015594720840454102, 0.01557289441426595, 0.015550211270650227, 0.015526776313781738, 0.01550267219543457, 0.015477693875630697, 0.01545178254445394, 0.015424405733744304, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question": [0.015930237770080565, 0.01589499632517497, 0.015861639976501463, 0.015829580624898275, 0.015798554420471192, 0.01576849937438965, 0.015739474296569824, 0.015711766878763835, 0.01568471590677897, 0.01565808614095052, 0.015631988843282065, 0.01560611883799235, 0.015580201148986816, 0.015554122924804688, 0.015528001785278321, 0.015502041180928548, 0.015476109186808269, 0.015449984868367513, 0.01542320728302002, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is": [0.01607226371765137, 0.01604137897491455, 0.0160102113087972, 0.015978735287984214, 0.015946930249532063, 0.015914754867553713, 0.015882158279418947, 0.015849086443583172, 0.01581549644470215, 0.015781351725260417, 0.01574659506479899, 0.015711181958516438, 0.015675021807352703, 0.015638003349304198, 0.015600058237711588, 0.015561223030090332, 0.015521500905354818, 0.015480810801188152, 0.015438865025838217, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-wiki_bio_comprehension": [0.01610628922780355, 0.01606233596801758, 0.016019605000813803, 0.01597781976064046, 0.01593702793121338, 0.015897499720255535, 0.015858592987060546, 0.015820449193318684, 0.01578332742055257, 0.01574712912241618, 0.015711417198181154, 0.015675889650980632, 0.01564067045847575, 0.01560582955678304, 0.015571142832438151, 0.015536465644836427, 0.015501699447631835, 0.015466701189676921, 0.015431291262308756, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015834670066833496, 0.015823766390482583, 0.01581147034962972, 0.015797727902730305, 0.015782504081726073, 0.015765744845072427, 0.01574741840362549, 0.015727481842041015, 0.015705893834431967, 0.015682616233825684, 0.01565759499867757, 0.015630807876586914, 0.015602329572041829, 0.015572250684102376, 0.01554051399230957, 0.015507109959920247, 0.015471908251444498, 0.01543470541636149, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.016043806076049806, 0.01600840250651042, 0.015972941716512045, 0.015937871932983398, 0.015902722676595052, 0.01586736520131429, 0.015831824938456217, 0.01579630215962728, 0.01576123555501302, 0.01572572390238444, 0.01569009304046631, 0.0156546417872111, 0.015619187355041505, 0.015583132108052572, 0.015546385447184246, 0.015509215990702312, 0.015471854209899903, 0.015433886845906575, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015345781644185385, 0.015364305178324381, 0.015381189982096354, 0.015396405855814616, 0.015409919420878092, 0.015421708424886068, 0.015431734720865885, 0.015439955393473308, 0.015446317990620932, 0.015450739860534668, 0.0154531462987264, 0.015453486442565919, 0.015451744397481282, 0.01544792652130127, 0.015442020098368326, 0.015433972676595051, 0.01542365074157715, 0.015410831769307454, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.016274356842041017, 0.01622467041015625, 0.016175251007080078, 0.016126068433125813, 0.016077103614807128, 0.016028329531351724, 0.0159797207514445, 0.015931251843770346, 0.015882903734842937, 0.01583465576171875, 0.015786503156026203, 0.015738404591878256, 0.01569027582804362, 0.015642011960347493, 0.015593549410502117, 0.015544788042704264, 0.01549560546875, 0.015445828437805176, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.01577031930287679, 0.015760998725891113, 0.015750557581583658, 0.0157389497756958, 0.015726149876912433, 0.015712103843688964, 0.015696791013081867, 0.015680152575174966, 0.015662155151367187, 0.015642743110656738, 0.015621856053670247, 0.015599400202433267, 0.015575348536173502, 0.015549750328063964, 0.01552254358927409, 0.015493698120117187, 0.015463069279988606, 0.015430369377136231, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.0156476895014445, 0.015643704732259116, 0.015638596216837566, 0.015632718404134115, 0.015625980695088703, 0.01561779022216797, 0.015609029134114584, 0.015599093437194823, 0.015587975184122721, 0.015576022466023763, 0.015562758445739747, 0.015547731717427571, 0.015530939102172852, 0.015512588818868002, 0.015492798487345378, 0.015471455256144205, 0.015448230107625326, 0.015422856012980143, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015640063285827635, 0.01563132127126058, 0.015622342427571614, 0.015613042513529459, 0.015603310267130533, 0.015593042373657226, 0.015582413673400878, 0.015571619669596354, 0.015559906959533692, 0.015547266006469726, 0.015533959070841472, 0.015520054499308268, 0.015505393346150717, 0.015489657719930014, 0.015472962061564127, 0.015455334981282553, 0.01543680508931478, 0.015416997273763021, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015942139625549315, 0.015975648562113445, 0.01598936875661214, 0.01598677635192871, 0.015973337491353354, 0.01595008373260498, 0.015919879277547202, 0.015885864893595378, 0.015847220420837402, 0.015806633631388345, 0.015765700340270996, 0.015721041361490884, 0.01567519982655843, 0.015628623962402343, 0.015581410725911458, 0.015534977912902832, 0.015488670667012533, 0.015442129770914713, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017791476249694824, 0.017556203206380207, 0.017339027722676596, 0.01713709831237793, 0.016947549184163413, 0.01677027384440104, 0.01660627524058024, 0.01645288308461507, 0.01631012757619222, 0.016179018020629883, 0.016057202021280925, 0.01594538688659668, 0.01584317684173584, 0.015749046007792155, 0.015663272539774578, 0.015585513114929199, 0.015515317916870117, 0.015451998710632324, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016006078720092774, 0.015951833724975585, 0.015897355079650878, 0.01584400494893392, 0.015793388684590657, 0.015745237668355307, 0.015702762603759766, 0.01566578229268392, 0.01563033739725749, 0.015599180857340494, 0.015570915540059408, 0.015544662475585938, 0.015521151224772135, 0.015499318440755208, 0.015478432973225912, 0.01545804500579834, 0.015437819163004558, 0.015416913032531739, 0.015395296414693197], "lorahub/flan_t5_large-wiqa_what_is_the_final_step_of_the_following_process+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014869823455810546, 0.014923764864603678, 0.014975261688232423, 0.015024177233378093, 0.015070400238037109, 0.015113851229349773, 0.015154452323913574, 0.01519210974375407, 0.015226750373840333, 0.015258297920227051, 0.015286699930826823, 0.015311943689982095, 0.015334024429321289, 0.01535288174947103, 0.015368336041768392, 0.015380341211954753, 0.015388855934143067, 0.015393848419189454, 0.015395296414693197], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015937633514404297, 0.015913529396057127, 0.015890405972798664, 0.0158682648340861, 0.015847105979919434, 0.015826929410298667, 0.015807716051737468, 0.01578945795694987, 0.015772137641906738, 0.01575574239095052, 0.01574024200439453, 0.01572562535603841, 0.015711863835652668, 0.015698949495951336, 0.015686861673990884, 0.01567558288574219, 0.015665106773376465, 0.015655411084493, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.016153321266174317, 0.01610954761505127, 0.01606788158416748, 0.01602754751841227, 0.015989754994710285, 0.015955184300740558, 0.015922576586405435, 0.01589116096496582, 0.01586125691731771, 0.015832982063293456, 0.015806271235148113, 0.01578120549519857, 0.015757673581441242, 0.0157355801264445, 0.01571486473083496, 0.015695549647013345, 0.015677701632181802, 0.015661349296569826, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-wiki_qa_found_on_google": [0.01600154399871826, 0.015980319976806642, 0.01595961252848307, 0.015939385096232096, 0.015919580459594726, 0.015900135040283203, 0.01588099479675293, 0.015862131118774415, 0.015843523343404133, 0.01582514444986979, 0.015806973775227863, 0.015788976351420084, 0.01577112833658854, 0.015753382047017414, 0.01573568820953369, 0.015718003908793132, 0.015700276692708334, 0.015682470003763833, 0.01566454569498698, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-glue_wnli": [0.015789286295572916, 0.01578201134999593, 0.01577471892038981, 0.015767455101013184, 0.015760231018066406, 0.01575305938720703, 0.015745902061462404, 0.01573871453603109, 0.015731452306111653, 0.015724085172017416, 0.01571660836537679, 0.015709037780761718, 0.01570139726003011, 0.015693694750467935, 0.015685938199361166, 0.01567813555399577, 0.015670289993286134, 0.01566240151723226, 0.01565447012583415, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question": [0.015930237770080565, 0.015905427932739257, 0.015882673263549803, 0.015861403147379556, 0.015841379165649414, 0.01582260608673096, 0.015805042584737142, 0.015788877805074056, 0.015774056116739908, 0.01576015790303548, 0.015746928850809732, 0.015734278361002604, 0.0157220983505249, 0.015710315704345702, 0.015698914527893067, 0.015687878926595053, 0.015677175521850585, 0.01566674550374349, 0.015656534830729166, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is": [0.01607226371765137, 0.0160387388865153, 0.01600644111633301, 0.01597537358601888, 0.01594554583231608, 0.01591696898142497, 0.015889641443888346, 0.015863553682963053, 0.015838705698649088, 0.01581509272257487, 0.015792705217997232, 0.015771551132202147, 0.015751617749532064, 0.015732913017272948, 0.015715436935424806, 0.015699186325073243, 0.01568416436513265, 0.015670374234517417, 0.015657820701599122, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-wiki_bio_comprehension": [0.01610628922780355, 0.01606736660003662, 0.016030314763387045, 0.01599540710449219, 0.015962106386820475, 0.01593056042989095, 0.015900940895080568, 0.01587316672007243, 0.01584699471791585, 0.015822359720865885, 0.015799347559611, 0.015777859687805176, 0.015757652918497723, 0.015738622347513834, 0.01572074254353841, 0.015703975359598797, 0.01568822383880615, 0.015673433939615886, 0.01565954049428304, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.01583678404490153, 0.01582901954650879, 0.015820927619934082, 0.015812498728434245, 0.0158037265141805, 0.015794604619344076, 0.015785120328267416, 0.015775284767150878, 0.015765093167622885, 0.015754550298055014, 0.01574366251627604, 0.015732447306315105, 0.01572091579437256, 0.015709088643391926, 0.015696991284688315, 0.015684647560119627, 0.015672098795572915, 0.015659367243448893, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.016044333775838217, 0.01601071039835612, 0.015978380839029947, 0.015947982470194497, 0.015918978055318198, 0.015891071955362955, 0.015864284833272298, 0.015838597615559894, 0.015814359982808432, 0.01579193592071533, 0.01577100435892741, 0.0157514746983846, 0.015733176867167156, 0.015715896288553875, 0.015699717203776043, 0.01568471113840739, 0.015670852661132814, 0.01565812587738037, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015351678530375163, 0.015376747449239095, 0.015400869051615397, 0.015424022674560547, 0.015446176528930664, 0.015467316309611002, 0.015487424532572429, 0.015506490071614584, 0.015524503389994303, 0.015541466077168782, 0.015557374954223633, 0.015572226842244467, 0.015586013793945313, 0.01559874693552653, 0.01561042308807373, 0.015621037483215331, 0.01563058853149414, 0.015639074643452964, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.016274658838907878, 0.01622664451599121, 0.016180149714152017, 0.01613508701324463, 0.016091429392496744, 0.016049256324768068, 0.016008636156717937, 0.015969635645548503, 0.01593226909637451, 0.015896541277567545, 0.01586243470509847, 0.01582992394765218, 0.01579898675282796, 0.015769627888997394, 0.015741834640502928, 0.01571562131245931, 0.015690987904866536, 0.015667945543924967, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.015774086316426596, 0.015769387880961102, 0.015764430363972983, 0.01575921058654785, 0.01575371265411377, 0.015747942924499513, 0.015741893450419108, 0.01573556423187256, 0.01572894096374512, 0.015722028414408364, 0.01571482022603353, 0.015707319577534993, 0.0156995153427124, 0.01569141705830892, 0.01568301518758138, 0.015674324035644532, 0.015665337244669595, 0.015656059583028157, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.015651774406433106, 0.01565247376759847, 0.015652875900268554, 0.015653322537740072, 0.015654226938883464, 0.015654567082722982, 0.015654837290445964, 0.01565550168355306, 0.01565630594889323, 0.015656905174255373, 0.015657172203063965, 0.015657068888346354, 0.015656647682189943, 0.015655922889709472, 0.01565485954284668, 0.015653400421142577, 0.015651535987854005, 0.015649237632751466, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.01565070152282715, 0.015652570724487305, 0.015654207865397136, 0.015655582745869954, 0.015656636555989582, 0.015657399495442707, 0.01565817991892497, 0.015659082730611167, 0.015659809112548828, 0.01566027641296387, 0.0156604274113973, 0.015660133361816406, 0.01565934658050537, 0.015658135414123534, 0.015656542778015137, 0.015654592514038085, 0.015652273495992023, 0.015649579366048178, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015940475463867187, 0.015973642667134604, 0.015988547007242837, 0.015988683700561522, 0.015980884234110513, 0.015963376363118488, 0.015940925280253093, 0.015915594100952148, 0.0158876101175944, 0.015860772132873534, 0.015833261807759604, 0.01580509662628174, 0.015777535438537597, 0.015752334594726563, 0.01572839419047038, 0.015705509185791014, 0.01568416436513265, 0.0156645139058431, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01778916835784912, 0.01755331039428711, 0.01733604590098063, 0.017136090596516926, 0.01694987932840983, 0.016777404149373374, 0.01661965052286784, 0.016475640932718912, 0.016343971888224285, 0.016224600474039712, 0.016118038495381674, 0.01602291425069173, 0.015939380327860516, 0.015866382916768392, 0.015803219477335612, 0.015749878883361816, 0.015706133842468262, 0.015671742757161457, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01602502663930257, 0.015987250010172527, 0.015947372118631998, 0.01590721289316813, 0.015868876775105793, 0.01583186149597168, 0.01580120881398519, 0.01577291011810303, 0.015750590960184732, 0.015730204582214354, 0.01571379820505778, 0.015699906349182127, 0.015688551266988118, 0.01567867596944173, 0.015671771367390952, 0.01566532293955485, 0.015658912658691407, 0.0156527042388916, 0.015646494229634603], "lorahub/flan_t5_large-quarel_do_not_use+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014891738891601563, 0.014966532389322917, 0.015037714640299479, 0.015105168024698893, 0.01516895612080892, 0.015229102770487467, 0.01528550148010254, 0.015337977409362793, 0.015386382738749186, 0.015430647532145183, 0.015470797220865886, 0.01550689697265625, 0.015539000829060873, 0.015567110379536947, 0.015591195424397786, 0.01561119556427002, 0.015627085367838543, 0.015638852119445802, 0.015646494229634603], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.01615817705790202, 0.016120638847351074, 0.01608622392018636, 0.016054360071818034, 0.016027164459228516, 0.016004058519999188, 0.015983802477518717, 0.015966442426045734, 0.015951919555664062, 0.01594016710917155, 0.01593139171600342, 0.015925402641296386, 0.015922064781188964, 0.015921470324198404, 0.015923787752787272, 0.01592908223470052, 0.015937341054280598, 0.01594855308532715, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-wiki_qa_found_on_google": [0.01600154399871826, 0.015984875361124674, 0.015969929695129396, 0.015956756273905436, 0.015945278803507486, 0.015935409863789878, 0.01592711607615153, 0.0159203831354777, 0.015915228525797527, 0.015911655426025392, 0.015909679730733237, 0.015909307797749836, 0.015910533269246418, 0.015913346608479817, 0.01591774304707845, 0.01592368761698405, 0.015931161244710286, 0.015940152804056803, 0.015950663884480795, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-glue_wnli": [0.015789286295572916, 0.015788154602050783, 0.015788006782531738, 0.0157888666788737, 0.01579076925913493, 0.015793752670288087, 0.0157978359858195, 0.015803050994873048, 0.01580942153930664, 0.01581696669260661, 0.01582572301228841, 0.01583570162455241, 0.015846935907999675, 0.01585945765177409, 0.015873289108276366, 0.01588846206665039, 0.015904990832010905, 0.015922878583272296, 0.015942123730977375, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question": [0.015930237770080565, 0.015912102063496907, 0.015896956125895183, 0.015884615580240884, 0.01587455113728841, 0.01586685021718343, 0.01586140473683675, 0.015858117739359537, 0.01585697333017985, 0.015857990582784018, 0.01586108684539795, 0.01586604913075765, 0.01587270736694336, 0.015881001154581707, 0.01589088757832845, 0.015902339617411297, 0.015915306409200032, 0.015929730733235677, 0.015945547421773273, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is": [0.01607226371765137, 0.016051462491353353, 0.016032301584879557, 0.01601481596628825, 0.015998997688293458, 0.015984827677408855, 0.01597227732340495, 0.01596134344736735, 0.015952037175496418, 0.01594438076019287, 0.015938404401143393, 0.01593413511912028, 0.015931588808695475, 0.01593079725901286, 0.015931766827901206, 0.015934489568074545, 0.015938967068990072, 0.01594517389933268, 0.015953089396158856, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-wiki_bio_comprehension": [0.01610628922780355, 0.016074382464090983, 0.016045212745666504, 0.016019039154052735, 0.015996052424112957, 0.01597585678100586, 0.0159584108988444, 0.015943638483683267, 0.01593154589335124, 0.015922191937764486, 0.015915546417236328, 0.015911510785420736, 0.015909961064656575, 0.0159108304977417, 0.01591404914855957, 0.015919548670450846, 0.01592724005381266, 0.015937045415242514, 0.015948893229166667, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015841213862101237, 0.01583889643351237, 0.015837308565775553, 0.015836502710978192, 0.015836536089579266, 0.01583745797475179, 0.01583933353424072, 0.015842239061991375, 0.015846238136291504, 0.015851411819458008, 0.015857834815979004, 0.015865589777628582, 0.01587474505106608, 0.015885380109151203, 0.01589755376180013, 0.01591132640838623, 0.015926753679911296, 0.01594387213389079, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.016053444544474285, 0.016029637654622397, 0.016008089383443197, 0.01598892052968343, 0.0159723965326945, 0.015957717895507813, 0.0159450101852417, 0.01593428134918213, 0.015925580660502116, 0.015919033686319986, 0.01591493288675944, 0.01591331164042155, 0.015913912455240885, 0.015916662216186525, 0.015921597480773927, 0.015928711891174317, 0.01593795935312907, 0.01594929059346517, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015357874234517415, 0.015390275319417317, 0.015422854423522949, 0.015455568631490071, 0.015488394101460775, 0.015521308581034343, 0.015554315249125162, 0.015587433179219564, 0.015620679855346679, 0.015654061635335285, 0.01568760871887207, 0.015721338589986165, 0.015755260785420735, 0.015789384841918944, 0.015823699633280435, 0.01585820198059082, 0.015892872810363768, 0.01592771371205648, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.01628304163614909, 0.016244227091471355, 0.01620778242746989, 0.016173621813456218, 0.016141751607259114, 0.01611222743988037, 0.016085147857666016, 0.016060595512390138, 0.01603861172993978, 0.016019217173258462, 0.016002424558003745, 0.01598823070526123, 0.01597664992014567, 0.015967698097229005, 0.015961384773254393, 0.015957722663879393, 0.015956719716389973, 0.015958383878072104, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.015778608322143554, 0.015779622395833335, 0.0157815949122111, 0.015784538586934408, 0.015788478851318358, 0.015793436368306477, 0.015799436569213867, 0.015806509653727215, 0.01581468105316162, 0.015823974609375, 0.01583442687988281, 0.01584605852762858, 0.01585891405741374, 0.015873014132181805, 0.015888376235961912, 0.01590502103169759, 0.015922962824503582, 0.015942195256551106, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.015661551157633465, 0.01567285378774007, 0.01568466822306315, 0.015697167714436848, 0.015710676511128743, 0.01572500546773275, 0.015739622116088866, 0.01575480302174886, 0.015770729382832846, 0.01578756014506022, 0.01580514113108317, 0.015823265711466472, 0.015841856002807617, 0.015860907236735024, 0.01588040351867676, 0.01590033213297526, 0.015920689900716146, 0.015941481590270996, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015657110214233397, 0.015666468938191732, 0.015676693916320802, 0.015687769254048665, 0.01569968541463216, 0.015712412198384602, 0.015725968678792317, 0.015740467707316082, 0.015756058692932128, 0.015772674878438312, 0.015790173212687175, 0.015808534622192384, 0.015827800432840985, 0.015847999254862466, 0.01586912790934245, 0.015891175270080566, 0.0159141206741333, 0.015937964121500652, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.01593430519104004, 0.015963255564371746, 0.015976230303446453, 0.01597692648569743, 0.015972145398457847, 0.015960489908854167, 0.01594622294108073, 0.015932865142822265, 0.015918715794881185, 0.01590835730234782, 0.01590151309967041, 0.015896026293436685, 0.015893425941467285, 0.015894591013590496, 0.015900155703226726, 0.015909547805786132, 0.01592330455780029, 0.015941055615743, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01780634880065918, 0.017587450345357258, 0.017385692596435548, 0.01720180670420329, 0.017031749089558918, 0.016875349680582682, 0.01673257350921631, 0.01660405158996582, 0.01648832321166992, 0.016384617487589518, 0.016292826334635416, 0.016212989489237467, 0.01614509105682373, 0.016088072458902994, 0.016041946411132813, 0.016006622314453125, 0.015981779098510743, 0.015967175165812173, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016035995483398437, 0.01600962956746419, 0.015981626510620118, 0.01595382531483968, 0.015928393999735516, 0.01590511163075765, 0.015888129870096843, 0.015874746640523275, 0.015868670145670574, 0.01586548169453939, 0.015866319338480633, 0.01587080160776774, 0.01587882359822591, 0.0158888037999471, 0.015900595982869466, 0.015914934476216634, 0.015930272738138834, 0.015946353276570638, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014897557894388834, 0.014979292551676432, 0.01505855401357015, 0.015135199228922525, 0.015209280649820963, 0.015280866622924804, 0.01534990946451823, 0.015416305859883626, 0.015479923884073894, 0.015540698369344075, 0.015598635673522949, 0.01565381685892741, 0.015706305503845216, 0.015756093660990397, 0.015803136825561524, 0.01584736506144206, 0.015888722737630208, 0.015927174886067708, 0.015962713559468586], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiki_qa_found_on_google": [0.01600154399871826, 0.01599194049835205, 0.0159846035639445, 0.015979472796122232, 0.01597647031148275, 0.015975656509399413, 0.015977160135904948, 0.015980955759684244, 0.01598694165547689, 0.015995003382364908, 0.01600498040517171, 0.016017014185587566, 0.016031249364217123, 0.016047199567159016, 0.01606509526570638, 0.016086138089497885, 0.016110580762227378, 0.016137394905090332, 0.016167027155558268, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-glue_wnli": [0.015789286295572916, 0.015792206128438315, 0.015797006289164226, 0.0158037265141805, 0.015812424023946125, 0.01582315444946289, 0.015835941632588703, 0.015850758552551268, 0.015867719650268553, 0.015886735916137696, 0.015907384554545084, 0.015930039087931315, 0.015954766273498535, 0.015981475512186687, 0.01601071039835612, 0.016042110125223795, 0.01607768694559733, 0.01611615180969238, 0.016156226793924967, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question": [0.015930237770080565, 0.01591588815053304, 0.015905669530232747, 0.015899195671081542, 0.01589596112569173, 0.01589599291483561, 0.01589923063913981, 0.01590598265329997, 0.015916372934977215, 0.015929773648579917, 0.015945229530334473, 0.015962950388590493, 0.015983130137125653, 0.01600548585255941, 0.016030613581339517, 0.01605812390645345, 0.01608984629313151, 0.01612438678741455, 0.01616044362386068, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is": [0.01607226371765137, 0.01605329990386963, 0.016037073135375977, 0.01602355480194092, 0.016012714703877766, 0.016004546483357748, 0.015999083518981935, 0.015996397336324054, 0.015996540387471517, 0.015999441146850587, 0.01600505828857422, 0.01601353327433268, 0.016025214195251464, 0.016040355364481607, 0.016059001286824543, 0.016080807050069174, 0.016105518341064454, 0.016133527755737304, 0.01616464614868164, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiki_bio_comprehension": [0.01610628922780355, 0.0160898494720459, 0.01607617696126302, 0.016065144538879396, 0.0160567045211792, 0.01605122407277425, 0.0160481595993042, 0.016047341028849284, 0.016048666636149088, 0.016051888465881348, 0.01605705261230469, 0.016064122517903647, 0.016073447863260905, 0.016085298856099446, 0.016099247932434082, 0.016114662488301595, 0.016132006645202635, 0.01615219275156657, 0.016174675623575847, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015844248135884604, 0.015846093495686848, 0.015849782625834148, 0.015855310757954915, 0.01586263338724772, 0.015871742566426594, 0.015882709821065266, 0.015895708401997884, 0.015910844802856445, 0.0159281063079834, 0.015947656631469728, 0.01596944491068522, 0.015993102391560873, 0.01601920445760091, 0.016048982938130698, 0.016082407633463542, 0.01611821174621582, 0.016157169342041016, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.016061007181803387, 0.01604548454284668, 0.016032962799072265, 0.016023565928141276, 0.016016685167948404, 0.016011751492818197, 0.0160092560450236, 0.016009480158487955, 0.0160129451751709, 0.016020078659057618, 0.016029248237609862, 0.01604076862335205, 0.016054347356160483, 0.016069955825805664, 0.01608880360921224, 0.016112225850423177, 0.01613892078399658, 0.016167575518290202, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015359074274698892, 0.015393808682759602, 0.0154298734664917, 0.015467267036437988, 0.015505954424540202, 0.01554590066274007, 0.01558709462483724, 0.015629587173461915, 0.015673440297444663, 0.015718615849812826, 0.015765053431193034, 0.015812760988871258, 0.015861996014912925, 0.015913516680399576, 0.01596725622812907, 0.01602244218190511, 0.016079476674397786, 0.01613846143086751, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.016286853154500326, 0.016252760887145997, 0.01622191905975342, 0.016194190979003906, 0.016169597307840983, 0.016148363749186198, 0.016130634943644206, 0.016116275787353515, 0.01610501766204834, 0.016096860567728678, 0.016092214584350586, 0.016091616948445638, 0.016095261573791503, 0.01610290209452311, 0.016113988558451333, 0.016128822962443033, 0.016148139635721842, 0.01617158095041911, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.01578357219696045, 0.015790367126464845, 0.015798948605855307, 0.015809338887532554, 0.015821561813354493, 0.015835574467976888, 0.015851260821024577, 0.01586862564086914, 0.015887831052144367, 0.015909034411112466, 0.015932064056396484, 0.015957064628601074, 0.015983920097351074, 0.01601248582204183, 0.016044122378031413, 0.016079657872517902, 0.016117037137349445, 0.016156803766886392, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.0156740140914917, 0.015697574615478514, 0.01572152296702067, 0.015746653874715168, 0.01577239195505778, 0.015798764228820802, 0.015827015240987143, 0.01585626443227132, 0.015885116259257, 0.01591380437215169, 0.015942603747049967, 0.015971722602844237, 0.0160013484954834, 0.016031171480814618, 0.01606279691060384, 0.016096250216166178, 0.016129870414733887, 0.016164271036783855, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015664575894673665, 0.01568179766337077, 0.015700302124023437, 0.015720087687174478, 0.015741143226623535, 0.015763444900512694, 0.015786983172098795, 0.015812015533447264, 0.015838993390401204, 0.015867853164672853, 0.015898661613464357, 0.01593006451924642, 0.015962417920430502, 0.015996173222859702, 0.016031770706176757, 0.016069952646891275, 0.016112016042073567, 0.016154497464497885, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015965488751729328, 0.016026713053385416, 0.01607176939646403, 0.016102412541707356, 0.016123345692952474, 0.016134212811787924, 0.01614142894744873, 0.016144763628641763, 0.01614636739095052, 0.01614925225575765, 0.016149036089579263, 0.016148703893025716, 0.016151485443115236, 0.016154727935791015, 0.01615880330403646, 0.016164995829264322, 0.016175484657287596, 0.016186572710673013, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.0178118896484375, 0.017599546114603678, 0.017407779693603517, 0.01723276933034261, 0.01707215468088786, 0.01692630926767985, 0.016795589129130047, 0.016679325103759766, 0.016575837135314943, 0.016485134760538738, 0.016407434145609537, 0.016341981887817384, 0.016287398338317872, 0.016244508425394693, 0.016213599840799967, 0.016194090843200684, 0.016184991200764973, 0.016186663309733073, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016055219968159992, 0.016046624183654785, 0.01603505293528239, 0.016022431055704753, 0.016011091868082684, 0.01600080172220866, 0.01599570910135905, 0.01599435488382975, 0.01599800109863281, 0.016005045572916668, 0.01601640701293945, 0.016030484835306804, 0.016047608057657876, 0.016067428588867186, 0.016091071764628092, 0.016116240819295247, 0.016142988204956056, 0.016170353889465333, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014897305170694987, 0.014979964892069498, 0.015061310132344564, 0.0151413361231486, 0.015220303535461426, 0.015298271179199218, 0.015374867121378581, 0.01544983704884847, 0.015523527463277181, 0.015596097310384114, 0.015667190551757814, 0.015736711819966633, 0.015805120468139647, 0.015872775713602703, 0.015939621925354003, 0.0160051965713501, 0.01607017676035563, 0.016135077476501464, 0.016198655764261882], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-glue_wnli": [0.015789286295572916, 0.015795620282491048, 0.015802396138509114, 0.015809685389200846, 0.01581756591796875, 0.015826032956441242, 0.01583500544230143, 0.015844391187032063, 0.015854161580403647, 0.015864367485046386, 0.01587511380513509, 0.015886486371358234, 0.015898543993631997, 0.015911307334899902, 0.015924752553304035, 0.015938828786214193, 0.0159535010655721, 0.015968804359436036, 0.015984837214152017, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question": [0.015930237770080565, 0.015924569765726725, 0.015920834541320802, 0.01591868241628011, 0.015917619069417317, 0.01591768741607666, 0.01591886520385742, 0.01592145284016927, 0.015925442377726237, 0.015930277506510417, 0.01593558629353841, 0.015941292444864908, 0.0159474515914917, 0.01595406373341878, 0.015961068471272787, 0.01596841017405192, 0.015976079305013022, 0.01598412036895752, 0.015992647806803387, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is": [0.01607226371765137, 0.016060563723246258, 0.01604957421620687, 0.01603932539621989, 0.01602983315785726, 0.016021140416463218, 0.016013274192810057, 0.016006278991699218, 0.01600019137064616, 0.015995041529337565, 0.0159908660252889, 0.015987707773844402, 0.01598558743794759, 0.015984541575113934, 0.015984590848286948, 0.01598573843638102, 0.015987971623738606, 0.015991311073303222, 0.015995807647705078, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-wiki_bio_comprehension": [0.01610628922780355, 0.01608693758646647, 0.016069746017456053, 0.016054566701253256, 0.016040833791097005, 0.016029027303059894, 0.016018999417622883, 0.016010491053263347, 0.016003616650899253, 0.015998144149780274, 0.01599361578623454, 0.01599013010660807, 0.01598778247833252, 0.015986523628234862, 0.01598631699879964, 0.015987159411112468, 0.015989065170288086, 0.01599210262298584, 0.01599630037943522, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015844287872314452, 0.015844923655192057, 0.015846184094746908, 0.015848129590352377, 0.015850809415181476, 0.015854287147521972, 0.0158586057027181, 0.015863839785257974, 0.01587004025777181, 0.01587727705637614, 0.015885616938273114, 0.01589512507120768, 0.015905887285868326, 0.01591797192891439, 0.0159314759572347, 0.01594649314880371, 0.015963147481282552, 0.015981502532958984, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.01606538931528727, 0.01605242888132731, 0.0160402250289917, 0.016029545466105143, 0.016019533475240072, 0.016010459264119467, 0.016002314885457357, 0.015995699564615884, 0.015990740458170574, 0.015987075169881185, 0.01598435084025065, 0.01598244031270345, 0.0159816312789917, 0.015981953938802085, 0.015983425776163736, 0.015986092885335288, 0.015990023612976075, 0.015995229085286458, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015362938245137533, 0.015400005976359049, 0.015436844825744629, 0.015473448435465494, 0.015509796142578126, 0.015545881589253744, 0.015581701596577962, 0.015617280006408692, 0.015652637481689453, 0.0156878137588501, 0.01572285016377767, 0.015757781664530436, 0.015792630513509116, 0.01582743485768636, 0.015862207412719726, 0.015896976788838703, 0.015931771596272785, 0.015966612497965493, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.01629201094309489, 0.016261245409647625, 0.01623205343882243, 0.016204446156819662, 0.01617846171061198, 0.016154112815856932, 0.016131407419840496, 0.01611037572224935, 0.016091022491455078, 0.016073392232259114, 0.016057542165120443, 0.016043540636698404, 0.0160314671198527, 0.016021377245585125, 0.01601329803466797, 0.016007259686787925, 0.016003271738688152, 0.016001351674397788, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.0157833464940389, 0.015788785616556802, 0.015794873237609863, 0.015801639556884767, 0.01580910523732503, 0.015817295710245767, 0.015826228459676107, 0.01583592414855957, 0.01584640343983968, 0.01585768222808838, 0.01586979071299235, 0.015882751146952312, 0.015896601676940916, 0.015911382039388022, 0.015927146275838217, 0.015943969090779622, 0.015961949030558267, 0.015981154441833498, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.015677854220072427, 0.015703986485799154, 0.01572898864746094, 0.01575308640797933, 0.01577651818593343, 0.015798509915669758, 0.0158200470606486, 0.015841166178385418, 0.01586114247639974, 0.015879732767740885, 0.015897167523701985, 0.015913580258687336, 0.015928940773010256, 0.01594327767690023, 0.015956624348958334, 0.01596903959910075, 0.015980626742045086, 0.015991506576538087, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015665707588195802, 0.015682795842488606, 0.01569989522298177, 0.01571699619293213, 0.01573408762613932, 0.015751193364461263, 0.015768599510192872, 0.015786674817403156, 0.015805201530456545, 0.01582392374674479, 0.015842672983805338, 0.01586143652598063, 0.01588040033976237, 0.015899621645609537, 0.015919130643208823, 0.01593897819519043, 0.01595926602681478, 0.015980156262715657, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015970492362976076, 0.016033697128295898, 0.01607793172200521, 0.01610634167989095, 0.016124637921651204, 0.01613226890563965, 0.01613376458485921, 0.016130302747090656, 0.01612353006998698, 0.016114439964294434, 0.01610331694285075, 0.016090521812438963, 0.01607835292816162, 0.016064866383870443, 0.016051316261291505, 0.016038227081298827, 0.01602563699086507, 0.01601335684458415, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01781888961791992, 0.0176105260848999, 0.01741978645324707, 0.0172432804107666, 0.01707967758178711, 0.016929070154825848, 0.016792050997416177, 0.016666970252990722, 0.01655329386393229, 0.01645197868347168, 0.016361791292826333, 0.016282785733540854, 0.016213321685791017, 0.01615394115447998, 0.01610476016998291, 0.016065551439921062, 0.016035610834757488, 0.016014242172241212, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016042415301005045, 0.016022666295369466, 0.016001078287760418, 0.015979181925455728, 0.01595867474873861, 0.01593985398610433, 0.015926464398701986, 0.01591541290283203, 0.01591049353281657, 0.015907503763834634, 0.015908584594726563, 0.0159128999710083, 0.015919168790181477, 0.01592970371246338, 0.015941615104675292, 0.015954740842183433, 0.015969227155049642, 0.01598498344421387, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014909372329711915, 0.015002037684122721, 0.015091381072998046, 0.015177205403645833, 0.01525938351949056, 0.015337831179300944, 0.015412492752075195, 0.01548331101735433, 0.015550236701965332, 0.01561325232187907, 0.015672337214152017, 0.015727465947469075, 0.01577863534291585, 0.015825827916463215, 0.015869034131368, 0.015908241271972656, 0.015943427085876465, 0.01597454071044922, 0.01600154399871826], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question": [0.015930237770080565, 0.01591003735860189, 0.0158922545115153, 0.015876863797505695, 0.01586331844329834, 0.01585143248240153, 0.01584112008412679, 0.01583221435546875, 0.01582455317179362, 0.015817990303039552, 0.015812397003173828, 0.015807660420735677, 0.015803680419921876, 0.015800371170043945, 0.01579763730367025, 0.01579537073771159, 0.015793479283650717, 0.015791869163513182, 0.01579048792521159, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is": [0.01607226371765137, 0.016039786338806154, 0.016009454727172853, 0.015981233914693197, 0.015954980850219725, 0.01593061606089274, 0.015908193588256837, 0.01588776429494222, 0.015869336128234865, 0.01585287888844808, 0.015838348070780436, 0.015825697580973307, 0.01581486701965332, 0.015805781682332355, 0.015798432032267253, 0.015792876879374185, 0.01578919728597005, 0.01578742027282715, 0.015787479082743326, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-wiki_bio_comprehension": [0.01610628922780355, 0.016068957646687827, 0.016033997535705568, 0.016001667976379395, 0.01597196102142334, 0.015944647789001464, 0.015919710795084637, 0.01589704672495524, 0.015876774787902833, 0.015858979225158693, 0.01584354559580485, 0.01583021640777588, 0.01581878662109375, 0.015809200604756674, 0.01580149173736572, 0.015795652071634927, 0.015791600545247395, 0.015789237022399902, 0.015788482030232746, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015840237935384114, 0.01583632787068685, 0.015832502047220864, 0.01582877477010091, 0.015825149218241373, 0.015821626981099447, 0.01581821282704671, 0.01581490198771159, 0.01581168015797933, 0.01580856164296468, 0.01580555280049642, 0.015802680651346844, 0.015799983342488607, 0.01579750855763753, 0.01579530874888102, 0.015793399810791017, 0.01579177697499593, 0.01579041639963786, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.01604257901509603, 0.016008119583129882, 0.015976579984029134, 0.01594764232635498, 0.015921459197998047, 0.015897860527038576, 0.015876307487487792, 0.01585696538289388, 0.0158398707707723, 0.01582502365112305, 0.015812397003173828, 0.01580195109049479, 0.015793665250142416, 0.01578760306040446, 0.015783794720967612, 0.015782168706258138, 0.015782599449157716, 0.0157849915822347, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015360997517903647, 0.015395277341206869, 0.015428404808044433, 0.015460298856099447, 0.015490914980570475, 0.015520289738972981, 0.01554847240447998, 0.015575462977091472, 0.01560124397277832, 0.01562580903371175, 0.015649139086405438, 0.015671175320943198, 0.01569185733795166, 0.015711166063944498, 0.015729190508524577, 0.01574601968129476, 0.015761685371398926, 0.015776136716206868, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.016275461514790854, 0.016229066848754883, 0.01618494987487793, 0.016142926216125487, 0.016102949778238933, 0.01606516679128011, 0.016029774347941082, 0.015996918678283692, 0.01596657117207845, 0.01593862851460775, 0.015912949244181317, 0.01588947931925456, 0.015868231455485025, 0.015849259694417316, 0.015832629203796387, 0.015818357467651367, 0.01580643018086751, 0.015796767870585125, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.015777610143025717, 0.015776821772257487, 0.015776165326436362, 0.015775651931762696, 0.01577527681986491, 0.01577503840128581, 0.015774946212768554, 0.01577499071756999, 0.015775194168090822, 0.015775559743245442, 0.015776108105977377, 0.01577686150868734, 0.01577784856160482, 0.01577908992767334, 0.015780601501464844, 0.015782389640808105, 0.015784443219502765, 0.015786741574605304, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.01565258185068766, 0.01565489927927653, 0.01565775235493978, 0.01566134770711263, 0.015665984153747557, 0.015671499570210776, 0.015677388509114584, 0.015683924357096354, 0.015691181818644206, 0.01569916248321533, 0.015707724889119465, 0.015716700553894042, 0.01572605609893799, 0.01573579470316569, 0.015745892524719238, 0.015756311416625975, 0.015767019589742026, 0.015778013865152995, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015653642018636067, 0.01565896193186442, 0.015664587020874022, 0.015670496622721353, 0.015676679611206053, 0.0156831153233846, 0.01568978468577067, 0.01569671948750814, 0.015703975359598797, 0.01571158250172933, 0.015719507535298664, 0.01572768052419027, 0.015736031532287597, 0.015744552612304688, 0.015753218332926432, 0.0157620366414388, 0.015770986874898276, 0.01578007698059082, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015916191736857096, 0.01593032677968343, 0.015931488672892253, 0.0159231964747111, 0.015909525553385418, 0.01589095115661621, 0.0158698829015096, 0.01584960142771403, 0.015831197102864583, 0.01581309954325358, 0.01579831600189209, 0.015787777900695802, 0.015779706637064617, 0.01577384948730469, 0.015770721435546874, 0.015770406723022462, 0.01577329158782959, 0.015779709815979003, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017782859802246094, 0.017544438044230143, 0.017325302759806316, 0.017127037048339844, 0.01694478193918864, 0.0167780605951945, 0.01662612597147624, 0.01648917039235433, 0.016367031733194988, 0.016257624626159668, 0.01616086483001709, 0.016076199213663735, 0.01600317160288493, 0.015941603978474935, 0.01589099884033203, 0.015850739479064943, 0.01582051912943522, 0.015800094604492186, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01602177619934082, 0.01598175525665283, 0.015940821965535482, 0.01590094725290934, 0.01586385409037272, 0.015831143061319986, 0.015803669293721515, 0.015782103538513184, 0.015764374732971192, 0.01575499693552653, 0.015747685432434082, 0.015744342803955078, 0.015744760831197104, 0.01574807008107503, 0.01575317859649658, 0.01575986703236898, 0.01576804478963216, 0.01577807108561198, 0.015789286295572916], "lorahub/flan_t5_large-glue_wnli+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014890255928039551, 0.014964613914489746, 0.015036311149597168, 0.015105266571044922, 0.015171570777893066, 0.015235265096028646, 0.0152962064743042, 0.015354153315226236, 0.015408946673075357, 0.015460624694824218, 0.015509295463562011, 0.015555025736490886, 0.015597716967264811, 0.015637292861938476, 0.015673782030741375, 0.01570727030436198, 0.015737749735514322, 0.01576511065165202, 0.015789286295572916], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is": [0.01607226371765137, 0.016052568753560384, 0.016034077008565267, 0.016016739209493, 0.01600042502085368, 0.015985223452250164, 0.015971291859944663, 0.015958711306254068, 0.01594750722249349, 0.015937604904174806, 0.015928913752237955, 0.015921494166056316, 0.015915635426839193, 0.015911931991577147, 0.015910409291585288, 0.015910690625508626, 0.015912737846374512, 0.015916493733723957, 0.015922172864278158, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-wiki_bio_comprehension": [0.01610628922780355, 0.016084806124369303, 0.016064168612162272, 0.01604489008585612, 0.01602726936340332, 0.016010958353678384, 0.015995747248331707, 0.015981705983479817, 0.015969003041585286, 0.01595771312713623, 0.0159478235244751, 0.015939332644144693, 0.01593226432800293, 0.015926694869995116, 0.01592272917429606, 0.015920454661051433, 0.015919985771179198, 0.015921417872111, 0.015924830436706543, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.01583902359008789, 0.015834277470906575, 0.0158300511042277, 0.01582640488942464, 0.015823391278584797, 0.015821054776509604, 0.015819497108459472, 0.015818870862325033, 0.015819347699483236, 0.015821094512939452, 0.015824389457702637, 0.01582965056101481, 0.015837043126424154, 0.015846516291300457, 0.01585814634958903, 0.015872125625610353, 0.015888476371765138, 0.015907710393269856, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.016053144137064615, 0.01602825164794922, 0.016005406379699706, 0.01598444938659668, 0.01596529801686605, 0.015947982470194497, 0.015932569503784178, 0.015919108390808106, 0.01590766429901123, 0.01589832623799642, 0.015891229311625163, 0.015886507034301757, 0.015884259541829426, 0.015884610811869305, 0.015887672106424968, 0.01589359124501546, 0.015902581214904784, 0.015914791425069172, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015343848864237468, 0.015363302230834961, 0.01538395881652832, 0.015405742327372234, 0.015428722699483236, 0.015453065236409505, 0.01547889550526937, 0.015506280263264975, 0.015535275141398111, 0.015565849939982097, 0.015597874323527019, 0.0156314484278361, 0.015666866302490236, 0.015704847971598306, 0.01574546019236247, 0.015788254737854005, 0.015833199818929035, 0.015880241394042968, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.016292802492777505, 0.01626215934753418, 0.01623225529988607, 0.016202985445658367, 0.016174424489339194, 0.016146799723307292, 0.01612032413482666, 0.0160951296488444, 0.016071338653564454, 0.016049017906188966, 0.01602817217508952, 0.016009023984273275, 0.0159919277826945, 0.015976823170979818, 0.015963527361551922, 0.01595210870107015, 0.015942559242248536, 0.015935080846150716, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.015774771372477212, 0.01577181339263916, 0.015769678751627603, 0.0157684055964152, 0.015768057505289715, 0.015768723487854006, 0.015770514806111652, 0.01577353318532308, 0.01577789306640625, 0.015783759752909344, 0.015791420936584474, 0.015801072120666504, 0.01581271012624105, 0.015826358795166015, 0.015842145284016926, 0.015860239664713543, 0.01588063398996989, 0.015903865496317546, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.015662242571512858, 0.01567351500193278, 0.015684752464294432, 0.015696179072062173, 0.015707821846008302, 0.01571973164876302, 0.01573199431101481, 0.015744686126708984, 0.015757875442504884, 0.015771573384602864, 0.01578580856323242, 0.015800649325052898, 0.01581618785858154, 0.01583252747853597, 0.015849784215291342, 0.015868080457051594, 0.015887522697448732, 0.0159082301457723, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015652745564778647, 0.015657738049825034, 0.015663647651672365, 0.0156705109278361, 0.015678383509318033, 0.015687313079833985, 0.015697352091471353, 0.015708560943603515, 0.015721001625061036, 0.01573474725087484, 0.0157498566309611, 0.015766394933064778, 0.015784411430358886, 0.015803996721903482, 0.01582529862721761, 0.01584847609202067, 0.01587364196777344, 0.015900867780049642, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.01592896302541097, 0.015954933166503905, 0.01596671422322591, 0.01596751848856608, 0.015961626370747883, 0.015950565338134767, 0.015935471852620443, 0.015919572512308758, 0.015905067125956216, 0.015890560150146484, 0.015880322456359862, 0.01587192217508952, 0.015866697629292804, 0.01586584726969401, 0.01586910883585612, 0.015876779556274413, 0.01588927904764811, 0.015907012621561686, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017810821533203125, 0.017595799763997395, 0.01739555835723877, 0.017212894757588703, 0.01704402764638265, 0.016887596448262533, 0.0167438809076945, 0.01661257266998291, 0.01649371306101481, 0.016387262344360352, 0.016292449633280436, 0.016209168434143065, 0.016137137413024902, 0.016076052983601888, 0.016025741895039875, 0.01598604679107666, 0.015956885019938152, 0.015938331286112467, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01605064868927002, 0.016037168502807616, 0.016020051638285317, 0.016000973383585613, 0.01598148187001546, 0.015963253974914552, 0.015945963859558106, 0.01593265215555827, 0.01592138926188151, 0.015912322998046874, 0.015908570289611818, 0.015905909538269043, 0.015904792149861655, 0.01590550740559896, 0.015907843907674152, 0.015911836624145508, 0.0159170134862264, 0.01592316468556722, 0.015930237770080565], "lorahub/flan_t5_large-duorc_ParaphraseRC_answer_question+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014871079126993815, 0.014928504625956218, 0.014985690116882324, 0.015042707125345866, 0.015099740028381348, 0.015156922340393066, 0.015214244524637857, 0.015271668434143066, 0.015329159100850424, 0.015386730829874674, 0.015444475809733073, 0.01550268014272054, 0.0155617094039917, 0.015621566772460937, 0.015682034492492676, 0.01574305852254232, 0.015804553031921388, 0.015866792996724447, 0.015930237770080565], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-wiki_bio_comprehension": [0.01610628922780355, 0.016079106330871583, 0.01605512777964274, 0.016034425099690754, 0.016016510327657062, 0.016001871426900228, 0.015990444819132487, 0.01598186492919922, 0.01597616195678711, 0.015973135630289712, 0.015972414016723634, 0.015974146525065104, 0.01597842534383138, 0.015985164642333984, 0.015994269053141275, 0.01600563049316406, 0.01601917266845703, 0.016034832000732423, 0.01605254809061686, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.01584168275197347, 0.01584060033162435, 0.01584099610646566, 0.015842890739440917, 0.01584631284077962, 0.015851289431254068, 0.01585784594217936, 0.01586600621541341, 0.01587581475575765, 0.015887290636698404, 0.015900483131408693, 0.01591541926066081, 0.015932146708170572, 0.01595070997873942, 0.01597114562988281, 0.015993496576944988, 0.016017783482869467, 0.016044039726257325, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.01606056531270345, 0.01604379653930664, 0.016028931935628255, 0.01601662000020345, 0.016006348927815755, 0.015997904141743978, 0.01599127133687337, 0.015986406008402506, 0.01598395824432373, 0.015984031359354656, 0.01598624070485433, 0.015990269978841145, 0.015996076265970865, 0.016003971099853517, 0.016013890902201334, 0.016025602022806805, 0.016039047241210937, 0.016054546038309733, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015356036822001139, 0.01538740317026774, 0.015419754981994629, 0.015453093846638998, 0.015487435658772787, 0.015522775650024414, 0.015559118588765462, 0.01559646447499593, 0.01563481330871582, 0.015674166679382324, 0.015714510281880697, 0.01575584888458252, 0.015798174540201822, 0.015841476122538247, 0.015885744094848633, 0.015930970509847004, 0.01597713788350423, 0.01602424144744873, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.016302828788757325, 0.016282294591267902, 0.016262715657552083, 0.01624404748280843, 0.016226272583007812, 0.016209362347920735, 0.016193319956461588, 0.01617814540863037, 0.016163853009541828, 0.016150471369425455, 0.016138017972310383, 0.016126497586568197, 0.01611592769622803, 0.016106303532918295, 0.016097623507181802, 0.01608989079793294, 0.016083087921142578, 0.01607721169789632, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.015777963002522787, 0.015779143969217937, 0.015782081286112467, 0.01578678290049235, 0.015793253580729166, 0.01580149491628011, 0.015811519622802736, 0.015823326110839843, 0.015836908022562664, 0.01585227648417155, 0.015869425137837727, 0.015888357162475587, 0.0159090789159139, 0.015931615829467772, 0.01595598538716634, 0.015982227325439455, 0.01601036071777344, 0.016040374437967936, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.015663641293843587, 0.015677391688028973, 0.015691968599955242, 0.015708041191101075, 0.015725011825561522, 0.015743120511372884, 0.015763263702392578, 0.015784587860107422, 0.015806458791097006, 0.015829172134399414, 0.015852883656819663, 0.01587752819061279, 0.015902997652689616, 0.015929152170817057, 0.015956058502197265, 0.01598383108774821, 0.01601250966389974, 0.01604201634724935, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015660204887390138, 0.015672958691914877, 0.015686866442362467, 0.015701891581217448, 0.015717976888020832, 0.015735173225402833, 0.015753928820292154, 0.015774296124776203, 0.015795944531758626, 0.015818748474121094, 0.0158424711227417, 0.01586714744567871, 0.015892942746480305, 0.01591992219289144, 0.015948135058085122, 0.01597751458485921, 0.01600791295369466, 0.01603944778442383, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015942018826802573, 0.015980559984842935, 0.016004378000895183, 0.016016589800516765, 0.016023467381795248, 0.016022847493489582, 0.01601959705352783, 0.016014750798543295, 0.016009901364644367, 0.0160077174504598, 0.016005436579386394, 0.01600386142730713, 0.016006223360697427, 0.016010491053263347, 0.016016769409179687, 0.01602599302927653, 0.01603839874267578, 0.016053873697916665, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017826889355977375, 0.017625840504964192, 0.017442140579223633, 0.017272833188374838, 0.017115575472513835, 0.016970899899800617, 0.01683907349904378, 0.01671851634979248, 0.01660884380340576, 0.01651107629140218, 0.016423994700113933, 0.0163479216893514, 0.016281105677286783, 0.01622371196746826, 0.016175451278686522, 0.016136299769083658, 0.01610621770222982, 0.01608497937520345, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.0160524845123291, 0.016041539510091147, 0.016027771631876627, 0.016012948354085288, 0.015999191602071125, 0.015986239115397136, 0.015978395144144696, 0.01597320556640625, 0.01597216288248698, 0.015973507563273114, 0.01597760518391927, 0.015984745025634767, 0.015993270874023437, 0.016006070772806802, 0.016018813451131184, 0.01603179136912028, 0.01604493459065755, 0.016058578491210937, 0.01607226371765137], "lorahub/flan_t5_large-adversarial_qa_dbidaf_tell_what_it_is+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014888752301534016, 0.014963254928588868, 0.015036970774332682, 0.015109783808390299, 0.015181652704874675, 0.01525257428487142, 0.015322585105895997, 0.015391678810119628, 0.01545978864034017, 0.015526808102925619, 0.015592629114786784, 0.015657161076863605, 0.015720367431640625, 0.01578225612640381, 0.015842852592468263, 0.015902177492777506, 0.015960219701131186, 0.016016933123270672, 0.01607226371765137], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015847562154134114, 0.01585171858469645, 0.015856734911600747, 0.01586265246073405, 0.015869534810384115, 0.015877399444580078, 0.0158862574895223, 0.0158961820602417, 0.01590734799702962, 0.015919920603434244, 0.015933920542399088, 0.01594937801361084, 0.01596649169921875, 0.01598545551300049, 0.016006263097127278, 0.016028674443562825, 0.016052652994791666, 0.016078605651855468, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.016069639523824057, 0.01606095790863037, 0.016053077379862467, 0.0160462760925293, 0.01604087829589844, 0.016036782264709473, 0.016033803621927897, 0.016032040913899738, 0.016031635602315266, 0.01603265603383382, 0.0160351037979126, 0.016038978894551595, 0.016044249534606935, 0.016050888697306316, 0.016058945655822755, 0.016068530082702637, 0.016079670588175457, 0.016092262268066405, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015355525016784667, 0.015386452674865722, 0.015418519973754883, 0.01545177459716797, 0.015486226081848145, 0.015521888732910155, 0.015558773676554363, 0.015596901575724284, 0.01563631057739258, 0.015677030881245932, 0.01571889082590739, 0.015761787096659343, 0.01580625057220459, 0.015852298736572266, 0.01589993158976237, 0.015949408213297527, 0.016000177065531414, 0.016052417755126953, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.01629102071126302, 0.016259827613830567, 0.016230767567952473, 0.016203889846801756, 0.0161792516708374, 0.01615691661834717, 0.01613695462544759, 0.016119437217712404, 0.01610434691111247, 0.01609165032704671, 0.01608150005340576, 0.01607424259185791, 0.016069884300231933, 0.016068331400553384, 0.016069854100545247, 0.01607459545135498, 0.01608206590016683, 0.01609257698059082, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.01578328450520833, 0.01578903357187907, 0.01579582373301188, 0.01580369472503662, 0.015812692642211915, 0.015822869936625163, 0.01583432197570801, 0.015847196578979494, 0.015861639976501463, 0.015877699851989745, 0.01589537302652995, 0.01591472307840983, 0.01593596935272217, 0.015959242184956868, 0.01598459720611572, 0.016011905670166016, 0.016041113535563152, 0.016072646776835123, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.015670587221781412, 0.01569092909495036, 0.01571159839630127, 0.01573264757792155, 0.01575409730275472, 0.015775968233744303, 0.015798285802205405, 0.01582106908162435, 0.015844337145487466, 0.015868120193481446, 0.01589243729909261, 0.015917297999064127, 0.01594269593556722, 0.015968586603800457, 0.01599494934082031, 0.01602192719777425, 0.016049663225809734, 0.016077823638916015, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015659327507019042, 0.01567126750946045, 0.015684479077657063, 0.015698981285095216, 0.015714794794718424, 0.015731972058614097, 0.01575056552886963, 0.01577064355214437, 0.015792288780212403, 0.015815585454305014, 0.015840574900309243, 0.01586726665496826, 0.015895625750223796, 0.01592559019724528, 0.015957353909810384, 0.015991284052530925, 0.016027674674987794, 0.01606616497039795, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015950400034586587, 0.015995535850524902, 0.016024279594421386, 0.01603978474934896, 0.016048501332600912, 0.01604915459950765, 0.016045826276143392, 0.01604186693827311, 0.01603748639424642, 0.016033350626627606, 0.016030775705973308, 0.016029884020487467, 0.016031371752421062, 0.016035289764404298, 0.01604203224182129, 0.016052273114522297, 0.016067075729370116, 0.016085103352864585, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017802723248799644, 0.017581392923990885, 0.01738120714823405, 0.017197769482930503, 0.017030264536539715, 0.016877822875976563, 0.01674136797587077, 0.01661889870961507, 0.01651050885518392, 0.016415923436482748, 0.01633392333984375, 0.016264387766520182, 0.01620732307434082, 0.016162428855895996, 0.01612905502319336, 0.016106656392415365, 0.016095201174418133, 0.01609516461690267, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016054490407307942, 0.016042631467183432, 0.016025427182515463, 0.01600533167521159, 0.01598507086435954, 0.0159652312596639, 0.01595101038614909, 0.0159408966700236, 0.015935163497924804, 0.015934089024861653, 0.015938533147176106, 0.015947554906209308, 0.01596046288808187, 0.01597684860229492, 0.015996556282043457, 0.016019784609476725, 0.016046228408813475, 0.016075091361999513, 0.01610628922780355], "lorahub/flan_t5_large-wiki_bio_comprehension+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014899048805236816, 0.014983000755310059, 0.01506528377532959, 0.015145765940348306, 0.015224364598592123, 0.015301052729288738, 0.01537575403849284, 0.015448357264200846, 0.015518808364868164, 0.015587161382039388, 0.015653510093688965, 0.015717782974243165, 0.015779832204182942, 0.015839715003967286, 0.01589758078257243, 0.015953276952107746, 0.01600636641184489, 0.016057387987772623, 0.01610628922780355], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.01604955832163493, 0.016022009849548338, 0.015996565818786623, 0.015973642667134604, 0.01595300833384196, 0.01593418757120768, 0.0159172248840332, 0.015901959737141928, 0.015888442993164064, 0.01587705930074056, 0.015867703755696613, 0.015860047340393067, 0.015853950182596842, 0.015849194526672362, 0.01584566116333008, 0.015843404134114582, 0.015842440923055014, 0.015842730204264324, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015360417366027833, 0.015394539833068847, 0.015428021748860677, 0.015460813840230306, 0.015492865244547526, 0.015524131457010905, 0.015554569562276204, 0.01558414618174235, 0.015612826347351075, 0.015640578269958495, 0.01566737174987793, 0.015693179766337075, 0.015717976888020832, 0.015741742451985678, 0.015764451026916503, 0.01578606923421224, 0.01580658753712972, 0.015825978914896646, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.016278079350789388, 0.01623439311981201, 0.01619318962097168, 0.016154381434122723, 0.01611790657043457, 0.01608373483022054, 0.01605186144510905, 0.016022281646728517, 0.015994989077250162, 0.015969980557759604, 0.01594723383585612, 0.015926725069681805, 0.01590842882792155, 0.015892333984375, 0.01587841510772705, 0.015866661071777345, 0.015857054392496746, 0.015849579175313315, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.01578132629394531, 0.015784238179524738, 0.01578726609547933, 0.015790395736694336, 0.01579362392425537, 0.015796937942504884, 0.015800328254699708, 0.015803782145182292, 0.01580730438232422, 0.015810877482096353, 0.01581449031829834, 0.0158181365331014, 0.01582182248433431, 0.015825525919596354, 0.015829248428344725, 0.01583298683166504, 0.015836730003356933, 0.015840476353963216, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.01566532293955485, 0.015679324467976888, 0.015692718823750815, 0.01570571422576904, 0.015718812942504882, 0.01573107083638509, 0.01574275811513265, 0.015754357973734538, 0.015765924453735352, 0.015777023633321126, 0.015787402788798015, 0.015797006289164226, 0.015805827776590984, 0.015813945134480794, 0.015821385383605956, 0.015828145345052082, 0.01583419958750407, 0.015839564005533855, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015657529830932618, 0.015666735967000325, 0.01567618211110433, 0.01568582534790039, 0.01569559415181478, 0.015705453554789226, 0.015715524355570474, 0.015726057688395183, 0.015736947059631346, 0.01574799378712972, 0.015759135882059735, 0.01577026685078939, 0.01578125, 0.015792059898376464, 0.015802709261576335, 0.0158132537206014, 0.015823696454366046, 0.015834026336669922, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015937616030375162, 0.015970317522684734, 0.01598706404368083, 0.015991021792093912, 0.015988910992940267, 0.015979493459065755, 0.015966307322184244, 0.015952385266621908, 0.015935659408569336, 0.015920268694559734, 0.01590732256571452, 0.01589359124501546, 0.01588058312733968, 0.015870060920715332, 0.015861805280049643, 0.01585505485534668, 0.015849587122599283, 0.01584591865539551, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017792514165242513, 0.017561457951863608, 0.0173495610555013, 0.017156516710917155, 0.016978567441304524, 0.016815317471822102, 0.016667302449544272, 0.016533843676249185, 0.01641332467397054, 0.0163053560256958, 0.016209929784138998, 0.016126999855041502, 0.01605546474456787, 0.015995262463887532, 0.01594537576039632, 0.015905407269795734, 0.015875334739685058, 0.01585499127705892, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016031813621520997, 0.016001326243082682, 0.015969311396280925, 0.015937633514404297, 0.015908438364664712, 0.015881171226501466, 0.015860613187154135, 0.015843100547790527, 0.01583230495452881, 0.015823779106140138, 0.015819188753763834, 0.015816926956176758, 0.015817610422770183, 0.01581907590230306, 0.01582308769226074, 0.01582862695058187, 0.015833918253580728, 0.015839088757832846, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.01489908218383789, 0.014981837272644042, 0.015061543782552084, 0.015137966473897297, 0.015211044947306315, 0.015280758539835612, 0.01534704844156901, 0.015409806569417317, 0.015468894640604655, 0.015524190266927083, 0.015575599670410157, 0.015623062451680502, 0.015666561126708986, 0.015706092516581217, 0.015741661389668784, 0.015773277282714843, 0.01580091953277588, 0.015824578603108725, 0.015844224294026692], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015357500712076822, 0.015390140215555827, 0.015423595110575358, 0.01545777956644694, 0.015492663383483887, 0.015528281529744467, 0.015564708709716797, 0.015601991017659505, 0.015639780362447103, 0.015678375562032065, 0.015718216896057128, 0.015759784380594888, 0.01580261707305908, 0.015846293767293296, 0.01589088757832845, 0.01593619664510091, 0.015983099937438964, 0.01603072802225749, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.01629326820373535, 0.01626414934794108, 0.016236863136291503, 0.016211407979329427, 0.016187774340311687, 0.01616588274637858, 0.016145922342936197, 0.016128198305765788, 0.01611266295115153, 0.016099538803100586, 0.016089043617248534, 0.016080678304036457, 0.016074309349060057, 0.01606999715169271, 0.016067535082499185, 0.016067283948262533, 0.016069393157958984, 0.01607335090637207, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.0157785431543986, 0.015780135790506997, 0.015783316294352215, 0.0157880433400472, 0.015794323285420735, 0.015802237192789715, 0.015811929702758788, 0.015823461214701334, 0.015836992263793946, 0.01585275332132975, 0.01587048053741455, 0.01588991324106852, 0.015911054611206055, 0.015933985710144042, 0.015958606402079266, 0.015985487302144368, 0.0160147492090861, 0.01604602813720703, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.015672248204549155, 0.015693840980529786, 0.015715394020080566, 0.01573699156443278, 0.01575871467590332, 0.015780657132466635, 0.015802895228068034, 0.01582532246907552, 0.015847864151000975, 0.015870493253072104, 0.015893222490946452, 0.01591602325439453, 0.015938908259073892, 0.015961963335673013, 0.01598528226216634, 0.016008814175923664, 0.016032280921936034, 0.016055806477864584, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015662668546040853, 0.01567760149637858, 0.015693421363830565, 0.01571015516916911, 0.015727810859680176, 0.015746407508850098, 0.015765961011250815, 0.015786492029825846, 0.01580801486968994, 0.015830551783243815, 0.015854088465372722, 0.01587860584259033, 0.015904043515523273, 0.01593022664388021, 0.015957504908243814, 0.015986081759134928, 0.01601588249206543, 0.016047164599100747, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015951631863911946, 0.015998423894246418, 0.016029006640116375, 0.01604668140411377, 0.016054848035176594, 0.01605862299601237, 0.016057000160217286, 0.016052939097086587, 0.01604878266652425, 0.01604438304901123, 0.016039663950602214, 0.016037561098734537, 0.016037287712097167, 0.016038500467936197, 0.01604177474975586, 0.016047350565592446, 0.01605547110239665, 0.016066282590230307, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017826571464538574, 0.01762657324473063, 0.01744056542714437, 0.01727112293243408, 0.01711613337198893, 0.016972716649373373, 0.016841354370117186, 0.016721526781717937, 0.01661299228668213, 0.016515591939290364, 0.016429014205932617, 0.01635267734527588, 0.01628604253133138, 0.0162287966410319, 0.016180858612060547, 0.016142215728759766, 0.01611267407735189, 0.01609197775522868, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016039415995279947, 0.016017422676086426, 0.015994532903035482, 0.01597244421641032, 0.015952779452006023, 0.015937188466389973, 0.015925097465515136, 0.015920426050821942, 0.01591926097869873, 0.015923194885253907, 0.01593320369720459, 0.015944822629292806, 0.015959186553955076, 0.015975915590922037, 0.01599462827046712, 0.016014838218688966, 0.01603602409362793, 0.016057796478271484, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014888420104980468, 0.014962630271911621, 0.015036056836446127, 0.015108580589294434, 0.015180106163024903, 0.015250574747721355, 0.015320100784301759, 0.01538878599802653, 0.015456546147664387, 0.015523556073506674, 0.015589845975240072, 0.015655113855997722, 0.015719238917032877, 0.01578217347462972, 0.015843688646952313, 0.01590430736541748, 0.015963919957478843, 0.016022210121154786, 0.01607987880706787], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer": [0.016324326197306314, 0.016259064674377443, 0.01619517962137858, 0.016132647196451824, 0.016071454683939616, 0.016011595726013184, 0.01595308303833008, 0.015895943641662597, 0.015840214093526206, 0.01578593413035075, 0.015733129183451336, 0.015681821505228677, 0.015632023811340334, 0.015583742459615071, 0.015536975860595704, 0.015491712888081868, 0.01544796625773112, 0.015405710538228352, 0.01536494255065918, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.015764538447062174, 0.015749422709147136, 0.015733195940653484, 0.015715858141581218, 0.015697415669759116, 0.01567787488301595, 0.01565725008646647, 0.01563552697499593, 0.01561272621154785, 0.015588844617207845, 0.015563877423604329, 0.015537816683451335, 0.015510668754577637, 0.015482432047526041, 0.015453116099039713, 0.015422741572062174, 0.015391345024108887, 0.015358978907267253, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.015638287862141928, 0.015624922116597493, 0.015610636075337728, 0.015595919291178385, 0.015580860773722331, 0.015564869244893392, 0.015548984209696451, 0.015533258120218912, 0.01551693598429362, 0.015499855677286784, 0.015482238133748372, 0.01546420415242513, 0.015445717175801595, 0.015426756540934245, 0.015407320658365885, 0.015387419064839682, 0.015367115338643392, 0.0153465207417806, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015636353492736815, 0.015623475710550944, 0.015609971682230632, 0.015595787366231283, 0.01558090368906657, 0.015565759340922037, 0.015550637245178222, 0.015535122553507487, 0.015519097646077474, 0.015502292315165202, 0.015484763781229654, 0.015466707547505697, 0.015448169708251953, 0.015429174105326335, 0.015409666697184245, 0.015389560063680013, 0.015368819236755371, 0.015347498257954915, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015914889971415203, 0.01592242399851481, 0.0159122101465861, 0.015888948440551758, 0.015857507387797037, 0.015818797747294108, 0.01577786445617676, 0.015733510653177896, 0.015688823064168293, 0.01564676602681478, 0.015603100458780925, 0.015560801823933918, 0.015521955490112305, 0.015484450658162435, 0.01544838269551595, 0.015414810180664063, 0.015383543968200684, 0.015353703498840332, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01776249090830485, 0.017501262029012043, 0.017261006037394205, 0.01703859806060791, 0.016831334431966147, 0.016639550526936848, 0.01646354834238688, 0.01630193551381429, 0.016153577168782553, 0.016019344329833984, 0.01589800516764323, 0.015789642333984374, 0.015692240397135418, 0.015605689684549968, 0.015529685020446778, 0.015463892618815105, 0.01540810743967692, 0.015362103780110678, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.015995386441548666, 0.015929325421651205, 0.015862584114074707, 0.015797022183736166, 0.01573474725087484, 0.015675230026245116, 0.015623532931009928, 0.015576060612996418, 0.015535141626993815, 0.015497875213623048, 0.01546568234761556, 0.015437838236490885, 0.015413055419921875, 0.01539329210917155, 0.015376187960306804, 0.01536063035329183, 0.015346999168395997, 0.015335343678792317, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014872374534606934, 0.014927945137023925, 0.014980130195617676, 0.015028802553812663, 0.01507390022277832, 0.015115443865458171, 0.015153462092081706, 0.015187951723734537, 0.015218866666158041, 0.015246156056722006, 0.015269761085510253, 0.015289637247721354, 0.015305782953898112, 0.015318193435668946, 0.01532690684000651, 0.015331974029541015, 0.015333434740702312, 0.015331323941548665, 0.015325651168823243], "lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer+lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only": [0.015778538386027018, 0.015785420735677083, 0.01579472064971924, 0.015806441307067872, 0.015820589065551758, 0.015837173461914062, 0.015856202443440756, 0.015877685546875, 0.01590163230895996, 0.01592804749806722, 0.015956924756368, 0.015988248189290365, 0.016022006670633953, 0.016058160463968914, 0.016096660296122233, 0.01613747437795003, 0.016180586814880372, 0.016226040522257488, 0.016273918151855468, 0.016324326197306314], "lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.01567405382792155, 0.015698736508687337, 0.01572467803955078, 0.01575235843658447, 0.01578146457672119, 0.015811686515808106, 0.015843865076700846, 0.015878100395202637, 0.01591372807820638, 0.015950374603271485, 0.015987962086995443, 0.016026574770609536, 0.01606624126434326, 0.016106897989908855, 0.016148489316304526, 0.01619100570678711, 0.016234466234842936, 0.016278913815816243, 0.016324326197306314], "lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015672930081685386, 0.01569842497507731, 0.01572511037190755, 0.01575296719868978, 0.015781957308451333, 0.01581210136413574, 0.015843637784322104, 0.015876765251159667, 0.01591121037801107, 0.01594696839650472, 0.0159842046101888, 0.016022828420003254, 0.016062684059143066, 0.016103746096293132, 0.016145965258280437, 0.016189160346984862, 0.01623321056365967, 0.016278182665507, 0.016324326197306314], "lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.01595244248708089, 0.016000844637552896, 0.016034135818481444, 0.01605567455291748, 0.016072258949279786, 0.016082649230957032, 0.016091963450113933, 0.016099971135457358, 0.01610889275868734, 0.0161201810836792, 0.016132235527038574, 0.016145310401916503, 0.01616146246592204, 0.01618082364400228, 0.016203325589497886, 0.016229076385498045, 0.01625794251759847, 0.0162894868850708, 0.016324326197306314], "lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01784161408742269, 0.017655261357625327, 0.017486545244852703, 0.01733193238576253, 0.017189358075459796, 0.017059016227722167, 0.016941291491190592, 0.016834712028503417, 0.016738988558451334, 0.016654486656188964, 0.016580823262532553, 0.01651718298594157, 0.01646376609802246, 0.016419178644816082, 0.01638316790262858, 0.016355767250061035, 0.016336881319681803, 0.016326430638631186, 0.016324326197306314], "lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016057340304056804, 0.01605230649312337, 0.016045479774475097, 0.016038695971171062, 0.01603391170501709, 0.016031263669331868, 0.01603411038716634, 0.016042086283365887, 0.016053056716918944, 0.01606841564178467, 0.0160872491200765, 0.016110291481018068, 0.01613509178161621, 0.016163167953491212, 0.016193949381510416, 0.01622541427612305, 0.016257594426472982, 0.016290637652079266, 0.016324326197306314], "lorahub/flan_t5_large-adversarial_qa_dbidaf_question_context_answer+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014900344212849935, 0.014986832936604818, 0.01507293701171875, 0.015158519744873047, 0.015243471463521322, 0.015327692031860352, 0.015411092440287271, 0.015493601163228354, 0.015575146675109864, 0.015655674934387208, 0.015735114415486653, 0.015813403129577637, 0.015890485445658367, 0.015966286659240724, 0.01604075908660889, 0.016113848686218263, 0.016185503005981445, 0.016255679130554198, 0.016324326197306314], "lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only+lorahub/flan_t5_large-wiki_bio_key_content": [0.015650684038798015, 0.015658798217773436, 0.015666618347167968, 0.015674182573954264, 0.015681764284769695, 0.015689830780029296, 0.015697407722473144, 0.015704739888509116, 0.015712159474690755, 0.015719844500223797, 0.015727469126383464, 0.01573478857676188, 0.01574171702067057, 0.01574824333190918, 0.01575433890024821, 0.015760019620259604, 0.015765287081400552, 0.015770133336385092, 0.01577454884847005, 0.015778538386027018], "lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015653870900472006, 0.015659324328104653, 0.01566497325897217, 0.015670787493387857, 0.015676724116007488, 0.015682762463887532, 0.01568893591562907, 0.015695425669352215, 0.01570234775543213, 0.015709547996520995, 0.01571691672007243, 0.015724434852600097, 0.01573206901550293, 0.01573974927266439, 0.01574743111928304, 0.015755133628845217, 0.015762869517008463, 0.015770665804545083, 0.015778538386027018], "lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.015935444831848146, 0.015965431531270346, 0.015979045232137043, 0.015979652404785157, 0.015974036852518716, 0.015960351626078288, 0.015942950248718262, 0.015924352010091146, 0.0159033997853597, 0.015884615580240884, 0.015867344538370767, 0.015849639574686686, 0.015832843780517577, 0.01581848462422689, 0.01580662727355957, 0.015796721776326496, 0.015788671175638834, 0.01578255494435628, 0.015778538386027018], "lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017783042589823404, 0.017543412844340005, 0.017323398590087892, 0.01712324301401774, 0.0169387420018514, 0.016769652366638185, 0.016616209348042806, 0.016478252410888673, 0.016354130109151203, 0.01624319871266683, 0.01614503542582194, 0.01605990409851074, 0.01598690986633301, 0.015925536155700682, 0.015875473022460937, 0.015835955937703452, 0.01580667813618978, 0.015787569681803386, 0.015778538386027018], "lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01602654457092285, 0.015990598996480306, 0.015953073501586913, 0.015915956497192383, 0.01588140328725179, 0.015849356651306153, 0.01582388242085775, 0.015801976521809896, 0.015787192980448405, 0.015775129000345865, 0.01576706568400065, 0.01576202392578125, 0.015760226249694823, 0.015759751001993814, 0.01576095740000407, 0.015764722824096678, 0.01576915740966797, 0.015773706436157227, 0.015778538386027018], "lorahub/flan_t5_large-wiki_qa_Topic_Prediction_Answer_Only+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014896936416625976, 0.014977372487386068, 0.015054553349812826, 0.015128280321756999, 0.015198554992675781, 0.015265366236368816, 0.015328615506490072, 0.015388153394063313, 0.015443817774454752, 0.015495486259460449, 0.015543111165364583, 0.015586684544881185, 0.01562622865041097, 0.015661749839782715, 0.015693252881368, 0.015720712343851726, 0.015744094848632813, 0.015763373374938966, 0.015778538386027018], "lorahub/flan_t5_large-wiki_bio_key_content+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.01565058708190918, 0.015652356147766115, 0.015653924942016603, 0.015655269622802736, 0.01565638224283854, 0.015657242139180502, 0.015657841364542645, 0.015658184687296548, 0.015658249855041505, 0.015657971700032552, 0.01565745989481608, 0.0156570037206014, 0.015656582514444985, 0.015656073888142902, 0.015655377705891926, 0.015654490788777668, 0.01565346876780192, 0.015652249654134115, 0.015650684038798015], "lorahub/flan_t5_large-wiki_bio_key_content+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.01593858559926351, 0.015970603624979655, 0.01598490079243978, 0.015984732309977212, 0.015975705782572427, 0.015958511034647623, 0.015935654640197753, 0.015910147031148274, 0.015883269309997557, 0.0158548370997111, 0.01582697073618571, 0.015800525347391764, 0.015774691899617513, 0.01574945608774821, 0.015725959142049155, 0.015704232851664224, 0.015684386889139812, 0.015666481653849283, 0.015650684038798015], "lorahub/flan_t5_large-wiki_bio_key_content+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017797900835673015, 0.017569931348164876, 0.01735809326171875, 0.01716352939605713, 0.016982930501302083, 0.016814842224121093, 0.016659170786539713, 0.0165164581934611, 0.016385682423909507, 0.016266241073608398, 0.016157898902893066, 0.016060263315836588, 0.015972844759623208, 0.015895501772562663, 0.015828099250793457, 0.015770274798075357, 0.015721635818481447, 0.015681799252827963, 0.015650684038798015], "lorahub/flan_t5_large-wiki_bio_key_content+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.0160252046585083, 0.015984654426574707, 0.015939633051554363, 0.015892791748046874, 0.015846659342447916, 0.015803558031717936, 0.01576438268025716, 0.015731476147969565, 0.01570281982421875, 0.015681463877360025, 0.01566373825073242, 0.01565012296040853, 0.015641252199808758, 0.015636035601298014, 0.01563392480214437, 0.01563470681508382, 0.01563798268636068, 0.015643347104390463, 0.015650684038798015], "lorahub/flan_t5_large-wiki_bio_key_content+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014887005488077799, 0.014957559903462729, 0.015025026003519694, 0.015089271863301595, 0.015150272051493326, 0.015207996368408203, 0.015262398719787598, 0.015313402811686198, 0.015360883076985677, 0.015404814084370931, 0.015445202191670736, 0.015482219060262044, 0.015516462326049805, 0.01554768721262614, 0.01557503859202067, 0.015599214235941569, 0.015620036125183106, 0.015637200673421225, 0.015650684038798015], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-glue_cola": [0.01588545004526774, 0.01592394193013509, 0.015941656430562338, 0.01594259262084961, 0.015930501619974773, 0.015911664962768555, 0.015885154406229656, 0.015854811668395995, 0.01582460085550944, 0.015794180234273276, 0.01576457977294922, 0.015739140510559083, 0.015716458956400555, 0.015696393648783367, 0.015679262479146323, 0.015665585199991863, 0.01565560817718506, 0.01564942200978597, 0.01564708391825358, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017781375249226888, 0.017539765040079754, 0.017315457661946615, 0.01711028575897217, 0.01692265033721924, 0.016749046643575034, 0.01658994197845459, 0.0164446226755778, 0.01631269296010335, 0.016194828351338706, 0.016089186668395997, 0.015995286305745444, 0.01591301918029785, 0.015842073758443195, 0.015782179832458495, 0.015733095804850262, 0.01569458802541097, 0.01566647529602051, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016014561653137208, 0.015967845916748047, 0.01592041015625, 0.015873953501383462, 0.015830028851826987, 0.015790195465087892, 0.015754294395446778, 0.01572505791982015, 0.015700257619222006, 0.015679744084676105, 0.015666605631510417, 0.015655163129170736, 0.015647058486938478, 0.015641972223917642, 0.01564000447591146, 0.015640077590942384, 0.015641509691874188, 0.015644410451253254, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014879380861918132, 0.014943030675252279, 0.01500432014465332, 0.015063276290893554, 0.01511993408203125, 0.015174190203348795, 0.015225906372070313, 0.01527498722076416, 0.015321439107259114, 0.015365260442097982, 0.015406560897827149, 0.015445574124654134, 0.015482384363810222, 0.015516705513000488, 0.015548367500305176, 0.015577359199523926, 0.015603710810343424, 0.015627454121907552, 0.015648625691731772], "lorahub/flan_t5_large-glue_cola+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017863149642944335, 0.017696490287780763, 0.017540966669718425, 0.01739593029022217, 0.01726142406463623, 0.017136540412902832, 0.01702001412709554, 0.016911147435506185, 0.016810359954833983, 0.01671638329823812, 0.016627626419067384, 0.01654338836669922, 0.01646174112955729, 0.016379437446594237, 0.016297073364257814, 0.016208887100219727, 0.016112712224324543, 0.01600578467051188, 0.01588545004526774], "lorahub/flan_t5_large-glue_cola+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016044975916544597, 0.016028893788655598, 0.01601234753926595, 0.015997093518575034, 0.015984296798706055, 0.015974570910135905, 0.01596848646799723, 0.015966540972391766, 0.015968316396077473, 0.0159737761815389, 0.015981860160827636, 0.015990931193033853, 0.015999237696329754, 0.01600472609202067, 0.01600489139556885, 0.015996630986531576, 0.015976322491963704, 0.01594042460123698, 0.01588545004526774], "lorahub/flan_t5_large-glue_cola+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014878443082173665, 0.014944219589233398, 0.0150112517674764, 0.015079035758972167, 0.015148008664449056, 0.015218397776285808, 0.015290401776631673, 0.015361955960591634, 0.01543227513631185, 0.015503654479980469, 0.015575067202250163, 0.015643237431844075, 0.015709827740987142, 0.015771245956420897, 0.015823561350504556, 0.015866821606953938, 0.015894131660461427, 0.0159016752243042, 0.01588545004526774], "lorahub/flan_t5_large-word_segment+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01608874797821045, 0.01611968994140625, 0.01615343729654948, 0.016191827456156414, 0.01623664697011312, 0.01628976027170817, 0.01635240872701009, 0.01642582893371582, 0.016511858304341633, 0.016608869234720866, 0.01671810309092204, 0.01684000809987386, 0.016974089940388997, 0.01712007522583008, 0.017278186480204263, 0.017449897130330405, 0.01763435999552409, 0.017831576665242512, 0.01804223855336507], "lorahub/flan_t5_large-word_segment+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.0148930025100708, 0.014980099995930989, 0.015075146357218424, 0.015178426106770834, 0.015290217399597168, 0.015410580635070802, 0.015539657274882, 0.015678772926330565, 0.0158288304011027, 0.01598967711130778, 0.016162975629170736, 0.016347816785176595, 0.016545639038085938, 0.016757248242696126, 0.01698264757792155, 0.017221593856811525, 0.01747576077779134, 0.01775050481160482, 0.01804223855336507], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-qasc_qa_with_separated_facts_3": [0.014813599586486816, 0.014868370691935221, 0.014923070271809896, 0.014977348645528158, 0.01503121534983317, 0.015085655848185222, 0.015142062505086262, 0.015198995272318522, 0.015258215268452962, 0.015318962732950846, 0.015382663408915202, 0.015447543462117514, 0.01551762580871582, 0.015589462916056314, 0.015666926701863607, 0.015745498339335123, 0.0158259646097819, 0.01590629736582438, 0.015984538396199545, 0.016058756510416668]}, "seed:2": {"lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-true_case": [0.019832337697347005, 0.019462099075317384, 0.019116034507751466, 0.01879344622294108, 0.018493445714314778, 0.0182156499226888, 0.017958989143371584, 0.017722751299540204, 0.017506227493286133, 0.017308778762817383, 0.017129991849263507, 0.016969079971313476, 0.01682491461435954, 0.016696879069010417, 0.016584653854370118, 0.016487766901652018, 0.016405704816182455, 0.016338022549947102, 0.016284351348876954, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-app_reviews_categorize_rating_using_review": [0.016069146792093914, 0.016040139198303223, 0.01601602872212728, 0.015996572176615396, 0.01598164717356364, 0.015971147219340006, 0.015964968999226888, 0.015963012377421062, 0.015965213775634767, 0.015971527099609376, 0.01598192532857259, 0.015996211369832355, 0.016014014879862468, 0.01603579044342041, 0.01606147607167562, 0.01609087626139323, 0.016123894055684408, 0.01616050084431966, 0.016200675964355468, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015958986282348632, 0.01595522403717041, 0.015953750610351564, 0.01595426559448242, 0.015956772168477375, 0.015961853663126628, 0.015970746676127117, 0.015980731646219888, 0.015993099212646484, 0.016007965405782063, 0.016024330457051594, 0.016043631235758464, 0.01606469472249349, 0.016087818145751952, 0.01611366589864095, 0.016142983436584473, 0.016174548467000324, 0.016208265622456867, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-race_middle_Taking_a_test": [0.01603962262471517, 0.016026767094930013, 0.016016799608866372, 0.016009753545125325, 0.016005632082621256, 0.016004746754964192, 0.01600678284962972, 0.016011370023091633, 0.016018489201863606, 0.016027992566426594, 0.016039395332336427, 0.016053032875061036, 0.016069159507751465, 0.016087633768717448, 0.016108385721842446, 0.01613135019938151, 0.016156463623046874, 0.016183686256408692, 0.016213005383809407, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-duorc_SelfRC_movie_director": [0.016625248591105143, 0.016562870343526204, 0.016506120363871255, 0.016454830169677734, 0.016408832867940266, 0.016367953618367515, 0.0163320255279541, 0.016300870577494304, 0.016274307568868, 0.016252164840698243, 0.016234294573465983, 0.016220537821451823, 0.016210748354593914, 0.01620480537414551, 0.016202589670817058, 0.016204012235005696, 0.016208977699279786, 0.016217419306437175, 0.016229254404703776, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-quarel_testing_students": [0.015599570274353027, 0.0156186310450236, 0.015639198621114094, 0.015661301612854003, 0.01568492889404297, 0.01571012496948242, 0.015736905733744304, 0.015765298207600913, 0.01579532464345296, 0.015827035903930663, 0.015860454241434733, 0.015895613034566245, 0.015932555198669433, 0.015971320470174154, 0.016011940638224285, 0.01605446497599284, 0.01609892209370931, 0.0161453644434611, 0.016193841298421222, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is": [0.016054999033610025, 0.0160592254002889, 0.016064108212788898, 0.016069650650024414, 0.016075857480367026, 0.01608273188273112, 0.0160902738571167, 0.016098484992980958, 0.01610733985900879, 0.016116836865743, 0.01612694581349691, 0.016137649218241373, 0.016148921648661295, 0.016160767873128257, 0.016173181533813478, 0.016186176935831707, 0.016199774742126465, 0.01621400515238444, 0.016228882471720378, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-quail_context_question_answer_description_id": [0.015255335172017416, 0.015297396977742513, 0.015340509414672852, 0.01538464864095052, 0.015429827372233073, 0.015476044019063313, 0.015523319244384765, 0.015571686426798502, 0.015621166229248046, 0.015671780904134115, 0.015723552703857422, 0.015776492754618326, 0.015830621719360352, 0.015885950724283854, 0.01594250202178955, 0.016000297864278156, 0.016059357325236, 0.016119704246520997, 0.016181384722391765, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.0160568364461263, 0.016051383018493653, 0.016044100125630695, 0.0160366423924764, 0.016031036376953123, 0.01602656364440918, 0.01602805773417155, 0.016031572024027507, 0.016041499773661295, 0.016052934328715008, 0.016067943572998046, 0.016085063616434733, 0.016104753812154135, 0.016125431060791017, 0.01614922046661377, 0.01617340564727783, 0.016197209358215333, 0.016220938364664712, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.01718250592549642, 0.017052302360534666, 0.016935447057088215, 0.01683048407236735, 0.016735604604085286, 0.016650007565816242, 0.016573354403177896, 0.016505204836527506, 0.016445156733194986, 0.016392855644226073, 0.016348160107930502, 0.01631093184153239, 0.016281000773111978, 0.0162581205368042, 0.01624209721883138, 0.01623277982076009, 0.016230096817016603, 0.016233978271484376, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.016544895172119142, 0.016471519470214843, 0.016408276557922364, 0.016355037689208984, 0.016308949788411457, 0.01627033869425456, 0.01624177614847819, 0.01621705691019694, 0.016197630564371745, 0.016183578173319498, 0.016173466046651205, 0.01616842269897461, 0.016167054176330565, 0.016169517834981283, 0.01617743492126465, 0.01618927319844564, 0.016204005877176922, 0.016222370465596516, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015991069475809732, 0.015989012718200683, 0.015988739331563313, 0.015990281105041505, 0.015993680953979492, 0.015998961130777995, 0.01600619951883952, 0.016015354792277017, 0.01602622985839844, 0.01603892962137858, 0.016053703625996906, 0.0160705296198527, 0.01608937740325928, 0.016110216776529948, 0.0161330509185791, 0.016157873471577964, 0.01618469556172689, 0.016213534673055013, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.01571715990702311, 0.015726701418558756, 0.015738423665364584, 0.015752355257670086, 0.01576849937438965, 0.015786894162495933, 0.01580756187438965, 0.015830523173014324, 0.01585581461588542, 0.015883458455403645, 0.015913492838541668, 0.01594595750172933, 0.015980879465738933, 0.016018301645914713, 0.01605826695760091, 0.016100810368855793, 0.01614598592122396, 0.016193836530049643, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015577878952026367, 0.015607186953226725, 0.015637462933858235, 0.01566871960957845, 0.01570096492767334, 0.015734186172485353, 0.01576834519704183, 0.01580338954925537, 0.015839285850524902, 0.015876010258992514, 0.015913554827372233, 0.01595194180806478, 0.01599117120107015, 0.016031254132588706, 0.01607218583424886, 0.01611395517985026, 0.016156578063964845, 0.016200056076049806, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017827601432800294, 0.017628650665283203, 0.017447444597880047, 0.017282265027364095, 0.01713028907775879, 0.016991427739461263, 0.01686641534169515, 0.016754132906595866, 0.01665338357289632, 0.01656410535176595, 0.016486924489339194, 0.016420957247416178, 0.01636623700459798, 0.016321496963500978, 0.01628658135732015, 0.01626152515411377, 0.01624619166056315, 0.01624050299326579, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.01634346803029378, 0.01629979133605957, 0.016259593963623045, 0.01622499148050944, 0.01619599978129069, 0.016170501708984375, 0.016147613525390625, 0.016129045486450194, 0.016115336418151854, 0.016107001304626466, 0.016104097366333007, 0.0161057710647583, 0.016111520131429035, 0.016121918360392253, 0.016136814753214518, 0.01615642547607422, 0.016180860201517742, 0.016210166613260905, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015466548601786296, 0.015498828887939454, 0.015532312393188476, 0.015566978454589844, 0.015602839787801108, 0.015639979044596353, 0.015678553581237792, 0.015718557039896646, 0.015759857495625813, 0.015802459716796877, 0.015846433639526366, 0.015891749064127603, 0.015938270886739096, 0.015985976854960122, 0.0160349702835083, 0.016085321108500163, 0.01613702456156413, 0.016190052032470703, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017268048922220867, 0.01717493216196696, 0.017084762255350747, 0.016997707684834797, 0.016914997100830078, 0.01683700720469157, 0.016763089497884114, 0.01669387658437093, 0.01662952740987142, 0.016570223172505696, 0.01651620070139567, 0.016466917991638182, 0.016421551704406737, 0.01638054847717285, 0.016344292958577474, 0.016312646865844726, 0.016285521189371745, 0.016262799898783365, 0.016244417826334637], "lorahub/flan_t5_large-adversarial_qa_dbidaf_based_on+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.01604533354441325, 0.01603753407796224, 0.016032236417134603, 0.016029327710469565, 0.016028591791788737, 0.01602984587351481, 0.01603302319844564, 0.01603817621866862, 0.01604540189107259, 0.01605478604634603, 0.016066416104634603, 0.016080350875854493, 0.016096625328063965, 0.01611525853474935, 0.016136283874511718, 0.016159702936808268, 0.016185514132181802, 0.016213746070861818, 0.016244417826334637], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-app_reviews_categorize_rating_using_review": [0.016069146792093914, 0.01609989643096924, 0.016146920522054038, 0.016210598945617674, 0.016291141510009766, 0.016388673782348633, 0.016503513654073078, 0.016636228561401366, 0.016787064870198567, 0.01695670445760091, 0.017146469751993815, 0.017356386184692384, 0.017586995760599772, 0.017838629086812337, 0.018111696243286134, 0.018407991727193197, 0.01872718334197998, 0.019070183436075847, 0.019438641866048177, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.016019714673360188, 0.01608889102935791, 0.016171932220458984, 0.016269615491231283, 0.016382404963175456, 0.016510284741719564, 0.016654001871744793, 0.01681444009145101, 0.016991674105326336, 0.017186443010965984, 0.017401215235392252, 0.017632964452107748, 0.017884456316630045, 0.01815535545349121, 0.01844613234202067, 0.018758230209350586, 0.01909274737040202, 0.019450403849283853, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-race_middle_Taking_a_test": [0.01603962262471517, 0.0160720427831014, 0.01612002690633138, 0.016184248924255372, 0.016265981992085773, 0.016363879839579265, 0.0164787753423055, 0.016612181663513182, 0.016763890584309896, 0.016934420267740887, 0.01712440013885498, 0.017333919207255046, 0.01756475289662679, 0.017817460695902506, 0.01809276262919108, 0.018390917778015138, 0.0187133264541626, 0.01906045118967692, 0.0194332218170166, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-duorc_SelfRC_movie_director": [0.016625248591105143, 0.01663687070210775, 0.01666483243306478, 0.016708958943684897, 0.0167693026860555, 0.016846017837524416, 0.01693930784861247, 0.017049304644266763, 0.017175916035970053, 0.017319766680399577, 0.01748197078704834, 0.017662747701009115, 0.017862292925516766, 0.018081040382385255, 0.01831922690073649, 0.01857795556386312, 0.018858396212259928, 0.01916050593058268, 0.019484860102335612, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-quarel_testing_students": [0.015599570274353027, 0.01565345605214437, 0.015722633997599284, 0.015807477633158366, 0.015908430417378744, 0.01602598508199056, 0.0161608091990153, 0.016313856442769368, 0.01648591995239258, 0.01667755126953125, 0.01688941478729248, 0.017122249603271484, 0.017376791636149087, 0.01765355110168457, 0.01795360565185547, 0.01827809969584147, 0.018627713521321615, 0.019002714157104493, 0.019403969446818034, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is": [0.016054999033610025, 0.016114702224731447, 0.016186962127685545, 0.01627209981282552, 0.016370495160420735, 0.01648262659708659, 0.016609002749125162, 0.01675013860066732, 0.016906458536783853, 0.01707823912302653, 0.01726626714070638, 0.017471877733866374, 0.01769580682118734, 0.017938612302144368, 0.018200931549072267, 0.018483036359151203, 0.018786271413167317, 0.01911154270172119, 0.019459970792134604, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-quail_context_question_answer_description_id": [0.015255335172017416, 0.015325676600138347, 0.015411308606465658, 0.015512693723042805, 0.015630388259887697, 0.015764977137247723, 0.01591705322265625, 0.016087287267049152, 0.016276609102884927, 0.016485994656880696, 0.016716049512227375, 0.016967337926228843, 0.0172405481338501, 0.017536396980285644, 0.01785545508066813, 0.018198984464009603, 0.018567886352539063, 0.01896243413289388, 0.019383653004964193, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016142520904541015, 0.016230133374532062, 0.016323731740315754, 0.01642552057902018, 0.016537458101908365, 0.016661612192789714, 0.016799081166585288, 0.01695077896118164, 0.017120765050252278, 0.017305986086527506, 0.017509832382202148, 0.017732795079549155, 0.017973477045694988, 0.018233383496602376, 0.018511873881022135, 0.01880990187327067, 0.019129071235656738, 0.01946955680847168, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.017322112719217936, 0.017335607210795086, 0.017366716066996257, 0.017412261962890627, 0.01747076670328776, 0.017542829513549806, 0.01762887159983317, 0.01772907257080078, 0.017843763033548992, 0.017973198890686035, 0.018117494583129883, 0.018276708920796712, 0.018450833956400552, 0.018639864921569823, 0.01884433428446452, 0.019065424601236978, 0.019303499857584637, 0.01955901781717936, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.016606720288594563, 0.016609331766764324, 0.016635006268819173, 0.01668489456176758, 0.016755425135294596, 0.016846351623535157, 0.01695700963338216, 0.017088557879130047, 0.01724075635274251, 0.01741081237792969, 0.017598776817321776, 0.01780560493469238, 0.018031023343404135, 0.018275993665059408, 0.01854176998138428, 0.01882928689320882, 0.01913929303487142, 0.01947315057118734, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.01603867212931315, 0.016096866925557455, 0.016169816652933756, 0.016258169809977213, 0.016362078984578452, 0.016482256253560385, 0.016619399388631186, 0.016773988405863444, 0.016946678161621095, 0.01713816006978353, 0.017349022229512533, 0.01757932662963867, 0.017830980618794758, 0.01810479164123535, 0.018401400248209635, 0.018721240361531576, 0.01906588077545166, 0.019436017672220866, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.015765377680460612, 0.015835037231445314, 0.01591915448506673, 0.016018152236938477, 0.016132485071818033, 0.016262685457865397, 0.01640954812367757, 0.01657441775004069, 0.01675821304321289, 0.016961418787638346, 0.01718483289082845, 0.017429439226786296, 0.017696024576822917, 0.01798600673675537, 0.018300738334655762, 0.01864161968231201, 0.019009634653727212, 0.019405981699625652, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.01562723954518636, 0.015718267758687336, 0.015823024113972982, 0.015941999753316245, 0.01607572555541992, 0.016224759419759115, 0.016389622688293456, 0.01657087802886963, 0.016769124666849773, 0.016985004742940266, 0.017219161987304686, 0.017472138404846193, 0.017744507789611817, 0.018037273089090984, 0.018351195653279622, 0.01868713696797689, 0.019045413335164386, 0.019426854451497395, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.018005695343017578, 0.017983956336975096, 0.017976137797037762, 0.017984132766723632, 0.018007497787475586, 0.018044153849283855, 0.01809543450673421, 0.018160201708475748, 0.018238929112752277, 0.018331700960795085, 0.01843872865041097, 0.018560271263122558, 0.018696524302164712, 0.018847578366597492, 0.019013757705688476, 0.019195078214009603, 0.019391546249389647, 0.01960382620493571, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016420226097106933, 0.016463545163472492, 0.01652049382527669, 0.016593044598897298, 0.016683483123779298, 0.016788614590962727, 0.016907431284586587, 0.01704278786977132, 0.01719690004984538, 0.017369068463643392, 0.017558951377868653, 0.01776720364888509, 0.017995454470316568, 0.018244396845499673, 0.018514501253763836, 0.01880696455637614, 0.01912384033203125, 0.019465540250142414, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015500569343566894, 0.015580495198567709, 0.01567570686340332, 0.015786730448404947, 0.015914142926534015, 0.016058600743611654, 0.016220796902974448, 0.016401464144388835, 0.016601325670878093, 0.016821061770121257, 0.017061446507771808, 0.017323501904805503, 0.01760806083679199, 0.017915757497151692, 0.018247230847676595, 0.018603703180948894, 0.018986210823059083, 0.01939526875813802, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017331345876057943, 0.01731217702229818, 0.01730717976888021, 0.017317668596903483, 0.01734545866648356, 0.017390511830647788, 0.017452670733133953, 0.01753288269042969, 0.01763314406077067, 0.017753705978393555, 0.01789490063985189, 0.01805725574493408, 0.018240912755330404, 0.01844613234202067, 0.018673892021179198, 0.018925463358561198, 0.019201143582661947, 0.0195035187403361, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016113006273905436, 0.016183708508809406, 0.016267911593119303, 0.01636591911315918, 0.016478055318196613, 0.01660467783610026, 0.016746193567911783, 0.016903098424275717, 0.01707597096761068, 0.01726541519165039, 0.017471927007039388, 0.01769621213277181, 0.01793911139170329, 0.01820122241973877, 0.01848332405090332, 0.018786721229553223, 0.0191120704015096, 0.019460236231486003, 0.019832337697347005], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015946927070617675, 0.0159310515721639, 0.015917531649271646, 0.015906310081481932, 0.01589742342631022, 0.015891928672790528, 0.015888525644938152, 0.01588857650756836, 0.015890318552652993, 0.01589500904083252, 0.01590188185373942, 0.0159115997950236, 0.01592511812845866, 0.01594179630279541, 0.015961720148722332, 0.01598368485768636, 0.016009058952331543, 0.01603683312733968, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-race_middle_Taking_a_test": [0.01603962262471517, 0.016024905840555825, 0.016012055079142253, 0.0160011355082194, 0.01599213759104411, 0.015985064506530762, 0.015979825655619305, 0.015976298650105795, 0.015974475542704265, 0.015974319775899252, 0.01597573439280192, 0.015978679656982422, 0.01598323345184326, 0.015989511807759604, 0.015997645060221354, 0.016007738113403322, 0.016019848187764484, 0.016034045219421388, 0.0160504150390625, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-duorc_SelfRC_movie_director": [0.016625248591105143, 0.01654640833536784, 0.01647414207458496, 0.016408176422119142, 0.016348269780476887, 0.0162942107518514, 0.016245845158894857, 0.016203052202860516, 0.016165479024251302, 0.016132675806681315, 0.01610478401184082, 0.016081813176472982, 0.016063637733459472, 0.016050163904825845, 0.016041371027628582, 0.016037246386210124, 0.016037848790486652, 0.01604329268137614, 0.016053682963053387, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-quarel_testing_students": [0.015599570274353027, 0.015617176691691081, 0.015634932518005372, 0.015652907689412434, 0.015671181678771972, 0.01568986415863037, 0.015709056854248046, 0.01572888215382894, 0.015749508539835613, 0.015771176020304364, 0.015794134140014647, 0.015817872683207192, 0.015842811266581217, 0.015869332949320476, 0.01589751084645589, 0.015927403767903647, 0.015959157943725585, 0.015993056297302247, 0.016029601097106935, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is": [0.016054999033610025, 0.016032767295837403, 0.016012762387593586, 0.01599506855010986, 0.015979760487874348, 0.01596686363220215, 0.015956406593322755, 0.015948448181152344, 0.01594288190205892, 0.01593960444132487, 0.015939054489135743, 0.01594139258066813, 0.015946574211120605, 0.015954612096150716, 0.015965574582417805, 0.015979625384012857, 0.01599691390991211, 0.01601753234863281, 0.016041555404663087, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-quail_context_question_answer_description_id": [0.015255335172017416, 0.015293556849161784, 0.015331857999165853, 0.015370167096455892, 0.015408530235290527, 0.015447087287902832, 0.015485935211181641, 0.015525174140930176, 0.015564955075581869, 0.015605535507202149, 0.01564685026804606, 0.015688529014587404, 0.015731221834818523, 0.015775039990743003, 0.015820012092590333, 0.015866289138793944, 0.0159140412012736, 0.015963565508524576, 0.016015186309814453, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016042998631795247, 0.01602464516957601, 0.016005072593688965, 0.015985458691914877, 0.015967313448588052, 0.015951342582702636, 0.015938798586527508, 0.01593149979909261, 0.015926127433776856, 0.01592520554860433, 0.01592796007792155, 0.015933542251586913, 0.015945218404134116, 0.01595908800760905, 0.015976414680480958, 0.015995715459187824, 0.016017244656880696, 0.016041555404663087, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.01716707706451416, 0.017022790908813475, 0.016893178621927896, 0.01677493890126546, 0.016666450500488282, 0.016567843755086263, 0.016478598912556965, 0.016398364702860515, 0.016327110926310222, 0.016264575322469076, 0.016210478146870932, 0.016164676348368327, 0.01612704594930013, 0.016097416877746584, 0.01607566197713216, 0.01606180508931478, 0.016056001981099445, 0.016058395703633627, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.016549700101216633, 0.01647902488708496, 0.016417064666748048, 0.016361881891886393, 0.016311788558959962, 0.016270337104797365, 0.016231468518575033, 0.01619690259297689, 0.01616687297821045, 0.016139742533365885, 0.01611634095509847, 0.016096256573994955, 0.01608153184254964, 0.0160692834854126, 0.016060895919799804, 0.01605637550354004, 0.016055394808451334, 0.016059276262919107, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015974841117858886, 0.01595702330271403, 0.015941519737243653, 0.015928435325622558, 0.015917832056681316, 0.01590976397196452, 0.015904318491617837, 0.015901565551757812, 0.01590157667795817, 0.015904380480448406, 0.01591003735860189, 0.01591863791147868, 0.015930274327596028, 0.015945040384928385, 0.015963009198506673, 0.015984265009562175, 0.01600891908009847, 0.016037136713663736, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.015712742805480958, 0.015716759363810222, 0.01572194258371989, 0.015728379885355633, 0.01573620001475016, 0.01574556509653727, 0.01575667381286621, 0.015769739151000977, 0.015784508387247723, 0.01580109755198161, 0.01581995646158854, 0.015841215451558432, 0.015864961942036945, 0.015891329447428385, 0.015920459429423016, 0.015952542622884116, 0.015987849235534667, 0.016026624043782554, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015565975507100423, 0.015583330790201824, 0.01560177485148112, 0.01562132994333903, 0.015641822814941406, 0.01566313902537028, 0.015685462951660158, 0.015708953539530435, 0.015733707745869956, 0.015759979883829753, 0.015788033803304038, 0.015817009607950846, 0.015847585995992026, 0.015879817008972168, 0.01591365337371826, 0.015949209531148274, 0.01598674138387044, 0.016026649475097656, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017785830497741698, 0.01754921277364095, 0.017335995038350423, 0.017140576044718425, 0.016961698532104493, 0.016800282796223958, 0.01665548324584961, 0.016525564193725587, 0.016412323315938313, 0.016314450899759927, 0.016232144037882486, 0.01616453488667806, 0.016110202471415203, 0.016069650650024414, 0.01604264259338379, 0.016028906504313153, 0.016028706232706705, 0.016042162577311198, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016343917846679688, 0.016299908955891926, 0.016259164810180665, 0.01622424284617106, 0.01619175910949707, 0.016159491539001467, 0.016130321820576984, 0.016105020840962728, 0.016083787282307943, 0.01606625239054362, 0.016051295598347982, 0.01603941758473714, 0.016031508445739747, 0.016027421951293946, 0.016027083396911623, 0.01603088855743408, 0.01603906790415446, 0.01605173110961914, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.01546507994333903, 0.01549464225769043, 0.01552412986755371, 0.015553687413533529, 0.015583882331848145, 0.015614306131998698, 0.015645155906677245, 0.01567673683166504, 0.01570840040842692, 0.01574036439259847, 0.015773096084594727, 0.015807100931803385, 0.01584123452504476, 0.0158763853708903, 0.01591255823771159, 0.01594955285390218, 0.01598759651184082, 0.016027283668518067, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017230401039123534, 0.017102101643880208, 0.016979711850484212, 0.01686412811279297, 0.01675673802693685, 0.016656840642293294, 0.016564353307088216, 0.016479608217875162, 0.016401766141255696, 0.016332529385884604, 0.016271613438924155, 0.016218287150065104, 0.016172809600830076, 0.016135339736938478, 0.016105842590332032, 0.01608434836069743, 0.016070963541666667, 0.016065840721130372, 0.016069146792093914], "lorahub/flan_t5_large-app_reviews_categorize_rating_using_review+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016034269332885744, 0.01601590951283773, 0.016000321706136068, 0.01598672072092692, 0.01597479820251465, 0.01596467653910319, 0.01595671017964681, 0.01595118522644043, 0.01594831943511963, 0.01594772656758626, 0.01594924767812093, 0.01595353921254476, 0.015960750579833986, 0.01597085952758789, 0.015983786582946777, 0.01599970499674479, 0.016019010543823244, 0.016042054494222004, 0.016069146792093914], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-race_middle_Taking_a_test": [0.01603962262471517, 0.01601781209309896, 0.01599890073140462, 0.015983948707580565, 0.015969279607137045, 0.01595773220062256, 0.01594795862833659, 0.015938690503438314, 0.01593325138092041, 0.015929171244303385, 0.015926448504130046, 0.015924933751424154, 0.015924461682637534, 0.01592615286509196, 0.015928904215494793, 0.015933810869852703, 0.015940038363138835, 0.01594711939493815, 0.015955499013264974, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-duorc_SelfRC_movie_director": [0.016625248591105143, 0.016548633575439453, 0.01647787570953369, 0.0164124059677124, 0.016351062456766763, 0.01629590352376302, 0.016246609687805176, 0.016201559702555338, 0.01616064230600993, 0.016124369303385417, 0.016091596285502115, 0.01606245517730713, 0.016037777264912925, 0.016016384760538738, 0.01599952538808187, 0.015986385345458983, 0.0159762446085612, 0.01596937338511149, 0.0159656031926473, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-quarel_testing_students": [0.015599570274353027, 0.015609413782755533, 0.015620020230611166, 0.015631621678670247, 0.015644280115763347, 0.015658626556396483, 0.015673944155375163, 0.015690053304036458, 0.015706710815429688, 0.015725080172220865, 0.01574383576711019, 0.015763975779215494, 0.01578483740488688, 0.015805784861246744, 0.01582951863606771, 0.015854727427164712, 0.015880821545918782, 0.015907677014668782, 0.015935789744059244, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is": [0.016054999033610025, 0.01603654384613037, 0.01601936181386312, 0.016003131866455078, 0.015987725257873536, 0.015974194208780924, 0.015963589350382487, 0.015954607327779133, 0.015946606000264485, 0.015940755208333334, 0.015936032931009928, 0.015932540893554687, 0.015930620829264323, 0.0159293794631958, 0.01593115965525309, 0.01593520482381185, 0.015940639177958172, 0.01594711939493815, 0.015955301920572918, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-quail_context_question_answer_description_id": [0.015255335172017416, 0.015284833908081054, 0.01531554381052653, 0.015347013473510742, 0.015379398663838705, 0.01541309356689453, 0.015447402000427246, 0.01548228899637858, 0.015517745018005371, 0.015554436047871907, 0.015591341654459636, 0.015629275639851888, 0.015668344497680665, 0.015706785519917808, 0.015747660001118977, 0.015789804458618165, 0.015832478205362956, 0.015875790913899738, 0.015919982592264813, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016034989356994628, 0.01600747267405192, 0.0159783935546875, 0.01594971497853597, 0.01592321554819743, 0.01590030034383138, 0.01588191827138265, 0.015868568420410158, 0.015860276222229006, 0.01585675080617269, 0.015859103202819823, 0.015864389737447103, 0.015872764587402343, 0.015883782704671223, 0.0158970308303833, 0.015912113189697267, 0.01592862923940023, 0.015945687294006347, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.017168148358662923, 0.01702652931213379, 0.01689985752105713, 0.0167834202448527, 0.016673957506815593, 0.016573654810587566, 0.016482685407002765, 0.01640058994293213, 0.016325825055440266, 0.01625898838043213, 0.016198395093282063, 0.016146639188130696, 0.01610118548075358, 0.01606270472208659, 0.01603098710378011, 0.016004926363627117, 0.015985339482625326, 0.015971895853678385, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.016531031926472983, 0.016445072491963704, 0.016369301478068032, 0.016302366256713868, 0.016243181228637694, 0.016192132631937663, 0.016147165298461913, 0.016107231775919596, 0.01607224146525065, 0.01604195753733317, 0.01601619243621826, 0.015994774500528972, 0.0159775177637736, 0.015964401563008625, 0.01595564365386963, 0.01595131556193034, 0.015951364835103354, 0.015955046017964682, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015979105631510417, 0.015964293479919435, 0.015950595537821452, 0.015938510894775392, 0.015929096539815266, 0.01592124144236247, 0.01591427803039551, 0.015910266240437825, 0.015907808939615884, 0.01590625603993734, 0.015906562805175783, 0.015907808939615884, 0.01591125170389811, 0.01591505209604899, 0.01592211882273356, 0.015930784543355305, 0.01594057559967041, 0.01595204830169678, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.015713796615600586, 0.015718808174133302, 0.015724544525146485, 0.015730746587117515, 0.015738277435302733, 0.015747995376586915, 0.015758605003356935, 0.015769494374593098, 0.015781833330790203, 0.015795060793558757, 0.015809059143066406, 0.01582390308380127, 0.01583947499593099, 0.015857481956481935, 0.01587692419687907, 0.015897302627563475, 0.01591862996419271, 0.015941235224405926, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015567847887674967, 0.015587035814921062, 0.015606733957926432, 0.01562670389811198, 0.015646831194559733, 0.015667335192362467, 0.015688608487447103, 0.015709891319274902, 0.015731345812479654, 0.015753366152445474, 0.0157755184173584, 0.015796871185302735, 0.01582026481628418, 0.015843766530354818, 0.015867781639099122, 0.015891745885213217, 0.015915886561075846, 0.015940260887145997, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017798911730448404, 0.01757530212402344, 0.01736984888712565, 0.0171813170115153, 0.01700859228769938, 0.016851258277893067, 0.01670842965443929, 0.016579383214314777, 0.016463624636332195, 0.016360686620076496, 0.016270480155944823, 0.016192682584126792, 0.016126596132914225, 0.016071949005126953, 0.016028620402018228, 0.015996395746866864, 0.01597523848215739, 0.01596465269724528, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016338276863098144, 0.016288026173909505, 0.016241180102030437, 0.01619925657908122, 0.01616048494974772, 0.01612304210662842, 0.016089078585306803, 0.016059513092041015, 0.01603561560312907, 0.016012837092081705, 0.015993162790934243, 0.015976870854695638, 0.015963929494222005, 0.01595427989959717, 0.015949776967366536, 0.015948634147644043, 0.015950530370076498, 0.015955994923909506, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015460395812988281, 0.015485663414001465, 0.015511271158854166, 0.015536996523539225, 0.015563023885091147, 0.015589796702067057, 0.01561683972676595, 0.01564372221628825, 0.015671277046203615, 0.0156985076268514, 0.015727025667826335, 0.015754235585530598, 0.015783503850301108, 0.0158130153020223, 0.015842978159586588, 0.015872872670491537, 0.015903293291727703, 0.015933938026428222, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017243868509928387, 0.017123998006184894, 0.01700881322224935, 0.016900275548299152, 0.016796170870463055, 0.016698627471923827, 0.016606930096944174, 0.016519894599914552, 0.016440774599711102, 0.01636734962463379, 0.016299023628234863, 0.01623661518096924, 0.016179664929707845, 0.016128660837809245, 0.016084628105163576, 0.016046039263407388, 0.016013380686442057, 0.015986356735229492, 0.015964024861653645], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016029095649719237, 0.016005477905273437, 0.015984468460083008, 0.015965439478556314, 0.015948721567789714, 0.015934789975484212, 0.015923264821370443, 0.015913902918497723, 0.015906100273132325, 0.01590119202931722, 0.015898009936014812, 0.015897968610127766, 0.015900386174519856, 0.015905749003092447, 0.01591324170430501, 0.015922651290893555, 0.01593456745147705, 0.01594853719075521, 0.015964024861653645], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-duorc_SelfRC_movie_director": [0.016625248591105143, 0.01654724597930908, 0.016475459734598796, 0.01640973091125488, 0.016349875132242838, 0.016295668284098307, 0.016246886253356935, 0.0162033748626709, 0.016164889335632326, 0.016130932172139487, 0.01610145568847656, 0.016076587041219077, 0.01605633576711019, 0.016040612856547037, 0.016029407183329264, 0.016022820472717286, 0.016020723978678385, 0.016022906303405762, 0.01602925141652425, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-quarel_testing_students": [0.015599570274353027, 0.015614852905273438, 0.01563065528869629, 0.015647029876708983, 0.015664045015970865, 0.01568177064259847, 0.015700260798136394, 0.015719536145528158, 0.01573957920074463, 0.01576038678487142, 0.015782135327657064, 0.01580527623494466, 0.015829744338989257, 0.015855034192403156, 0.01588129679361979, 0.015908934275309244, 0.01593829313913981, 0.01597016970316569, 0.01600394566853841, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is": [0.016054999033610025, 0.016037999788920086, 0.01602243900299072, 0.01600838343302409, 0.015995887120564777, 0.015985021591186522, 0.015975874265034995, 0.0159685214360555, 0.0159630552927653, 0.01595959981282552, 0.015958174069722494, 0.01595835526784261, 0.015960259437561033, 0.015964241027832032, 0.015970414479573567, 0.01597901185353597, 0.015990443229675293, 0.016004406611124674, 0.016020809809366862, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-quail_context_question_answer_description_id": [0.015255335172017416, 0.015291055043538412, 0.015327210426330567, 0.01536372979482015, 0.015400622685750326, 0.015437995592753093, 0.01547593911488851, 0.015514443715413412, 0.015553431510925293, 0.015592915217081706, 0.01563319524129232, 0.0156747039159139, 0.015717007319132486, 0.01575967311859131, 0.015803146362304687, 0.015847517649332683, 0.015893298784891763, 0.015940820376078288, 0.01598958651224772, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01604170322418213, 0.01602103074391683, 0.015998473167419435, 0.015975716908772787, 0.01595482349395752, 0.01593515872955322, 0.015922104517618815, 0.015911641120910643, 0.015907198588053385, 0.015905470848083497, 0.01590774377187093, 0.015914063453674316, 0.015925350189208983, 0.01593842347462972, 0.01595324198404948, 0.015971458752950033, 0.015990823109944662, 0.016014283498128255, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.017175539334615072, 0.017038040161132813, 0.01691317876180013, 0.016799513498942056, 0.016695311864217122, 0.01659983476003011, 0.01651285171508789, 0.016433984438578287, 0.016362814903259276, 0.016299039522806803, 0.016242454846700033, 0.016192878087361653, 0.01615019957224528, 0.01611437479654948, 0.016085615158081056, 0.01606410344441732, 0.01604933738708496, 0.01604118347167969, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.016548891067504883, 0.01647692680358887, 0.016412898699442544, 0.01635655721028646, 0.016305697758992512, 0.016263529459635415, 0.016224810282389323, 0.016189632415771486, 0.016158974965413412, 0.01613085428873698, 0.01610703150431315, 0.016085569063822427, 0.016070065498352052, 0.016055418650309246, 0.016044100125630695, 0.016036367416381835, 0.01603243350982666, 0.016034218470255535, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015981252988179526, 0.01596917788187663, 0.015958698590596516, 0.015949832598368328, 0.015942583084106444, 0.015936986605326334, 0.015933070182800293, 0.01593086083730062, 0.015930407842000324, 0.015931750933329266, 0.015934956868489582, 0.0159401273727417, 0.015947397549947104, 0.015956905682881672, 0.015968704223632814, 0.01598282019297282, 0.015999317169189453, 0.016018255551656087, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.015715422630310057, 0.01572194735209147, 0.01572940985361735, 0.015737876892089844, 0.0157473882039388, 0.015757994651794435, 0.01576974074045817, 0.015782726605733235, 0.015797228813171388, 0.015813541412353516, 0.015831352869669597, 0.015850319862365722, 0.01587077776590983, 0.015893065134684244, 0.015917261441548664, 0.0159439484278361, 0.015973401069641114, 0.016005276044209798, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015571961402893067, 0.015594730377197266, 0.015617895126342773, 0.015641549428304036, 0.015665613810221354, 0.015689868927001954, 0.01571426073710124, 0.015738879839579265, 0.0157636292775472, 0.01578853130340576, 0.015813976923624674, 0.015840457280476887, 0.015867398579915364, 0.01589392344156901, 0.0159209934870402, 0.015948861440022787, 0.015978283882141113, 0.016008599599202474, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01781531016031901, 0.017604554494222005, 0.017411948839823405, 0.017235174179077148, 0.017071552276611328, 0.0169213072458903, 0.01678516705830892, 0.016661314964294432, 0.016549312273661295, 0.016450681686401368, 0.01636406421661377, 0.016286530494689942, 0.016219933827718098, 0.01616478443145752, 0.016118655204772948, 0.01608328342437744, 0.016058955192565918, 0.016044516563415528, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016368025143941242, 0.01634445349375407, 0.01631950537363688, 0.01629527409871419, 0.016272761027018228, 0.016251161893208823, 0.016228823661804198, 0.016205652554829916, 0.016183196703592938, 0.01616223176320394, 0.01614252249399821, 0.016123967170715334, 0.01610685666402181, 0.01609141190846761, 0.01607767422993978, 0.01606560548146566, 0.016055204073588052, 0.01604651927947998, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.01546282450358073, 0.01549033800760905, 0.015517992973327637, 0.015545835494995117, 0.015574369430541992, 0.015603586832682292, 0.01563339074452718, 0.015663827260335286, 0.01569428602854411, 0.015725399653116864, 0.01575712998708089, 0.01578924020131429, 0.015822628339131672, 0.015856423377990723, 0.015890452067057293, 0.01592522462209066, 0.01596180280049642, 0.01600011984507243, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017247831026713054, 0.017134788831075033, 0.01702589193979899, 0.01692109743754069, 0.01682120482126872, 0.016726485888163247, 0.016637258529663086, 0.01655375321706136, 0.016475960413614908, 0.016404026349385578, 0.016338067054748537, 0.016278204917907716, 0.016224549611409504, 0.01617738405863444, 0.016136805216471355, 0.01610273043314616, 0.016075167655944824, 0.016054123242696127, 0.01603962262471517], "lorahub/flan_t5_large-race_middle_Taking_a_test+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016033233006795246, 0.01601345698038737, 0.015996311505635578, 0.01598127365112305, 0.01596794287363688, 0.015956586201985676, 0.01594751199086507, 0.015940791765848797, 0.01593657652537028, 0.015935060183207193, 0.015936290423075358, 0.015939671198527017, 0.015945062637329102, 0.015953001976013185, 0.015963603655497233, 0.015977187156677244, 0.015994836489359537, 0.016015653610229493, 0.01603962262471517], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-quarel_testing_students": [0.015599570274353027, 0.01562350591023763, 0.01564998149871826, 0.015679093996683758, 0.015710930824279785, 0.015745604832967122, 0.015783244768778484, 0.015823979377746582, 0.01586796760559082, 0.015915381113688152, 0.015966402689615886, 0.016021231015523274, 0.016080082257588703, 0.01614317576090495, 0.016210754712422688, 0.016283065478006998, 0.016360379854838052, 0.016442983945210776, 0.016531179745992025, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is": [0.016054999033610025, 0.0160542631149292, 0.016056350072224935, 0.016061363220214845, 0.016069385210673016, 0.016080479621887207, 0.016094686190287272, 0.01611204465230306, 0.01613265514373779, 0.016156682968139647, 0.016184377670288085, 0.016215968132019042, 0.016251603762308758, 0.01629135449727376, 0.016335301399230957, 0.016383584340413412, 0.016436452865600585, 0.01649420102437337, 0.016557079950968424, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-quail_context_question_answer_description_id": [0.015255335172017416, 0.01528925895690918, 0.015326620737711589, 0.015367472966512044, 0.01541189988454183, 0.015459993680318196, 0.015511906941731771, 0.015567800203959148, 0.01562785466512044, 0.015692267417907715, 0.015761233965555826, 0.01583496888478597, 0.015913693110148112, 0.015997629165649414, 0.01608702818552653, 0.01618213971455892, 0.016283230781555177, 0.016390592257181803, 0.01650451183319092, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01607728640238444, 0.01609118143717448, 0.01610231876373291, 0.0161124324798584, 0.016123571395874024, 0.016135889689127603, 0.016152911186218262, 0.0161728302637736, 0.01619923750559489, 0.016228049596150717, 0.016260662078857423, 0.016296574274698893, 0.01633620262145996, 0.01637781778971354, 0.016423301696777345, 0.01647174040476481, 0.01652098814646403, 0.016572065353393554, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.01719916820526123, 0.01708619435628255, 0.016987438201904296, 0.01690040111541748, 0.01682290236155192, 0.01675471623738607, 0.016695583661397298, 0.016645029385884604, 0.016603097915649415, 0.01656989574432373, 0.016545106569925944, 0.0165283203125, 0.01651929219563802, 0.016517945925394694, 0.016524259249369302, 0.01653817335764567, 0.016559664408365884, 0.016588683128356933, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.016581403414408367, 0.016542701721191405, 0.016512095133463543, 0.016489969889322918, 0.016472827593485513, 0.016460827191670736, 0.016457212766011555, 0.016454960505167645, 0.01645593007405599, 0.016460779507954916, 0.01646736780802409, 0.01647706190745036, 0.01648865858713786, 0.016502369244893393, 0.01652121067047119, 0.01654216766357422, 0.016565945943196613, 0.01659342130025228, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.016000507672627767, 0.0160085662206014, 0.01601913293202718, 0.01603227774302165, 0.01604811509450277, 0.01606675624847412, 0.016088326772054035, 0.016113003094991047, 0.01614091396331787, 0.016172137260437012, 0.016206663449605307, 0.016244503657023113, 0.01628595987955729, 0.016331337292989096, 0.016380866368611652, 0.01643479029337565, 0.016493344306945802, 0.01655675729115804, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.01572390874226888, 0.01574089527130127, 0.015760852495829265, 0.015783886909484863, 0.015810136795043946, 0.01583974520365397, 0.015872872670491537, 0.015909687678019205, 0.01595037619272868, 0.01599514325459798, 0.016044217745463052, 0.016097831726074218, 0.01615626017252604, 0.01621978759765625, 0.016288727124532065, 0.016363404591878256, 0.016444150606791177, 0.0165313196182251, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015569855372111002, 0.01559335708618164, 0.01562014897664388, 0.015650374094645182, 0.0156841770807902, 0.015721710522969563, 0.015763127009073893, 0.015808531443277995, 0.01585806210835775, 0.015911854108174642, 0.015970109303792317, 0.016033074061075847, 0.016101004282633464, 0.01617411454518636, 0.016252617835998535, 0.0163367223739624, 0.016426687240600587, 0.016522769927978517, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017834300994873046, 0.017643003463745116, 0.017469077110290526, 0.017313162485758465, 0.017171510060628257, 0.017043892542521158, 0.016931190490722656, 0.0168328857421875, 0.01674772262573242, 0.0166756804784139, 0.01661726156870524, 0.016573017438252766, 0.016542123158772785, 0.016523958841959636, 0.016518254280090332, 0.016525484720865884, 0.016545605659484864, 0.016578766504923504, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016353405316670736, 0.016320327123006184, 0.016291866302490233, 0.016271150906880697, 0.016255666414896647, 0.016242175102233886, 0.016233234405517577, 0.01623057683308919, 0.01623390833536784, 0.01624350388844808, 0.016259417533874512, 0.016281051635742186, 0.01630861759185791, 0.01634306271870931, 0.01638450622558594, 0.01643283526102702, 0.01648869514465332, 0.01655272642771403, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015465164184570312, 0.015497713088989258, 0.015533194541931153, 0.015571668942769368, 0.015613269805908204, 0.01565826733907064, 0.0157069460550944, 0.0157593043645223, 0.015815410614013672, 0.015875547726949057, 0.015939876238505044, 0.0160083532333374, 0.016081112225850423, 0.01615853945414225, 0.016240949630737304, 0.01632856527964274, 0.016421610514322917, 0.01652037779490153, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017268929481506348, 0.01717774709065755, 0.017090646425882976, 0.017009215354919435, 0.016934952735900878, 0.016867159207661946, 0.0168053404490153, 0.016750458081563314, 0.01670237382253011, 0.016661656697591145, 0.01662881056467692, 0.016603047053019206, 0.016583620707194012, 0.01657126744588216, 0.016566398938496908, 0.016569226582845053, 0.016579912503560383, 0.01659855842590332, 0.016625248591105143], "lorahub/flan_t5_large-duorc_SelfRC_movie_director+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016060732205708823, 0.01606868584950765, 0.016079521179199217, 0.016092979113260904, 0.01610868771870931, 0.01612648804982503, 0.016146488189697265, 0.016168961524963377, 0.016194202105204263, 0.01622239112854004, 0.01625361919403076, 0.016287926038106283, 0.01632535457611084, 0.01636602560679118, 0.016410133043924968, 0.01645790417989095, 0.01650956630706787, 0.016565300623575845, 0.016625248591105143], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is": [0.016054999033610025, 0.016022510528564453, 0.015990997950236004, 0.015960480372111004, 0.015930946667989096, 0.015902376174926756, 0.015874735514322915, 0.015847973823547364, 0.0158220640818278, 0.015796995162963866, 0.015772802035013835, 0.015749524434407552, 0.015727216402689616, 0.015705924034118652, 0.015685663223266602, 0.015666437149047852, 0.01564823627471924, 0.015631036758422853, 0.015614824295043945, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-quail_context_question_answer_description_id": [0.015255335172017416, 0.015279536247253417, 0.015303109486897786, 0.015326050122578939, 0.015348329544067382, 0.01536995569864909, 0.015390907923380534, 0.015411184628804525, 0.015430773099263509, 0.015449668566385905, 0.015467872619628906, 0.015485367774963378, 0.015502163569132487, 0.015518240928649903, 0.015533609390258789, 0.015548256238301595, 0.01556218147277832, 0.01557537873586019, 0.01558784008026123, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016021726926167806, 0.015980548858642578, 0.01593734900156657, 0.01589403788248698, 0.015852762858072918, 0.015813430150349934, 0.015780010223388673, 0.015749618212381997, 0.015725824038187664, 0.01570424556732178, 0.01568598747253418, 0.015670461654663084, 0.015657671292622886, 0.015645941098531086, 0.015635175704956053, 0.015626233418782554, 0.015617615381876627, 0.015608766873677571, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.017147332827250162, 0.01698303540547689, 0.01683340549468994, 0.016695523262023927, 0.01656718095143636, 0.016448143323262533, 0.016338191032409667, 0.016236728032430012, 0.016143442789713542, 0.016058193842569988, 0.015980594952901203, 0.01591012636820475, 0.015846498807271323, 0.01578956445058187, 0.01573915481567383, 0.015695082346598308, 0.015657200813293456, 0.015625389417012532, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.01652681032816569, 0.01643364429473877, 0.01634871006011963, 0.016272352536519367, 0.016201578776041666, 0.01613634745279948, 0.01607954184214274, 0.016024519602457682, 0.015972690582275392, 0.01592458407084147, 0.01587864398956299, 0.015835498174031574, 0.015794706344604493, 0.015755964914957683, 0.01571951707204183, 0.015686291058858236, 0.015655345916748047, 0.015626422564188638, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015963517824808756, 0.0159332005182902, 0.01590407689412435, 0.015876077016194663, 0.015849299430847168, 0.015823979377746582, 0.0157998259862264, 0.0157767645517985, 0.015755016009012857, 0.015734464327494303, 0.015715071360270182, 0.015696829160054524, 0.015679707527160646, 0.015663703282674152, 0.015648786226908365, 0.01563494046529134, 0.01562215010325114, 0.015610370635986328, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.015709234873453777, 0.015708189010620117, 0.015706620216369628, 0.015704522132873534, 0.015701874097188314, 0.01569864749908447, 0.015694835980733235, 0.0156904141108195, 0.015685367584228515, 0.015679691632588703, 0.01567336400349935, 0.015666391054789227, 0.015658756891886394, 0.015650477409362793, 0.015641543070475262, 0.015631969769795737, 0.015621771812438965, 0.015610963503519693, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015556255976359049, 0.015562745730082194, 0.015568973223368327, 0.015574893951416015, 0.01558046817779541, 0.015585657755533854, 0.015590410232543945, 0.015594669977823893, 0.015598392486572266, 0.015601539611816406, 0.0156040620803833, 0.015605950355529785, 0.015607158342997232, 0.015607681274414063, 0.015607495307922364, 0.015606597264607747, 0.01560497760772705, 0.015602633158365886, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01778309981028239, 0.017541839281717937, 0.01731917858123779, 0.0171148157119751, 0.016924818356831867, 0.01674916426340739, 0.016588414510091146, 0.016442076365152995, 0.016308695475260416, 0.016187834739685058, 0.016079095204671223, 0.015982659657796223, 0.0158974822362264, 0.015823124249776204, 0.015759270985921225, 0.015705272356669107, 0.015660770734151206, 0.01562557856241862, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.01632957617441813, 0.016269963582356772, 0.01621220588684082, 0.016158092816670737, 0.01610685666402181, 0.016055930455525717, 0.016006280581156412, 0.01595978260040283, 0.015916199684143068, 0.015875546137491862, 0.015836798350016276, 0.015800426801045736, 0.015765533447265626, 0.015732107162475587, 0.01570084095001221, 0.0156720765431722, 0.01564572016398112, 0.015621585845947266, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015449755986531576, 0.015463469823201497, 0.015476593971252442, 0.015489099820454915, 0.015500961939493815, 0.015512196222941081, 0.015522855122884115, 0.015533005396525065, 0.015542588233947753, 0.015551517804463705, 0.015559746424357096, 0.015567269325256348, 0.015574096043904622, 0.015580228169759115, 0.015585635503133138, 0.0155902894337972, 0.015594166119893392, 0.015597256024678548, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017216657002766925, 0.017072898546854655, 0.016932633717854816, 0.01679861068725586, 0.016671617825826008, 0.016550180117289225, 0.016435407002766928, 0.01632791042327881, 0.01622769832611084, 0.016134467124938965, 0.01604815642038981, 0.015968453089396158, 0.01589566707611084, 0.01582940896352132, 0.015769859949747722, 0.01571717898050944, 0.01567131042480469, 0.015632136662801107, 0.015599570274353027], "lorahub/flan_t5_large-quarel_testing_students+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016015307108561198, 0.015977023442586263, 0.015940759976704914, 0.015906392733256024, 0.01587374210357666, 0.015842688878377278, 0.015813220342000327, 0.015785401662190755, 0.015759331385294596, 0.015735057195027668, 0.01571261723836263, 0.01569200356801351, 0.015673220952351886, 0.01565627892812093, 0.015641180674235027, 0.01562794844309489, 0.015616593360900878, 0.015607132911682128, 0.015599570274353027], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-quail_context_question_answer_description_id": [0.015255335172017416, 0.015290082295735677, 0.01532574494679769, 0.015362257957458497, 0.015399595896402996, 0.01543776830037435, 0.01547681967417399, 0.01551676114400228, 0.015557586352030436, 0.01559925397237142, 0.015641692479451498, 0.01568483829498291, 0.015728654861450194, 0.015773127873738607, 0.015818289120992025, 0.01586415449778239, 0.015910757382710774, 0.01595810890197754, 0.016006189982096353, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01605016867319743, 0.016036667823791505, 0.016020447413126627, 0.016003737449645995, 0.015988890329996744, 0.015975348154703774, 0.015968019167582195, 0.015962964693705242, 0.0159634002049764, 0.015965245564778647, 0.015970565478006998, 0.01597825845082601, 0.01598743756612142, 0.015997482935587566, 0.016010061899820963, 0.016022183100382486, 0.0160335381825765, 0.016044487953186037, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.017180202802022298, 0.017046511967976886, 0.016924115816752117, 0.016812524795532226, 0.016710596084594728, 0.016617538134257, 0.01653273423512777, 0.016455726623535158, 0.016386233965555826, 0.0163239844640096, 0.016268744468688964, 0.01622028668721517, 0.01617837905883789, 0.01614280859629313, 0.016113409996032713, 0.016090025901794435, 0.0160725466410319, 0.016060889561971027, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.01654937744140625, 0.016478134791056316, 0.01641576608022054, 0.016361478169759115, 0.016313184102376303, 0.016273671785990398, 0.01623781363169352, 0.016205894152323406, 0.01617844581604004, 0.016153828303019205, 0.016132235527038574, 0.016113382975260417, 0.016097288131713867, 0.0160847536722819, 0.01607519785563151, 0.01606706142425537, 0.016060754458109536, 0.016056683858235676, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.01598433971405029, 0.01597527027130127, 0.01596768856048584, 0.015961639086405435, 0.015957132975260416, 0.015954143206278484, 0.01595269997914632, 0.01595283508300781, 0.015954511960347494, 0.015957573254903157, 0.015962082544962564, 0.015968208312988282, 0.015975958506266277, 0.015985293388366698, 0.015996187527974447, 0.016008620262145997, 0.016022572517395018, 0.016038036346435545, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.015715635617574056, 0.01572281201680501, 0.015731345812479654, 0.0157412322362264, 0.01575249195098877, 0.015765105883280436, 0.0157790740331014, 0.015794386863708498, 0.015811033248901367, 0.015829011599222818, 0.015848344167073567, 0.015869043668111166, 0.015891159375508626, 0.015914710362752278, 0.015939745903015137, 0.01596627394358317, 0.015994321505228677, 0.016023893356323243, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015575116475423176, 0.015600949923197428, 0.01562704881032308, 0.015653425852457683, 0.0156800651550293, 0.015706915855407715, 0.015733896891276043, 0.015760947863260905, 0.01578801949818929, 0.01581506093343099, 0.015842045148213704, 0.01586892286936442, 0.015895676612854005, 0.015922334988911945, 0.01594891389211019, 0.015975448290507, 0.01600197156270345, 0.016028494834899903, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01782590389251709, 0.017624661127726236, 0.017440182367960612, 0.01727148691813151, 0.0171147092183431, 0.01696983019510905, 0.016837746302286783, 0.016717661221822104, 0.01660841147104899, 0.016509863535563152, 0.016422460873921713, 0.01634533405303955, 0.01627808411916097, 0.016219813028971353, 0.016169932683308918, 0.016128656069437662, 0.016095860799153646, 0.016071364084879556, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.01634310563405355, 0.016298735936482747, 0.016256988843282062, 0.016218676567077636, 0.01618428707122803, 0.016153903007507325, 0.016126480102539063, 0.016101845105489097, 0.016080098152160646, 0.01606152057647705, 0.016046853065490724, 0.01603594144185384, 0.016028483708699543, 0.016024112701416016, 0.016023276646931966, 0.016025964419047037, 0.01603215217590332, 0.01604183832804362, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015459165573120118, 0.015483840306599935, 0.015509454409281413, 0.01553598403930664, 0.015563535690307616, 0.015592363675435384, 0.015622412363688151, 0.01565349578857422, 0.015685652097066242, 0.015718963940938312, 0.015753307342529298, 0.0157884422938029, 0.015824249585469564, 0.01586076259613037, 0.015898027420043946, 0.015936067899068197, 0.015974895159403483, 0.016014528274536134, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.01725290616353353, 0.017145280838012696, 0.017041122118632, 0.01694052537282308, 0.016845091183980306, 0.016754721005757648, 0.01666866461435954, 0.01658820629119873, 0.016512999534606932, 0.01644368330637614, 0.0163794740041097, 0.0163210391998291, 0.01626772403717041, 0.016219140688578288, 0.016175983746846517, 0.016138129234313965, 0.01610542138417562, 0.01607774575551351, 0.016054999033610025], "lorahub/flan_t5_large-adversarial_qa_droberta_tell_what_it_is+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016046282450358072, 0.01603831926981608, 0.016031673749287923, 0.016026069323221842, 0.016021310488382977, 0.01601738452911377, 0.016014374097188314, 0.016012341181437174, 0.01601133664449056, 0.01601136048634847, 0.016012360254923502, 0.016014307339986166, 0.016017176310221353, 0.01602098306020101, 0.01602575937906901, 0.01603152592976888, 0.01603831132253011, 0.016046133041381836, 0.016054999033610025], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.015989530881245932, 0.01591818332672119, 0.01584660530090332, 0.015776483217875163, 0.015709773699442545, 0.015646297136942544, 0.015589588483174642, 0.01553758144378662, 0.015493000348409017, 0.015452264149983724, 0.01541614850362142, 0.015384629567464192, 0.015357468922932943, 0.015333326657613118, 0.01531202793121338, 0.015294322967529297, 0.015279037157694499, 0.01526613712310791, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.017127609252929686, 0.016943890253702798, 0.01677509625752767, 0.01661820729573568, 0.016470867792765298, 0.016333001454671224, 0.016204444567362468, 0.016084513664245605, 0.015972967147827147, 0.015869537989298504, 0.015773770014444986, 0.015685405731201172, 0.015604182879130046, 0.015529837608337402, 0.015462174415588378, 0.015401027997334798, 0.015346253712972005, 0.015297725995381673, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.016509822209676107, 0.016398873329162598, 0.01629547437032064, 0.01620044549306234, 0.016110679308573406, 0.016026523907979328, 0.015950493812561035, 0.01587645212809245, 0.015805869102478026, 0.015739283561706542, 0.015675125122070314, 0.015613986651102701, 0.015555071830749511, 0.015498469670613607, 0.015444226264953613, 0.015393223762512207, 0.015344667434692382, 0.015298678080240885, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015950547854105632, 0.015906718571980793, 0.01586343765258789, 0.015820757548014323, 0.015778651237487794, 0.015737169583638508, 0.015696481068929038, 0.015656361579895018, 0.015616833368937174, 0.015578099886576335, 0.015540016492207846, 0.015502500534057616, 0.015465547243754069, 0.01542916774749756, 0.015393376350402832, 0.015358160336812338, 0.015323445002237956, 0.015289142926534017, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.015696353912353515, 0.015681784947713218, 0.015666074752807617, 0.015649210611979165, 0.015631192525227863, 0.015612009366353354, 0.015591654777526855, 0.015570127169291178, 0.015547415415445964, 0.015523524284362792, 0.015498442649841309, 0.015472175280253093, 0.015444717407226562, 0.015416062672932943, 0.015386219024658204, 0.015355197588602702, 0.015323017438252767, 0.015289716720581055, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015536934534708658, 0.015524172782897949, 0.015511236190795898, 0.015498089790344238, 0.015484716097513835, 0.015471080144246419, 0.01545713742574056, 0.01544285774230957, 0.015428199768066406, 0.015413126945495605, 0.015397613843282063, 0.015381642977396647, 0.015365174611409505, 0.015348210334777831, 0.015330718358357748, 0.015312689145406087, 0.015294119517008464, 0.0152750031153361, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01776069164276123, 0.0174983549118042, 0.017255039215087892, 0.017030906677246094, 0.0168220853805542, 0.016628004709879556, 0.0164486821492513, 0.016284344991048177, 0.01613359769185384, 0.015995440483093263, 0.015869598388671875, 0.01575567404429118, 0.015653664271036784, 0.015562343597412109, 0.015481355985005697, 0.015410539309183756, 0.015349486668904622, 0.015297840436299642, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.01632137457529704, 0.016252868970235188, 0.016185191472371418, 0.016119847297668456, 0.0160565980275472, 0.015992492039998373, 0.015928467114766438, 0.015866125424702962, 0.015805424054463703, 0.0157463534673055, 0.015688608487447103, 0.01563159783681234, 0.01557523250579834, 0.015519237518310547, 0.015464210510253906, 0.015410486857096355, 0.015357834498087565, 0.01530609130859375, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.01542836348215739, 0.015420969327290852, 0.015413285891215007, 0.01540529727935791, 0.015397003491719564, 0.015388453801472982, 0.01537974198659261, 0.015370901425679524, 0.015361839930216472, 0.015352460543314616, 0.015342758496602377, 0.015332752863566081, 0.015322472254435221, 0.015311948458353679, 0.015301170349121094, 0.015290131568908691, 0.015278816223144531, 0.015267217953999837, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017202359835306803, 0.01704394817352295, 0.016888964970906577, 0.016739174524943033, 0.016595789591471354, 0.016458357175191243, 0.016326192220052084, 0.01620082378387451, 0.016081819534301756, 0.01597014904022217, 0.015865135192871093, 0.01576679229736328, 0.015674643516540528, 0.015589071909586588, 0.015509656270345052, 0.015436569849650065, 0.015369906425476074, 0.015309483210245767, 0.015255335172017416], "lorahub/flan_t5_large-quail_context_question_answer_description_id+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.01599270184834798, 0.01593250274658203, 0.01587497552235921, 0.015819954872131347, 0.015767199198404948, 0.015716541608174643, 0.0156679630279541, 0.015621536572774252, 0.015577327410380046, 0.015535367329915365, 0.015495632489522298, 0.015458086331685383, 0.015422693888346354, 0.01538943608601888, 0.015358311335245768, 0.015329325993855794, 0.015302497545878093, 0.015277827580769857, 0.015255335172017416], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-wmt16_translate_ro-en": [0.017324058214823405, 0.017200268109639486, 0.017082672119140625, 0.016972788174947104, 0.01687065919240316, 0.016776119867960612, 0.016685962677001953, 0.01660361925760905, 0.01652778148651123, 0.016457722981770832, 0.01639300346374512, 0.0163364839553833, 0.016285486221313476, 0.016241574287414552, 0.016204706827799478, 0.016171778043111165, 0.016142803827921548, 0.01611559232076009, 0.016088202794392905, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.016535091400146484, 0.01644944985707601, 0.016371089617411294, 0.01629957358042399, 0.016234768231709797, 0.016176641782124836, 0.016125327746073406, 0.016081045468648275, 0.01604408582051595, 0.01601467450459798, 0.015992801984151206, 0.01597870667775472, 0.015972517331441245, 0.015973715782165526, 0.01598151365915934, 0.01599496046702067, 0.016012981732686362, 0.01603457768758138, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015989335378011067, 0.01598265329996745, 0.015974984169006348, 0.015966838200887044, 0.01595915635426839, 0.015951670010884603, 0.015943862597147623, 0.015940368970235187, 0.01593862533569336, 0.015939366022745767, 0.015944012006123862, 0.015949767430623374, 0.015961527824401855, 0.015977174441019693, 0.01599488099416097, 0.01601393540700277, 0.016032222112019857, 0.01604783852895101, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.01571339766184489, 0.015716962814331055, 0.015720553398132324, 0.015723700523376464, 0.015728643735249837, 0.015735867818196615, 0.0157438596089681, 0.015754714012145996, 0.0157678492863973, 0.015784470240275066, 0.01580295403798421, 0.015827873547871907, 0.015855539639790854, 0.015888492266337078, 0.015923155148824055, 0.0159593931833903, 0.015995267232259115, 0.016029011408487955, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015570216178894043, 0.015590004920959473, 0.015609431266784667, 0.015628272692362468, 0.01564652442932129, 0.015665062268575034, 0.01568450450897217, 0.015704997380574546, 0.015727739334106445, 0.015752107302347818, 0.01577892780303955, 0.015809650421142577, 0.015843857129414878, 0.015881460507710776, 0.015920111338297526, 0.015959386825561524, 0.015996974309285483, 0.016030821800231933, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017831576665242512, 0.01763435999552409, 0.017449897130330405, 0.017278186480204263, 0.01712007522583008, 0.016974089940388997, 0.016840009689331054, 0.01671810309092204, 0.016608867645263672, 0.01651186148325602, 0.01642582893371582, 0.016352407137552896, 0.01628976027170817, 0.01623664697011312, 0.01619182586669922, 0.01615343729654948, 0.016119693120320636, 0.016088746388753256, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016338682174682616, 0.016288414001464843, 0.01624009132385254, 0.016195106506347656, 0.016155484517415365, 0.016116687456766764, 0.016080617904663086, 0.016050613721211752, 0.016025455792744954, 0.01600651741027832, 0.015993984540303548, 0.015985854466756187, 0.01598345915476481, 0.01598946253458659, 0.015998870531717935, 0.01601255257924398, 0.016028350194295247, 0.016044332186381023, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015440783500671386, 0.015447624524434407, 0.015456144014994304, 0.015466534296671549, 0.015478704770406087, 0.015494112968444823, 0.015512216885884602, 0.01553386688232422, 0.015559897422790528, 0.015588808059692382, 0.015624661445617676, 0.015665396054585775, 0.015711771647135418, 0.01576362450917562, 0.01581979751586914, 0.015879109700520835, 0.015939906438191733, 0.016000436147054035, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017235875129699707, 0.017110379536946614, 0.016987010637919107, 0.016870729128519692, 0.016762367884318032, 0.016661647160847982, 0.016569137573242188, 0.01648505210876465, 0.016411070823669435, 0.016345117886861164, 0.016288878122965495, 0.016238540013631186, 0.016196449597676594, 0.016163489023844402, 0.01613548755645752, 0.01611235459645589, 0.016092785199483237, 0.01607537269592285, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.01603525479634603, 0.01601625601450602, 0.01599870204925537, 0.015982850392659505, 0.015968839327494305, 0.015956673622131348, 0.015946747461954753, 0.01594020366668701, 0.01593648592631022, 0.0159366766611735, 0.01593985398610433, 0.01594847838083903, 0.015959288279215497, 0.015975882212320963, 0.015993405977884928, 0.016012312571207683, 0.016030553181966146, 0.016046563784281414, 0.016058756510416668], "lorahub/flan_t5_large-wmt16_translate_ro-en+lorahub/flan_t5_large-wiki_hop_original_generate_subject": [0.01662901242574056, 0.01657861550649007, 0.01654133637746175, 0.016515525182088216, 0.016502896944681805, 0.016499091784159342, 0.01650376637776693, 0.0165188201268514, 0.016541274388631184, 0.016569833755493164, 0.01660470644632975, 0.016646868387858074, 0.016696925163269042, 0.016756391525268553, 0.016825273831685385, 0.016901321411132812, 0.016987245877583823, 0.017084824244181316, 0.017197694778442383, 0.017324058214823405], "lorahub/flan_t5_large-wmt16_translate_ro-en+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.01599654833475749, 0.016004789670308432, 0.016019641558329266, 0.016041185061136883, 0.016069496472676595, 0.016104793548583983, 0.01614725907643636, 0.01619696299235026, 0.016254041989644367, 0.016318748792012533, 0.016391445795694987, 0.016472530364990235, 0.016562442779541015, 0.016661556561787923, 0.016770366032918295, 0.016889928181966146, 0.01702176094055176, 0.017166824340820314, 0.017324058214823405], "lorahub/flan_t5_large-wmt16_translate_ro-en+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.01572809378306071, 0.0157524045308431, 0.015782826741536457, 0.015819501876831055, 0.015862614313761392, 0.01591238021850586, 0.0159690523147583, 0.01603282610575358, 0.016103851000467937, 0.016182411511739096, 0.016268973350524903, 0.01636413892110189, 0.01646848996480306, 0.016582330067952473, 0.01670576572418213, 0.016839939753214517, 0.016987083752950032, 0.017149070103963215, 0.017324058214823405], "lorahub/flan_t5_large-wmt16_translate_ro-en+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015581549008687337, 0.015619091987609864, 0.015662296613057455, 0.015711345672607423, 0.015766423543294272, 0.015827701886494953, 0.01589521884918213, 0.015968963305155435, 0.016049321492513022, 0.016136878331502277, 0.0162318754196167, 0.016334547996520996, 0.016445512771606444, 0.0165653657913208, 0.01669428825378418, 0.016832547187805177, 0.01698245366414388, 0.017147005399068195, 0.017324058214823405], "lorahub/flan_t5_large-wmt16_translate_ro-en+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01789144198099772, 0.01775377909342448, 0.017630688349405923, 0.01752143700917562, 0.017423750559488933, 0.01733797550201416, 0.017264202435811362, 0.01720308303833008, 0.01715372403462728, 0.0171159823735555, 0.01709100882212321, 0.01707672913869222, 0.017074076334635417, 0.01708370844523112, 0.01710568428039551, 0.017140604654947916, 0.017189178466796875, 0.017250658671061198, 0.017324058214823405], "lorahub/flan_t5_large-wmt16_translate_ro-en+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016380103429158528, 0.01637493133544922, 0.0163751220703125, 0.016380726496378582, 0.016392175356547037, 0.016410009066263834, 0.016434450149536133, 0.01646535555521647, 0.016503849029541016, 0.016549100875854494, 0.01660115400950114, 0.016660736401875813, 0.016728181838989258, 0.01680383523305257, 0.016888262430826823, 0.01698198954264323, 0.01708559989929199, 0.017199641863505047, 0.017324058214823405], "lorahub/flan_t5_large-wmt16_translate_ro-en+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015472089449564616, 0.01551447868347168, 0.015562726656595865, 0.0156169589360555, 0.01567725658416748, 0.015743783315022786, 0.015816887219746906, 0.01589704990386963, 0.015984654426574707, 0.016079646746317545, 0.016181801160176593, 0.016291367212931316, 0.016408999760945637, 0.01653535842895508, 0.016671005884806314, 0.016815495491027833, 0.016971173286437987, 0.017141408920288086, 0.017324058214823405], "lorahub/flan_t5_large-wmt16_translate_ro-en+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.01727645715077718, 0.01719558080037435, 0.017122693061828613, 0.01705774784088135, 0.017001489003499348, 0.01695463975270589, 0.0169173002243042, 0.016889527638753257, 0.016871236165364584, 0.01686259905497233, 0.01686500867207845, 0.01687882900238037, 0.01690369447072347, 0.01694028377532959, 0.01698965867360433, 0.01705231825510661, 0.017128893534342448, 0.017219661076863606, 0.017324058214823405], "lorahub/flan_t5_large-wmt16_translate_ro-en+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016077694892883302, 0.016104354858398437, 0.016135544776916505, 0.016171212196350097, 0.016211436589558918, 0.016256291071573892, 0.016305754979451498, 0.01635977586110433, 0.01641844113667806, 0.01648211638132731, 0.016550930341084798, 0.016624817848205565, 0.0167044464747111, 0.01678988297780355, 0.016880982716878254, 0.016978540420532227, 0.017084391911824544, 0.017200212478637695, 0.017324058214823405], "lorahub/flan_t5_large-wiki_hop_original_generate_subject+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.016001041730244955, 0.016009033521016437, 0.016019047101338703, 0.016031373341878256, 0.016045721371968587, 0.01606261094411214, 0.016080082257588703, 0.016102237701416014, 0.016126844088236492, 0.016154112815856932, 0.016184414227803548, 0.01621869087219238, 0.016256974538167317, 0.016298240025838216, 0.016349822680155435, 0.016407230695088704, 0.01647209167480469, 0.016546176274617512, 0.01662901242574056], "lorahub/flan_t5_large-wiki_hop_original_generate_subject+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.015725606282552082, 0.015743794441223143, 0.015764222145080567, 0.015786361694335938, 0.015811546643575033, 0.015840752919514974, 0.015872282981872557, 0.01590625603993734, 0.015944034258524576, 0.01598461945851644, 0.016029674212137857, 0.01607891877492269, 0.016131075223286946, 0.016192917823791505, 0.016261871655782065, 0.016338144938151042, 0.016424811681111654, 0.016521460215250652, 0.01662901242574056], "lorahub/flan_t5_large-wiki_hop_original_generate_subject+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015563247998555501, 0.015581170717875162, 0.01560362974802653, 0.015630324681599934, 0.015661250750223794, 0.01569612503051758, 0.01573599179585775, 0.01577996095021566, 0.01582753817240397, 0.015879915555318196, 0.015936837196350098, 0.015998953183492023, 0.016064243316650392, 0.016139292716979982, 0.016220507621765138, 0.016307918230692546, 0.016405731836954752, 0.016512346267700196, 0.01662901242574056], "lorahub/flan_t5_large-wiki_hop_original_generate_subject+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017827598253885905, 0.017632048924764, 0.017453786532084146, 0.017294804255167644, 0.017152101198832193, 0.017023855845133464, 0.01691002051035563, 0.016810340881347655, 0.016724344889322916, 0.016651536623636883, 0.01659190018971761, 0.01654451370239258, 0.016512393951416016, 0.016494139035542806, 0.01648959795633952, 0.016498748461405435, 0.01652572790781657, 0.01656882921854655, 0.01662901242574056], "lorahub/flan_t5_large-wiki_hop_original_generate_subject+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.0163785187403361, 0.016366853713989257, 0.016357181866963704, 0.016352732976277668, 0.01634768803914388, 0.01634331226348877, 0.016341238021850585, 0.016341768900553385, 0.01634681224822998, 0.016351950963338215, 0.016360909144083658, 0.016374762852986655, 0.01639121691385905, 0.016410694122314454, 0.016439259847005207, 0.016473843256632488, 0.016517106691996256, 0.01656898021697998, 0.01662901242574056], "lorahub/flan_t5_large-wiki_hop_original_generate_subject+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015471522013346355, 0.015509969393412272, 0.015550767580668132, 0.015593848228454589, 0.01563883145650228, 0.01568638483683268, 0.015736440022786458, 0.015788551966349283, 0.01584297021230062, 0.015900346438090008, 0.015960715611775717, 0.016023640632629396, 0.01609037399291992, 0.01616459051767985, 0.01624384085337321, 0.016328112284342448, 0.016421262423197427, 0.01652106285095215, 0.01662901242574056], "lorahub/flan_t5_large-wiki_hop_original_generate_subject+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.01725289026896159, 0.0171460755666097, 0.017044377326965333, 0.016950696309407553, 0.016864166259765626, 0.01678633689880371, 0.01671630541483561, 0.01665504773457845, 0.016601705551147462, 0.016557393074035646, 0.01652233600616455, 0.01649693489074707, 0.01648170789082845, 0.016474809646606445, 0.01648244063059489, 0.016500137646993002, 0.016530125935872397, 0.016573182741800942, 0.01662901242574056], "lorahub/flan_t5_large-wiki_hop_original_generate_subject+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016060733795166017, 0.016068922678629558, 0.016079851786295573, 0.016092756589253743, 0.016108099619547525, 0.016126319567362466, 0.016146725018819173, 0.016168087323506674, 0.016191887855529784, 0.016218458811442057, 0.01624646027882894, 0.016277011235555014, 0.016313082377115887, 0.016352556546529135, 0.01639649550120036, 0.016444905598958334, 0.016500428517659507, 0.01656122843424479, 0.01662901242574056], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-web_questions_get_the_answer": [0.015709789594014485, 0.01571593443552653, 0.0157229216893514, 0.015730772018432617, 0.01573949972788493, 0.01574912707010905, 0.015759674708048503, 0.015771164894104003, 0.015783621470133465, 0.01579710642496745, 0.015811700820922852, 0.015827530225118, 0.015844480196634928, 0.01586241881052653, 0.015881563822428387, 0.015901945432027182, 0.015923423767089842, 0.015946091016133625, 0.015969926516215007, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015575310389200847, 0.015600956281026205, 0.015626649856567382, 0.015652213096618652, 0.015677345593770344, 0.01570207118988037, 0.015726499557495117, 0.015750589370727538, 0.015774281819661458, 0.01579762140909831, 0.015820751190185545, 0.015843876202901206, 0.015866535504659017, 0.015888837178548176, 0.01591090679168701, 0.0159325647354126, 0.015953817367553712, 0.01597460905710856, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017802931467692056, 0.017580647468566895, 0.017379131317138672, 0.017193695704142253, 0.017022849718729655, 0.016867535909016927, 0.0167269770304362, 0.01659940242767334, 0.016485732396443686, 0.01638526439666748, 0.01629781405131022, 0.016221300760904948, 0.016156058311462402, 0.016102437973022462, 0.016059595743815103, 0.016027940114339192, 0.016006709734598796, 0.01599575360616048, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016342077255249023, 0.016296448707580565, 0.016253223419189455, 0.0162141482035319, 0.01617948532104492, 0.016147899627685546, 0.016117734909057616, 0.01608949343363444, 0.016064459482828777, 0.01604280153910319, 0.016024408340454103, 0.016009400685628256, 0.015997891426086427, 0.015989727973937988, 0.01598470369974772, 0.015982702573140464, 0.015983710289001463, 0.015987764994303384, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015460004806518554, 0.015484967231750489, 0.015510300000508626, 0.015536135037740071, 0.015562950770060221, 0.015590295791625977, 0.015618319511413575, 0.015647041002909343, 0.015675857861836753, 0.015705111821492514, 0.01573499361673991, 0.01576551914215088, 0.015796771049499513, 0.015828735033671062, 0.015860913594563802, 0.01589380423227946, 0.015927062034606934, 0.015960795084635417, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.01724730968475342, 0.017133644421895345, 0.01702381451924642, 0.01691789150238037, 0.016817035675048827, 0.016721715927124025, 0.01663188616434733, 0.01654751777648926, 0.016468286514282227, 0.016394678751627603, 0.016327072779337565, 0.016265269915262857, 0.016209432284037272, 0.016159512201944986, 0.016115368207295734, 0.01607689380645752, 0.016044020652770996, 0.016016705830891927, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.01603814125061035, 0.016022971471150716, 0.0160097074508667, 0.015997606913248696, 0.015986639658610025, 0.01597706158955892, 0.015968977610270184, 0.015962406794230142, 0.015957404772440592, 0.01595415751139323, 0.01595271110534668, 0.015952642758687338, 0.015954055786132813, 0.01595704396565755, 0.015961519877115884, 0.01596751848856608, 0.015975125630696616, 0.015984257062276203, 0.01599491755167643], "lorahub/flan_t5_large-web_questions_get_the_answer+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015557357470194499, 0.015565471649169922, 0.01557384967803955, 0.01558248202006022, 0.015591328938802083, 0.015600330034891764, 0.015609401067097982, 0.015618462562561036, 0.015627463658650715, 0.015636364618937176, 0.015645146369934082, 0.015653812090555826, 0.01566234270731608, 0.015670723915100097, 0.015678941408793133, 0.015686969757080078, 0.015694797833760578, 0.015702409744262694, 0.015709789594014485], "lorahub/flan_t5_large-web_questions_get_the_answer+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.017779301007588705, 0.017536191940307616, 0.017312866846720378, 0.01710959275563558, 0.016922386487325032, 0.016750804583231606, 0.016594854990641277, 0.01645418643951416, 0.016327187220255533, 0.01621313254038493, 0.016111737887064617, 0.01602331320444743, 0.0159466552734375, 0.015881670316060383, 0.015827182133992514, 0.015782820383707683, 0.015748610496520998, 0.015724331537882486, 0.015709789594014485], "lorahub/flan_t5_large-web_questions_get_the_answer+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.01632871468861898, 0.01626954396565755, 0.016213011741638184, 0.01616024335225423, 0.0161113977432251, 0.01606508731842041, 0.016020522117614747, 0.01597859541575114, 0.01594075361887614, 0.01590591748555501, 0.01587378978729248, 0.015844372113545734, 0.015818082491556803, 0.015794164339701336, 0.015772403081258136, 0.015752987861633302, 0.01573607126871745, 0.015721688270568846, 0.015709789594014485], "lorahub/flan_t5_large-web_questions_get_the_answer+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015457324981689453, 0.015478423436482747, 0.01549871285756429, 0.015518134435017903, 0.01553669770558675, 0.015554553667704264, 0.015571786562601725, 0.015588239034016927, 0.01560382843017578, 0.01561859130859375, 0.015632546742757162, 0.01564555803934733, 0.01565754254659017, 0.01566850980122884, 0.015678547223409018, 0.015687689781188965, 0.015695939064025877, 0.015703301429748535, 0.015709789594014485], "lorahub/flan_t5_large-web_questions_get_the_answer+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017214962641398112, 0.017070949872334797, 0.01693171501159668, 0.016799476941426594, 0.016675202051798503, 0.01655795892079671, 0.016447755495707195, 0.0163454008102417, 0.016251222292582194, 0.01616516590118408, 0.016086252530415852, 0.016014533042907717, 0.01594979445139567, 0.015892410278320314, 0.015842173894246418, 0.015798888206481933, 0.015762475331624348, 0.015732819239298503, 0.015709789594014485], "lorahub/flan_t5_large-web_questions_get_the_answer+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.01601938565572103, 0.015985762278238932, 0.015954659779866535, 0.01592593828837077, 0.015899357795715333, 0.015874698956807456, 0.015851823488871257, 0.01583067258199056, 0.01581123352050781, 0.01579350471496582, 0.015777478218078612, 0.015763160387674967, 0.015750544865926107, 0.015739622116088866, 0.015730371475219728, 0.015722777048746747, 0.01571681340535482, 0.01571249008178711, 0.015709789594014485], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-word_segment": [0.01804223855336507, 0.01780139446258545, 0.017575488090515137, 0.01736508051554362, 0.017170364061991374, 0.01698769728342692, 0.01681694507598877, 0.01665810267130534, 0.016511460940043132, 0.01637613614400228, 0.01625097910563151, 0.016136000951131185, 0.016030886967976887, 0.01593557357788086, 0.015849761962890625, 0.01577288786570231, 0.015704652468363445, 0.015644838015238444, 0.015593212445576985, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016323582331339518, 0.016258201599121093, 0.016194583574930827, 0.016134866078694663, 0.016078572273254394, 0.016023359298706054, 0.01596930662790934, 0.015918938318888347, 0.015872063636779784, 0.01582754453023275, 0.01578651746114095, 0.015748174985249837, 0.015711615880330404, 0.01567726453145345, 0.015645615259806313, 0.01561708132425944, 0.015591721534729003, 0.015569259325663248, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015448403358459473, 0.015460426012674968, 0.015471556981404622, 0.015481799443562826, 0.015491167704264322, 0.0154996919631958, 0.015507432619730631, 0.015514438947041829, 0.01552074909210205, 0.01552638053894043, 0.015531333287556966, 0.015535612106323243, 0.015539240837097169, 0.015542262395222982, 0.015544705390930176, 0.015546619097391764, 0.015548033714294434, 0.015548992156982421, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.01723110834757487, 0.01710025469462077, 0.01697105884552002, 0.016845884323120116, 0.0167258358001709, 0.0166097100575765, 0.016498311360677084, 0.01639223575592041, 0.016291945775349936, 0.01619589964548747, 0.01610469341278076, 0.016018891334533693, 0.01593757152557373, 0.01586104234059652, 0.01578924496968587, 0.01572212855021159, 0.015659929911295573, 0.015602486928304037, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016024762789408366, 0.015994423230489094, 0.015964558919270833, 0.015935079256693522, 0.015905895233154298, 0.015876944859822592, 0.015848282178243002, 0.015820012092590333, 0.015792218844095866, 0.01576497554779053, 0.01573831558227539, 0.01571226437886556, 0.015686841011047364, 0.01566208521525065, 0.015638030370076498, 0.015614716211954753, 0.015592177708943685, 0.015570443471272786, 0.015549538930257161], "lorahub/flan_t5_large-word_segment+lorahub/flan_t5_large-glue_mrpc": [0.016390879948933918, 0.016382562319437664, 0.016383020083109538, 0.01639185110727946, 0.016411202748616537, 0.016441726684570314, 0.016480867067972818, 0.016529051462809245, 0.01658745288848877, 0.016656997998555502, 0.016737902959187825, 0.016831378936767578, 0.01693699518839518, 0.017053874333699544, 0.01718502998352051, 0.017328726450602214, 0.0174842643737793, 0.017654096285502116, 0.017840840021769205, 0.01804223855336507], "lorahub/flan_t5_large-word_segment+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015470905303955078, 0.01551552136739095, 0.015569545427958171, 0.015633214314778647, 0.015706799825032553, 0.015790637334187826, 0.015885117848714193, 0.015990653038024903, 0.016107648213704428, 0.016236340204874675, 0.016377916336059572, 0.01653273423512777, 0.016701674461364745, 0.016884546279907226, 0.017081634203592936, 0.017293980916341146, 0.01752538522084554, 0.017774422963460285, 0.01804223855336507], "lorahub/flan_t5_large-word_segment+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017291102409362793, 0.0172262446085612, 0.0171712859471639, 0.01712667147318522, 0.01709408124287923, 0.017073248227437336, 0.017063387235005698, 0.01706593672434489, 0.01708394686381022, 0.017115310033162436, 0.017159291903177897, 0.017216466267903647, 0.017288052241007486, 0.017374768257141113, 0.017476089795430503, 0.017593730290730795, 0.01772497812906901, 0.01787532170613607, 0.01804223855336507], "lorahub/flan_t5_large-word_segment+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.01606314182281494, 0.016080300013224285, 0.016107179323832193, 0.016143932342529296, 0.016190586090087892, 0.016247105598449708, 0.0163136355082194, 0.016390660603841145, 0.0164786163965861, 0.016577483812967937, 0.016687825520833335, 0.01681036949157715, 0.016944770812988282, 0.01709232489267985, 0.017252073287963868, 0.017425363858540852, 0.01761524041493734, 0.017820868492126465, 0.01804223855336507], "lorahub/flan_t5_large-glue_mrpc+lorahub/flan_t5_large-quail_description_context_question_answer_id": [0.01543548583984375, 0.015471134185791015, 0.015508286158243815, 0.015546824137369792, 0.015586849848429361, 0.015629116694132486, 0.015673548380533853, 0.015720307032267254, 0.0157682991027832, 0.01581676483154297, 0.015866522789001466, 0.015918323198954264, 0.015971601804097492, 0.01602792739868164, 0.016085723241170247, 0.01614322026570638, 0.01620191733042399, 0.016263658205668132, 0.016326751708984375, 0.016390879948933918], "lorahub/flan_t5_large-glue_mrpc+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017246394157409667, 0.01713476022084554, 0.017030337651570637, 0.016932948430379232, 0.01684269428253174, 0.016759826342264812, 0.016684590975443524, 0.0166171137491862, 0.01655737559000651, 0.016505295435587566, 0.016460854212443032, 0.01642426649729411, 0.01639586130777995, 0.01637579917907715, 0.01636397043863932, 0.016359850565592447, 0.01636287848154704, 0.016372992197672527, 0.016390879948933918], "lorahub/flan_t5_large-glue_mrpc+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.016045241355895995, 0.016038527488708498, 0.016035447120666502, 0.01603535016377767, 0.016037805875142416, 0.01604321797688802, 0.01605204423268636, 0.016064346631368, 0.016079138120015463, 0.01609613259633382, 0.016116127967834473, 0.016140268643697102, 0.016168282826741535, 0.01619741439819336, 0.01622895081837972, 0.0162644894917806, 0.016303757031758626, 0.016345799763997394, 0.016390879948933918], "lorahub/flan_t5_large-quail_description_context_question_answer_id+lorahub/flan_t5_large-squad_v2.0": [0.0173663600285848, 0.017212506930033365, 0.017063708305358888, 0.016917449633280436, 0.01677735646565755, 0.01664334774017334, 0.016514393488566082, 0.016391757329305014, 0.016276488304138182, 0.016167744000752767, 0.01606507460276286, 0.01596863110860189, 0.015878739356994628, 0.015795151392618816, 0.015718441009521484, 0.01564848264058431, 0.015585606892903645, 0.015529278119405111, 0.015479208628336589, 0.01543548583984375], "lorahub/flan_t5_large-quail_description_context_question_answer_id+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.01600982666015625, 0.015965776443481447, 0.015923390388488768, 0.015882522265116373, 0.01584303061167399, 0.01580483595530192, 0.015767935117085775, 0.01573241869608561, 0.01569833278656006, 0.01566569646199544, 0.01563451608022054, 0.015604761441548666, 0.01557641347249349, 0.015549448331197103, 0.01552385965983073, 0.015499649047851562, 0.015476833979288738, 0.015455438296000162, 0.01543548583984375], "lorahub/flan_t5_large-squad_v2.0+lorahub/flan_t5_large-wiki_bio_guess_person": [0.016055534680684408, 0.0160707426071167, 0.016092820167541502, 0.01612061818440755, 0.01615359624226888, 0.016192631721496584, 0.01623811403910319, 0.01629004637400309, 0.016347201665242513, 0.016410118738810223, 0.016479256947835287, 0.016554721196492515, 0.016636389096577962, 0.01672474225362142, 0.016818076769510904, 0.016917112668355307, 0.017022555669148762, 0.01713285764058431, 0.017246503829956055, 0.0173663600285848]}, "seed:3": {"lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2": [0.014848691622416178, 0.014866512616475423, 0.014900827407836914, 0.014951178232828776, 0.015012297630310058, 0.015081028938293457, 0.015156281789143881, 0.015235694249471028, 0.015318630536397298, 0.015401341120402019, 0.015479536056518554, 0.015550235112508137, 0.015615363121032715, 0.015678455034891764, 0.015735025405883788, 0.015788079897562663, 0.01583501656850179, 0.01587903340657552, 0.015906624794006348, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015870914459228516, 0.01587004820505778, 0.01586922804514567, 0.01586929162343343, 0.015871013005574544, 0.015872451464335125, 0.01587472120920817, 0.015878289540608725, 0.01588187535603841, 0.015887080828348797, 0.015894072850545247, 0.01589702288309733, 0.015902126630147298, 0.015908676783243814, 0.015913424491882325, 0.01592066287994385, 0.01593104362487793, 0.01593115965525309, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product": [0.01652472496032715, 0.016495167414347332, 0.01646449089050293, 0.016432878176371256, 0.016400074958801268, 0.01636661688486735, 0.016333560943603515, 0.016300760904947916, 0.016267654101053873, 0.01623454252878825, 0.01620349407196045, 0.016169398625691733, 0.01613485336303711, 0.016103331247965494, 0.016073665618896484, 0.01604424794514974, 0.016016709009806316, 0.015993118286132812, 0.015960944493611653, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-ropes_prompt_beginning": [0.015914785067240398, 0.015911142031351726, 0.015908118883768717, 0.01590573787689209, 0.01590467611948649, 0.01590432008107503, 0.0159039576848348, 0.015905481974283854, 0.015907511711120606, 0.01590985298156738, 0.015914546648661296, 0.01591955343882243, 0.01592016061147054, 0.015922214190165204, 0.01592617352803548, 0.01592833360036214, 0.015931750933329266, 0.01593842665354411, 0.015934851964314777, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning": [0.016090335845947264, 0.016076876322428386, 0.01606420675913493, 0.016051615079243978, 0.016040622393290203, 0.01603090763092041, 0.016021868387858074, 0.01601410230000814, 0.01600693861643473, 0.01600095589955648, 0.0159971809387207, 0.01599255084991455, 0.015984201431274415, 0.01597784678141276, 0.015972825686136883, 0.01596584637959798, 0.015959986050923667, 0.015957544644673666, 0.015944191614786784, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-lambada": [0.01551544984181722, 0.015467931429545084, 0.015441633860270183, 0.015432429313659669, 0.015437335968017578, 0.015452253023783365, 0.01547608216603597, 0.01550538698832194, 0.01553885300954183, 0.015576721827189128, 0.015616044998168946, 0.01565686066945394, 0.015699035326639812, 0.01573963483174642, 0.015779908498128256, 0.015818376541137696, 0.015855301221211753, 0.015886565844217937, 0.015909401575724284, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director": [0.016013663609822593, 0.015991063117980958, 0.015971542994181315, 0.015954602559407553, 0.01594026565551758, 0.015927658081054688, 0.015918442408243815, 0.0159108304977417, 0.01590498129526774, 0.01590067386627197, 0.015897761980692544, 0.015898788770039876, 0.015897479057312012, 0.01589886665344238, 0.015902884801228843, 0.015906866391499838, 0.015914430618286134, 0.015926017761230468, 0.015927985509236655, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015974607467651367, 0.015956199963887533, 0.015940208435058594, 0.015926907857259115, 0.01591526985168457, 0.015905475616455077, 0.015897749265034993, 0.01589203675587972, 0.01588854948679606, 0.01588867982228597, 0.015889304478963216, 0.015888083775838217, 0.015891269048055014, 0.01589614709218343, 0.015900781949361165, 0.01590907096862793, 0.01592236836751302, 0.015925744374593098, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.01616612116495768, 0.016136215527852375, 0.016110234260559082, 0.01608695348103841, 0.016065818468729655, 0.016045268376668295, 0.01602699915568034, 0.01601041793823242, 0.015996487935384114, 0.015984201431274415, 0.01597317059834798, 0.015965582529703776, 0.01595452308654785, 0.015945515632629394, 0.0159418789545695, 0.01593913714090983, 0.015939499537150067, 0.015935608545939128, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016025431950887046, 0.01598934809366862, 0.015954914093017577, 0.015921764373779297, 0.015893762906392415, 0.015867822964986164, 0.015849800109863282, 0.015838027000427246, 0.01583281993865967, 0.01583237330118815, 0.015836319923400878, 0.01584320863087972, 0.015851263999938966, 0.015863871574401854, 0.015880897839864096, 0.015897084871927897, 0.015915188789367676, 0.01592278480529785, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014998841285705566, 0.015010973612467449, 0.015040140151977539, 0.015084972381591797, 0.015142393112182618, 0.015208328564961751, 0.01527854601542155, 0.015352074305216472, 0.0154279359181722, 0.01550070603688558, 0.015569589932759602, 0.015628201166788737, 0.015686647097269694, 0.015739707946777343, 0.015789877573649087, 0.015835386912027995, 0.015879117647806803, 0.01590639114379883, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.01584315617879232, 0.015843404134114582, 0.015844268798828123, 0.015845255851745607, 0.015847546259562174, 0.015850186347961426, 0.015853368441263834, 0.015858127276102703, 0.015862380663553874, 0.015868129730224608, 0.01587549050649007, 0.015878334045410156, 0.015884095827738445, 0.015892279942830403, 0.015899807612101236, 0.015909786224365233, 0.015923210779825846, 0.015926688512166342, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.016446579297383628, 0.016340821584065756, 0.016250573794047037, 0.016175874074300132, 0.016113139788309732, 0.016059773763020833, 0.016014466285705565, 0.015976842244466147, 0.015946885744730632, 0.015923557281494142, 0.01590771198272705, 0.015897793769836424, 0.015893084208170573, 0.01589317003885905, 0.015897402763366698, 0.015905882517496747, 0.015912857055664063, 0.015919694900512694, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.01546263853708903, 0.015483028093973795, 0.015504169464111327, 0.015526175498962402, 0.015549456278483073, 0.015574264526367187, 0.015598624547322592, 0.015624629656473795, 0.01565085252126058, 0.015678118069966634, 0.015708236694335936, 0.015734076499938965, 0.01576132615407308, 0.01579105854034424, 0.01581925868988037, 0.01584988276163737, 0.015883766810099283, 0.01590760548909505, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.01582228978474935, 0.015820587476094564, 0.01582001527150472, 0.015819784800211588, 0.01582110087076823, 0.015823359489440917, 0.01582585652669271, 0.015830184618632, 0.015834878285725912, 0.015840725898742677, 0.015849388440450033, 0.01585418701171875, 0.015862309137980143, 0.01587339719136556, 0.015883827209472658, 0.015897000630696614, 0.015914133389790853, 0.015922101338704427, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.015943307876586914, 0.0159209410349528, 0.015901296933492026, 0.01588492234547933, 0.015871769587198895, 0.015861377716064454, 0.015853815078735352, 0.01584839344024658, 0.01584642251332601, 0.015847601890563966, 0.015846947034200032, 0.015847983360290526, 0.015854042371114097, 0.015863707860310872, 0.015875341097513835, 0.015889625549316406, 0.01590809186299642, 0.01591788132985433, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.01662602424621582, 0.016606450080871582, 0.016584672927856446, 0.016560675303141276, 0.01653541882832845, 0.01650847911834717, 0.016477977434794108, 0.01644450346628825, 0.01640898863474528, 0.01637019157409668, 0.01632638136545817, 0.016283984184265136, 0.016239115397135417, 0.016191697120666503, 0.016145865122477215, 0.016096750895182293, 0.016047943433125815, 0.01598885218302409, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016278772354125975, 0.016241378784179687, 0.01620709737141927, 0.016175646781921387, 0.016146334012349446, 0.01611945152282715, 0.01609528700510661, 0.01607393741607666, 0.016053646405537924, 0.016032816569010417, 0.016013650894165038, 0.015997481346130372, 0.015986402829488117, 0.01597440242767334, 0.015965369542439777, 0.015958409309387207, 0.015953480402628582, 0.01594120979309082, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.01597095330556234, 0.0159775972366333, 0.015983146031697593, 0.015986933708190917, 0.015989743868509928, 0.015992147127787272, 0.015992156664530435, 0.01599197228749593, 0.01599081039428711, 0.01598913351694743, 0.01598806381225586, 0.0159816042582194, 0.0159774382909139, 0.01597304662068685, 0.01596651554107666, 0.01596114953358968, 0.01595836639404297, 0.015944465001424154, 0.015930376052856444], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.0158603302637736, 0.015841851234436034, 0.01581676483154297, 0.01578457832336426, 0.015745123227437336, 0.01569838841756185, 0.01564369837443034, 0.01558120568593343, 0.015513296127319337, 0.015439497629801431, 0.015359965960184734, 0.015277932484944662, 0.015194525718688965, 0.015112169583638509, 0.015035948753356933, 0.014967873891194661, 0.014911438624064128, 0.014870023727416993, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product": [0.01652472496032715, 0.016483696301778157, 0.016434958775838216, 0.016378170649210613, 0.01631313959757487, 0.016239627202351888, 0.016157894134521483, 0.016068603197733563, 0.015971566836039227, 0.01586721420288086, 0.015756622950236002, 0.01564232349395752, 0.01552509625752767, 0.015406489372253418, 0.015290802319844563, 0.015181137720743814, 0.015077857971191407, 0.014986160596211752, 0.014908169110616048, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-ropes_prompt_beginning": [0.015914785067240398, 0.01588756243387858, 0.015854558944702148, 0.015815876324971518, 0.015771683057149252, 0.015721762975056966, 0.01566604773203532, 0.015604658126831055, 0.015537158648173014, 0.015464348793029785, 0.015389496485392253, 0.015311565399169922, 0.015231566429138184, 0.015152931213378906, 0.015075969696044921, 0.015005502700805664, 0.014944631258646647, 0.014895119667053223, 0.014861772855122884, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning": [0.016090335845947264, 0.016054989496866862, 0.01601357142130534, 0.01596683661142985, 0.015914729436238607, 0.015856725374857585, 0.015792800585428875, 0.015722972551981608, 0.015646549860636395, 0.015565783182779947, 0.015481845537821452, 0.015394070943196614, 0.015304617881774903, 0.015215965906778971, 0.01512897491455078, 0.015048664410909017, 0.014977712631225586, 0.014917922019958497, 0.014873582522074382, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-lambada": [0.01551544984181722, 0.015463263193766275, 0.015419432322184245, 0.015383691787719726, 0.015353507995605468, 0.015323657989501954, 0.015293238957722981, 0.015262916882832845, 0.015231037139892578, 0.015197661717732748, 0.015163111686706542, 0.015125780105590821, 0.01508668581644694, 0.015046868324279785, 0.015005668004353842, 0.01496459166208903, 0.01492736021677653, 0.014894501368204752, 0.01486759344736735, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director": [0.016013663609822593, 0.015966893831888835, 0.015917455355326335, 0.015864920616149903, 0.015808976491292318, 0.015749731063842774, 0.01568694591522217, 0.015620935757954915, 0.015551862716674804, 0.015479342142740885, 0.015403558413187662, 0.015326334635416666, 0.015248862902323405, 0.015171748797098795, 0.015097393989562988, 0.015028537114461263, 0.014966468811035156, 0.014914023081461588, 0.014873496691385905, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015967432657877603, 0.015934058825174967, 0.015894511540730794, 0.015849305788675945, 0.015797588030497235, 0.01573928674062093, 0.015674939155578615, 0.01560420831044515, 0.015527331034342447, 0.015447290738423665, 0.015364430745442708, 0.015279068946838378, 0.0151950470606486, 0.015112608273824057, 0.015035780270894368, 0.014968522389729818, 0.014911611874898275, 0.014870392481486002, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.016147120793660482, 0.01609180768330892, 0.016031705538431803, 0.015968003273010255, 0.015901700655619303, 0.015829830169677733, 0.015753018061319988, 0.015672469139099122, 0.015586347579956054, 0.01549535592397054, 0.015402820905049642, 0.01530908743540446, 0.015215293566385905, 0.0151256529490153, 0.015043605168660481, 0.014970169067382813, 0.014911149342854818, 0.014868876139322917, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.015988968213399252, 0.01591622193654378, 0.015841563542683918, 0.01576591968536377, 0.015690128008524578, 0.01561510403951009, 0.015541186332702637, 0.015468009312947591, 0.015396208763122558, 0.015325652758280435, 0.015256695747375489, 0.015190011660257975, 0.015124613444010417, 0.015061960220336915, 0.015003274281819662, 0.014950245221455893, 0.014904985427856446, 0.01487008253733317, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014995285669962565, 0.014979586601257325, 0.014965128898620606, 0.01495181401570638, 0.014939557711283366, 0.014928280512491862, 0.014917904535929363, 0.01490835984547933, 0.014899595578511556, 0.014891554514567057, 0.014884200096130371, 0.014877508481343588, 0.014871460596720378, 0.014866045316060384, 0.014861262639363607, 0.014857120513916015, 0.014853628476460774, 0.014850813547770183, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015826210975646973, 0.01580204486846924, 0.015771490732828776, 0.015734151204427085, 0.015690155029296875, 0.01563965161641439, 0.01558330217997233, 0.015520722071329752, 0.015451866785685222, 0.015377294222513835, 0.015299423535664877, 0.015219216346740722, 0.015138169924418132, 0.015061092376708985, 0.01499191125233968, 0.014931151072184245, 0.014884929656982421, 0.014855661392211915, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.01641808032989502, 0.01627450148264567, 0.016138472557067872, 0.01600932757059733, 0.015887861251831056, 0.015772611300150553, 0.01566150665283203, 0.01555354118347168, 0.015449522336324056, 0.015350429217020671, 0.015256299972534179, 0.015167695681254069, 0.015086658795674642, 0.015015465418497721, 0.014955644607543945, 0.014906423886617025, 0.014871649742126465, 0.014851574897766113, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015452890396118165, 0.01545653502146403, 0.015454082489013672, 0.015444957415262858, 0.015429221789042154, 0.015406715075174967, 0.015376935005187988, 0.015340161323547364, 0.015296748479207357, 0.015247761408487956, 0.01519474983215332, 0.015138338406880697, 0.015080326398213705, 0.015023940404256185, 0.0149716583887736, 0.014924343427022297, 0.014886487325032552, 0.014859867095947266, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015814647674560547, 0.015797133445739745, 0.01577278772989909, 0.015741254488627118, 0.015702681541442873, 0.015657227834065757, 0.015605392456054688, 0.015546504656473796, 0.015480508804321289, 0.015408193270365397, 0.01533155123392741, 0.015251569747924805, 0.015169679323832194, 0.015090626080830892, 0.015018426577250162, 0.01495349884033203, 0.014901604652404785, 0.014864931106567383, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.015930930773417156, 0.015888597170511883, 0.01584131081899007, 0.015788981119791667, 0.015731531778971353, 0.015668935775756836, 0.015601471265157063, 0.01552960236867269, 0.015454182624816895, 0.015376283327738443, 0.015297234853108724, 0.01521883487701416, 0.015142294565836588, 0.015069239934285482, 0.015003329912821451, 0.014945823351542155, 0.014898951848347981, 0.014865512847900391, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.016578526496887208, 0.01650900681813558, 0.016434402465820314, 0.01635423501332601, 0.01626806894938151, 0.016175087292989096, 0.016075849533081055, 0.015971345901489256, 0.015862339337666828, 0.015748051007588703, 0.015628981590270995, 0.015508527755737305, 0.015387368202209473, 0.015270336469014486, 0.015161337852478028, 0.015059819221496582, 0.014971961975097656, 0.01490005334218343, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016251699129740397, 0.016181667645772297, 0.016108476320902506, 0.0160322904586792, 0.01595405101776123, 0.015871976216634113, 0.01578714370727539, 0.01569834550221761, 0.01560482660929362, 0.015510265032450359, 0.015415425300598145, 0.015320275624593099, 0.015227290789286295, 0.015137505531311036, 0.015055974324544271, 0.014983924229939778, 0.014923435846964518, 0.01487718105316162, 0.014848691622416178], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_2+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015948944091796875, 0.01592725912729899, 0.01589704672495524, 0.015859155654907225, 0.015813148816426596, 0.01575893719991048, 0.015696314175923664, 0.01562566916147868, 0.015549259185791016, 0.015467944145202637, 0.01538151741027832, 0.015293614069620768, 0.015205760002136231, 0.015119619369506836, 0.01504058837890625, 0.014971027374267578, 0.014913002649943033, 0.01487069288889567, 0.014848691622416178], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product": [0.01652472496032715, 0.01648894468943278, 0.016452104250590006, 0.01641418774922689, 0.01637541135152181, 0.016336088180541993, 0.016296558380126953, 0.016257120768229168, 0.016218042373657225, 0.016179550488789878, 0.016141861279805502, 0.016105175018310547, 0.016069706281026205, 0.016035634676615396, 0.016003158887227375, 0.015972495079040527, 0.015943864186604817, 0.015917506217956543, 0.01589366594950358, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-ropes_prompt_beginning": [0.015914785067240398, 0.015913408597310386, 0.01591195265452067, 0.015910423596700033, 0.0159088134765625, 0.01590712388356527, 0.01590535481770833, 0.015903493563334148, 0.015901546478271484, 0.01589950720469157, 0.01589736302693685, 0.01589511235555013, 0.015892756779988606, 0.015890274047851562, 0.015887672106424968, 0.015884928703308106, 0.01588204860687256, 0.01587901751200358, 0.0158758274714152, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning": [0.016090335845947264, 0.01607046604156494, 0.016051700909932454, 0.016034005482991536, 0.016017325719197593, 0.01600163777669271, 0.015986917813618978, 0.015973134040832518, 0.015960270563761394, 0.01594829241434733, 0.015937175750732422, 0.01592690626780192, 0.015917448997497557, 0.015908786455790202, 0.015900896390279133, 0.015893766085306803, 0.015887371699015298, 0.01588170051574707, 0.015876736640930176, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-lambada": [0.01551544984181722, 0.015466006596883138, 0.015438318252563477, 0.015428994496663411, 0.01543272336324056, 0.015444947878519693, 0.0154664945602417, 0.015494680404663086, 0.015526243845621745, 0.015561480522155762, 0.015600895881652832, 0.015639076232910155, 0.015675331751505536, 0.015710291862487794, 0.015743818283081055, 0.0157755708694458, 0.015804758071899416, 0.01583067576090495, 0.01585324287414551, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director": [0.016013663609822593, 0.01599824905395508, 0.015984177589416504, 0.015971360206604005, 0.015959712664286297, 0.01594914118448893, 0.01593953768412272, 0.01593079725901286, 0.015922845204671222, 0.01591561476389567, 0.01590904712677002, 0.0159030818939209, 0.015897679328918456, 0.01589279015858968, 0.015888376235961912, 0.015884416898091634, 0.01588087558746338, 0.01587772846221924, 0.01587494691212972, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.01597867170969645, 0.015963513056437173, 0.01594943364461263, 0.0159364652633667, 0.01592463493347168, 0.015913912455240885, 0.015904305775960286, 0.015895838737487792, 0.015888500213623046, 0.01588227430979411, 0.015877121289571125, 0.015873009363810222, 0.015869911511739096, 0.015867822964986164, 0.01586674213409424, 0.015866669019063313, 0.01586760361989339, 0.01586953639984131, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.016161724726359048, 0.01612668514251709, 0.016094169616699218, 0.016064275105794272, 0.016036394437154135, 0.016010891596476236, 0.015988054275512694, 0.015967766443888348, 0.0159496275583903, 0.015933402379353843, 0.015918993949890138, 0.015906440416971843, 0.01589577039082845, 0.01588699658711751, 0.015880133310953778, 0.015875231424967447, 0.01587231953938802, 0.01587140401204427, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016042645772298178, 0.016021631558736166, 0.015997819900512696, 0.015973227818806966, 0.015949899355570476, 0.015928794542948405, 0.015911601384480795, 0.01589920202891032, 0.015889275868733725, 0.01588253180185954, 0.015877722104390462, 0.015875433286031086, 0.015874767303466798, 0.01587623914082845, 0.015876744588216144, 0.015876636505126954, 0.015875884691874186, 0.015874671936035156, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014999876022338867, 0.01501702626546224, 0.01505606969197591, 0.01511196772257487, 0.015178523063659667, 0.015252251625061036, 0.015327706336975097, 0.015403676033020019, 0.015475982030232748, 0.015544358889261882, 0.015606436729431152, 0.015662503242492676, 0.015713280042012532, 0.015755818684895832, 0.01579169273376465, 0.01582101821899414, 0.015843963623046874, 0.01586098353068034, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015843091011047365, 0.015842185020446778, 0.015841514269510904, 0.015841075579325358, 0.015840875307718914, 0.01584092140197754, 0.01584121863047282, 0.015841779708862306, 0.015842620531717935, 0.015843753814697267, 0.015845203399658205, 0.01584699312845866, 0.01584916114807129, 0.015851736068725586, 0.015854768753051758, 0.015858310063680013, 0.01586242357889811, 0.015867142677307128, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.016460142135620116, 0.0163643217086792, 0.01628031094868978, 0.016209230422973633, 0.016148802439371744, 0.016097211837768556, 0.016052910486857096, 0.0160150416692098, 0.015982216199239094, 0.015954683621724447, 0.01593172868092855, 0.015913246472676595, 0.015898221333821613, 0.015886850357055664, 0.015878591537475586, 0.015873238245646158, 0.015870437622070313, 0.01587017059326172, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015467753410339355, 0.0154922882715861, 0.015517099698384603, 0.01554179032643636, 0.015566234588623046, 0.015590527852376301, 0.015614658991495767, 0.015638550122578938, 0.015662136077880858, 0.015685372352600098, 0.015708204905192057, 0.01573060671488444, 0.01575253963470459, 0.015773978233337402, 0.015794878005981446, 0.015815216700236, 0.01583495299021403, 0.015854047139485676, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015822779337565103, 0.015820473035176596, 0.015818735758463542, 0.015817562739054363, 0.015816957155863443, 0.01581693490346273, 0.015817488034566243, 0.01581863244374593, 0.015820364952087402, 0.015822696685791015, 0.015825624465942382, 0.015829164187113443, 0.0158333158493042, 0.01583810488382975, 0.01584354559580485, 0.015849677721659343, 0.015856534639994303, 0.01586413542429606, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.015951749483744303, 0.015936371485392252, 0.015922396977742514, 0.015910056432088215, 0.01589889685312907, 0.01588856856028239, 0.01587972164154053, 0.015872419675191242, 0.0158663272857666, 0.015861968994140625, 0.015858600934346517, 0.015856088002522785, 0.015854857762654623, 0.015854862531026203, 0.015856021245320637, 0.015858290990193685, 0.015861717859903972, 0.015866448084513346, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.016592186292012534, 0.016542285283406576, 0.016493665377298992, 0.01644620895385742, 0.016399827003479004, 0.016354459126790365, 0.016310106913248697, 0.01626679261525472, 0.01622458299001058, 0.01618351936340332, 0.01614362080891927, 0.01610487461090088, 0.01606727917989095, 0.016030917167663573, 0.015995898246765138, 0.015962392489115396, 0.01593055248260498, 0.015900524457295735, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016276105244954427, 0.01623534838358561, 0.01619665463765462, 0.01616028944651286, 0.01612617015838623, 0.0160940949122111, 0.016064125696818032, 0.016036944389343263, 0.016012481053670247, 0.015990201632181802, 0.01596976598103841, 0.015951048533121744, 0.015934149424235027, 0.015919175148010254, 0.015906109809875488, 0.015894915262858075, 0.015885581970214845, 0.015878095626831054, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015961809158325194, 0.015959820747375487, 0.01595698674519857, 0.015953431129455565, 0.015949300130208333, 0.0159446922938029, 0.015939706166585285, 0.015934437115987143, 0.01592896302541097, 0.015923341115315754, 0.01591762065887451, 0.015911852518717448, 0.015906060536702474, 0.015900287628173828, 0.01589454968770345, 0.01588886896769206, 0.015883280436197918, 0.01587780475616455, 0.015872467358907065], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-ropes_prompt_beginning": [0.015914785067240398, 0.015925437609354654, 0.015939234097798665, 0.01595605691274007, 0.015976018905639648, 0.01599901040395101, 0.016024816830952963, 0.016053231557210286, 0.016084065437316896, 0.016117124557495116, 0.01615222454071045, 0.016189185778299968, 0.01622779687245687, 0.016267851193745932, 0.016309135754903156, 0.01635139306386312, 0.016394362449645997, 0.016437694231669107, 0.016481138865152994, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning": [0.016090335845947264, 0.016082428296407065, 0.016079203287760416, 0.01608071486155192, 0.0160869566599528, 0.01609764258066813, 0.01611246426900228, 0.01613112767537435, 0.01615331808725993, 0.01617872714996338, 0.016207013130187988, 0.016237837473551432, 0.016270813941955568, 0.01630554993947347, 0.01634159723917643, 0.01637847900390625, 0.016415665944417318, 0.01645266532897949, 0.016489081382751465, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-lambada": [0.01551544984181722, 0.015521539052327475, 0.015543448130289713, 0.015579479535420736, 0.015625840822855633, 0.01567828337351481, 0.015736945470174155, 0.015802033742268882, 0.015869971911112467, 0.015938758850097656, 0.016008625030517577, 0.016077739397684733, 0.01614472230275472, 0.016209479967753092, 0.016271419525146484, 0.01632998784383138, 0.016384873390197754, 0.016435770988464354, 0.0164824120203654, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director": [0.016013663609822593, 0.016027159690856933, 0.016043941179911297, 0.016063717206319172, 0.016086169878641764, 0.01611095110575358, 0.016137673060099285, 0.01616597334543864, 0.01619548797607422, 0.016225876808166503, 0.016256845792134603, 0.01628815491994222, 0.01631959597269694, 0.016350982983907063, 0.016382106145222983, 0.016412671407063803, 0.016442386309305827, 0.01647099494934082, 0.016498401959737143, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015997689565022788, 0.016004223823547364, 0.016014394760131837, 0.01602800687154134, 0.016044944127400717, 0.016064761479695638, 0.016087468465169272, 0.016113327344258625, 0.0161418883005778, 0.016172823905944825, 0.016205933888753254, 0.01624103546142578, 0.016277947425842286, 0.016316453615824383, 0.016356329917907714, 0.016397282282511392, 0.016439045270284017, 0.016481499671936035, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.0161733611424764, 0.016153958638509113, 0.0161410919825236, 0.016134230295817058, 0.0161328395207723, 0.016137123107910156, 0.016146435737609863, 0.016160648663838706, 0.016179043451944985, 0.016201087633768717, 0.016226576169331867, 0.016255286534627277, 0.01628728230794271, 0.0163221804300944, 0.01635939915974935, 0.016398522059122723, 0.016439212163289387, 0.016481266021728516, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016065502166748048, 0.016070791880289714, 0.016076296170552572, 0.016083672841389975, 0.016094282468159995, 0.01610770543416341, 0.01612802823384603, 0.016151731808980305, 0.016181047757466635, 0.016212334632873537, 0.016246280670166015, 0.01628191947937012, 0.016318758328755695, 0.016355385780334474, 0.016391175587972005, 0.01642694632212321, 0.01646113713582357, 0.016493762334187825, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015044253667195638, 0.015103710492451987, 0.015183215141296386, 0.015277489026387533, 0.015381217002868652, 0.015490881601969401, 0.0156037171681722, 0.015715344746907552, 0.015824786822001138, 0.01592865467071533, 0.01602705001831055, 0.01611756960550944, 0.016199830373128256, 0.01627347946166992, 0.016339179674784342, 0.016397188504536947, 0.016447114944458007, 0.01648947556813558, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.01585686206817627, 0.01587224324544271, 0.0158903439839681, 0.015911162694295246, 0.01593467394510905, 0.015960874557495116, 0.015989739100138345, 0.016021264394124348, 0.016055418650309246, 0.016092165311177572, 0.016131451924641927, 0.01617320378621419, 0.01621733029683431, 0.016263702710469563, 0.01631217956542969, 0.016362600326538086, 0.01641483783721924, 0.016468841234842935, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.01646233081817627, 0.016375710169474283, 0.01630758762359619, 0.01625642935434977, 0.016220070521036783, 0.016197899182637532, 0.01618568261464437, 0.016183679898579915, 0.01619056542714437, 0.016204829216003417, 0.01622514247894287, 0.016250747044881185, 0.016280984878540038, 0.01631504694620768, 0.016352237065633136, 0.01639228661855062, 0.016434729894002277, 0.01647900899251302, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015495608647664388, 0.015549745559692383, 0.015605788230895996, 0.0156633726755778, 0.015722152392069498, 0.01578181266784668, 0.01584206263224284, 0.015902630488077798, 0.015963266690572103, 0.01602374712626139, 0.016083842913309734, 0.01614334265391032, 0.01620203653971354, 0.01625969886779785, 0.01631609598795573, 0.016370991071065266, 0.016424150466918946, 0.016475400924682616, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.01583863099416097, 0.015854883193969726, 0.015874322255452475, 0.0158968718846639, 0.015922438303629556, 0.015950929323832193, 0.01598224639892578, 0.01601628621419271, 0.016052942276000976, 0.0160920778910319, 0.01613356113433838, 0.016177218755086265, 0.016222848892211914, 0.016270227432250976, 0.01631909688313802, 0.016369187037150065, 0.016420246760050456, 0.01647209644317627, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.01600050131479899, 0.016032498677571616, 0.016064416567484537, 0.01609623114267985, 0.016127923329671223, 0.016159574190775555, 0.016190532048543295, 0.016221073468526203, 0.016251150767008463, 0.01628087043762207, 0.016310272216796876, 0.016339179674784342, 0.016367473602294923, 0.016395152409871418, 0.016422235171000162, 0.01644868850708008, 0.016474515597025553, 0.0164997927347819, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.01661254088083903, 0.016584877967834474, 0.016560400327046712, 0.016539003054300946, 0.01652059078216553, 0.016505057017008464, 0.016492296854654948, 0.016482221285502117, 0.016474726994832357, 0.01646973450978597, 0.016467157999674478, 0.016466943422953288, 0.016469014485677082, 0.016473318735758465, 0.016479767163594564, 0.016488224665323892, 0.016498600641886393, 0.016510777473449707, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016304734547932943, 0.016293962796529133, 0.01628667672475179, 0.01628289222717285, 0.016282248497009277, 0.016285001436869305, 0.016291257540384928, 0.01629966894785563, 0.01631004015604655, 0.016323326428731282, 0.016339014371236166, 0.01635675589243571, 0.01637643337249756, 0.01639789581298828, 0.01642095406850179, 0.01644536018371582, 0.016470829645792644, 0.01649724006652832, 0.01652472496032715], "lorahub/flan_t5_large-amazon_polarity_User_recommend_this_product+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015990716616312663, 0.016018392244974772, 0.01604585329691569, 0.0160730504989624, 0.016099963188171387, 0.016127072970072428, 0.016154673894246418, 0.016182773907979328, 0.01621142069498698, 0.01624067306518555, 0.016270588239034017, 0.016301163037618003, 0.0163323450088501, 0.016364040374755858, 0.016396114031473796, 0.016428386370340983, 0.016460633277893065, 0.016492721239725748, 0.01652472496032715], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning": [0.016090335845947264, 0.01607524553934733, 0.016060911814371744, 0.01604729493459066, 0.016034388542175294, 0.016022167205810546, 0.01601061662038167, 0.015999725659688314, 0.015989464124043784, 0.015979827245076496, 0.015970794359842937, 0.015962357521057128, 0.015954497655232748, 0.01594720204671224, 0.01594046115875244, 0.015934267044067384, 0.01592861334482829, 0.015923484166463216, 0.015918877919514973, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-lambada": [0.01551544984181722, 0.015457649230957032, 0.01542242685953776, 0.015406409899393717, 0.01540500005086263, 0.015413775444030761, 0.015432627995808919, 0.015459205309549967, 0.01549116611480713, 0.015528286298116048, 0.01556950569152832, 0.015611882209777833, 0.015654101371765136, 0.015695505142211914, 0.01573609987894694, 0.01577568531036377, 0.01581387678782145, 0.01584996541341146, 0.01588363488515218, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director": [0.016013663609822593, 0.015996108055114745, 0.0159804105758667, 0.015966474215189617, 0.01595418612162272, 0.015943446159362794, 0.015934154192606607, 0.01592618942260742, 0.015919483502705892, 0.015913955370585122, 0.015909549395243326, 0.015906198819478353, 0.01590388298034668, 0.0159025780359904, 0.01590228239695231, 0.01590301513671875, 0.015904757181803387, 0.01590736230214437, 0.015910706520080566, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.015983675320943195, 0.01597326437632243, 0.015963643391927084, 0.015954820315043132, 0.015946796735127767, 0.015939574241638183, 0.015933116277058918, 0.015927403767903647, 0.015922438303629556, 0.015918243726094565, 0.0159148104985555, 0.015912132263183595, 0.015910197893778483, 0.015909024874369303, 0.01590860684712728, 0.015908966064453123, 0.015910104115804038, 0.01591204007466634, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.016160842577616373, 0.016125378608703615, 0.016093029975891113, 0.016063453356424968, 0.01603642781575521, 0.016012516021728516, 0.015991719563802083, 0.01597339948018392, 0.01595725695292155, 0.015943229993184406, 0.01593140443166097, 0.01592167059580485, 0.015914066632588705, 0.015908665657043457, 0.015905513763427734, 0.01590458075205485, 0.01590581258138021, 0.015909209251403808, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01602925141652425, 0.015996867815653484, 0.015963484446207682, 0.01593088944753011, 0.015901165008544924, 0.015874656041463216, 0.01585435708363851, 0.015839293797810874, 0.015829221407572428, 0.01582348346710205, 0.01582201639811198, 0.015824166933695476, 0.015830866495768228, 0.01584055582682292, 0.015852142969767252, 0.01586559772491455, 0.015880707105000814, 0.015897386868794758, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014993071556091309, 0.015002943674723308, 0.01503501256306966, 0.015083743731180826, 0.015144357681274414, 0.015212766329447429, 0.01528493881225586, 0.015359037717183431, 0.015432186126708984, 0.015501869519551596, 0.015568389892578124, 0.01563123067220052, 0.015687853495279947, 0.01573891003926595, 0.015784522692362468, 0.015824815432230632, 0.015860037803649904, 0.0158900515238444, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015841654141743978, 0.015839532216389975, 0.0158379062016805, 0.015836806297302247, 0.015836278597513836, 0.015836367607116698, 0.01583711783091227, 0.01583857218424479, 0.015840784708658854, 0.01584381103515625, 0.015847684542338054, 0.015852473576863608, 0.01585822900136312, 0.015865004857381185, 0.015872855186462403, 0.015881797472635906, 0.015891772905985514, 0.01590274175008138, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.01645550727844238, 0.016356123288472493, 0.016269426345825195, 0.016196409861246746, 0.016134004592895507, 0.016081401507059733, 0.016036831537882486, 0.01599944750467936, 0.015968968073527018, 0.015944301287333172, 0.015924208958943684, 0.01590867042541504, 0.01589784781138102, 0.015891439119974773, 0.01588897387186686, 0.01589030106862386, 0.015895284016927084, 0.015903452237447102, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015471717516581218, 0.015499970118204753, 0.015527782440185546, 0.01555496056874593, 0.015581806500752768, 0.01560832659403483, 0.015634479522705077, 0.015660263697306314, 0.015685669581095376, 0.01571069876352946, 0.015735348065694172, 0.015759587287902832, 0.01578333377838135, 0.015806554158528646, 0.015829235712687174, 0.015851395924886068, 0.015873042742411296, 0.01589417298634847, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015822170575459798, 0.015819490750630695, 0.015817619959513345, 0.015816578865051268, 0.015816380182902018, 0.015817047754923503, 0.015818602244059246, 0.01582106908162435, 0.015824467341105142, 0.015828824043273924, 0.015834169387817384, 0.0158405335744222, 0.01584795316060384, 0.015856448809305826, 0.015866042772928874, 0.015876693725585936, 0.01588835875193278, 0.015901045799255373, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.015959957440694172, 0.015951808293660483, 0.015944163004557293, 0.01593746821085612, 0.01593075434366862, 0.015924533208211262, 0.015919384956359865, 0.015914982159932454, 0.01591174284617106, 0.01590864340464274, 0.015906079610188802, 0.01590425173441569, 0.015903164545694987, 0.015902865727742514, 0.01590340773264567, 0.015904938379923503, 0.01590748945871989, 0.015910751024882, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.01659023602803548, 0.01653900146484375, 0.016489588419596354, 0.0164418363571167, 0.016395599047342935, 0.016350797017415365, 0.016307409604390463, 0.016265455881754556, 0.016224993069966633, 0.016186070442199708, 0.016148746808369953, 0.01611305236816406, 0.016079017321268717, 0.016046698888142905, 0.016016197204589844, 0.01598763624827067, 0.015961143175760906, 0.015936826070149738, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016282960573832193, 0.01624869187672933, 0.01621617317199707, 0.016185696919759116, 0.016156922976175943, 0.016129717826843262, 0.01610443592071533, 0.01608136812845866, 0.016060102780659995, 0.016040299733479816, 0.016021703084309894, 0.01600430647532145, 0.015988181432088217, 0.015973226229349772, 0.015959356625874836, 0.01594656308492025, 0.015934861501057943, 0.015924267768859864, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_beginning+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015960046450297038, 0.01595650355021159, 0.015952345530192057, 0.015947744051615396, 0.015942888259887697, 0.015937945048014324, 0.015933074951171876, 0.015928425788879395, 0.015924116770426433, 0.01592024803161621, 0.015916900634765627, 0.01591413656870524, 0.015912017822265624, 0.015910577774047852, 0.015909851392110187, 0.01590988318125407, 0.01591069539388021, 0.01591231981913249, 0.015914785067240398], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-lambada": [0.01551544984181722, 0.01547464370727539, 0.0154535977045695, 0.015449748039245606, 0.015458501180013021, 0.015476117134094238, 0.015503721237182617, 0.015538759231567383, 0.015578263600667318, 0.015623178482055664, 0.015673050880432127, 0.01572295029958089, 0.015772544542948404, 0.015821913083394368, 0.015871187845865886, 0.015919782320658365, 0.01596654733022054, 0.01601063092549642, 0.016051832834879556, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director": [0.016013663609822593, 0.016007609367370605, 0.01600315570831299, 0.01600021044413249, 0.015998678207397463, 0.015998468399047852, 0.015999471346537272, 0.01600159009297689, 0.016004761060078938, 0.016008906364440918, 0.016013954480489093, 0.01601984182993571, 0.016026490529378254, 0.016033846537272134, 0.01604186534881592, 0.01605049769083659, 0.016059676806132, 0.01606937249501546, 0.01607958475748698, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.01598733425140381, 0.015981055895487466, 0.0159760586420695, 0.015972386995951333, 0.015970064798990886, 0.01596911589304606, 0.015969541867574055, 0.015971385637919108, 0.015974664688110353, 0.015979402860005695, 0.015985617637634276, 0.015993312199910483, 0.016002500851949056, 0.016013204256693524, 0.016025433540344237, 0.016039236386617025, 0.01605462869008382, 0.016071645418802898, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.01616376717885335, 0.016131653785705566, 0.016103010177612304, 0.016077656745910645, 0.01605533281962077, 0.01603678862253825, 0.016022095680236815, 0.01601069450378418, 0.016002333958943685, 0.015996960004170734, 0.015994574228922528, 0.015995229085286458, 0.01599897861480713, 0.016005880037943523, 0.016016020774841308, 0.016029502550760907, 0.016046363512674966, 0.016066619555155436, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01604586124420166, 0.016028364499409992, 0.016008345286051433, 0.015987826983133953, 0.015968953768412272, 0.015952781041463217, 0.01594087600708008, 0.015935298601786295, 0.01593252976735433, 0.015934543609619142, 0.015940353075663247, 0.015949824651082356, 0.01596430778503418, 0.015980901718139647, 0.015999318758646647, 0.016019407908121744, 0.016041688919067383, 0.016065656344095867, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015004879633585612, 0.015025437672932943, 0.015067265828450522, 0.015125699043273926, 0.015195781389872234, 0.015273747444152832, 0.015354862213134765, 0.015437814394632975, 0.015519429842631022, 0.015597591400146485, 0.015671621958414712, 0.015742034912109376, 0.015807854334513347, 0.01586751619974772, 0.01592199643452962, 0.01597119172414144, 0.016015572547912596, 0.01605558713277181, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015840972264607747, 0.01583900769551595, 0.015838383038838704, 0.015839190483093263, 0.015841503143310547, 0.015845414797465006, 0.015851025581359864, 0.015858426094055175, 0.01586772918701172, 0.015879022280375164, 0.015892430941263833, 0.015908063252766926, 0.01592604637145996, 0.015946532885233563, 0.015969667434692383, 0.0159955898920695, 0.01602436860402425, 0.016055930455525717, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.01645328998565674, 0.016352972984313964, 0.016266833941141763, 0.01619525909423828, 0.01613620440165202, 0.016087759335835776, 0.0160488224029541, 0.016018218994140625, 0.01599522113800049, 0.01597899119059245, 0.01596951961517334, 0.01596566677093506, 0.015967947642008463, 0.01597613175710042, 0.01598958174387614, 0.016007744471232096, 0.016030632654825846, 0.01605818748474121, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015470515886942546, 0.015498572985331218, 0.015527515411376954, 0.015556972821553548, 0.015587091445922852, 0.015617992083231608, 0.015649654070536295, 0.015682082176208496, 0.01571528911590576, 0.015749295552571613, 0.015784101486206056, 0.01581969420115153, 0.015856078465779622, 0.015893212954203286, 0.01593107223510742, 0.015969667434692383, 0.01600903828938802, 0.01604924996693929, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.01582012335459391, 0.015816399256388346, 0.015814523696899414, 0.015814550717671714, 0.015816540718078614, 0.015820557276407878, 0.01582666238149007, 0.01583492120107015, 0.015845408439636232, 0.0158581813176473, 0.0158733065923055, 0.01589087963104248, 0.015910986264546713, 0.015933739344278972, 0.015959264437357585, 0.01598767121632894, 0.016018983523050943, 0.016053166389465332, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.015958070755004883, 0.01594923496246338, 0.015942096710205078, 0.01593700408935547, 0.01593346118927002, 0.015931264559427897, 0.01593108654022217, 0.015933165550231932, 0.015937312444051107, 0.015943859418233234, 0.01595195770263672, 0.015961976051330568, 0.01597415765126546, 0.01598847548166911, 0.016004783312479655, 0.016023062070210776, 0.01604349454243978, 0.01606605052947998, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.016591189702351888, 0.01654101053873698, 0.016492932637532553, 0.016446970303853354, 0.01640315055847168, 0.016361532211303712, 0.016322234471638997, 0.016285403569539388, 0.016251215934753416, 0.01621986389160156, 0.016191503206888835, 0.016166270573933918, 0.01614426771799723, 0.016125628153483073, 0.016110533078511555, 0.01609921137491862, 0.016091922124226887, 0.01608889897664388, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016284451484680176, 0.01625236988067627, 0.016222666104634603, 0.016195527712504067, 0.01617108186086019, 0.016149028142293295, 0.01612943967183431, 0.016112608909606932, 0.01609890302022298, 0.016087980270385743, 0.016079401969909667, 0.01607298215230306, 0.016068679491678874, 0.016066540082295737, 0.01606664021809896, 0.016069062550862632, 0.016073824564615886, 0.01608091672261556, 0.016090335845947264], "lorahub/flan_t5_large-ropes_prompt_bottom_hint_beginning+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.01596444606781006, 0.015965596834818522, 0.015966461499532063, 0.015967283248901367, 0.015968286196390787, 0.015969683329264323, 0.01597168763478597, 0.015974470774332682, 0.015978188514709474, 0.015982982317606607, 0.015988977750142415, 0.015996273358662924, 0.016004961331685386, 0.016015119552612304, 0.016026825904846193, 0.016040132840474446, 0.01605511665344238, 0.01607182502746582, 0.016090335845947264], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director": [0.016013663609822593, 0.015960591634114583, 0.01590815544128418, 0.015856424967447918, 0.015805400212605795, 0.01575523376464844, 0.01570626099904378, 0.015658740997314454, 0.015614275932312011, 0.015573520660400391, 0.015535306930541993, 0.015499297777811687, 0.015468250910441081, 0.015443956057230632, 0.015428016980489095, 0.015422889391581217, 0.015425531069437663, 0.015439082781473795, 0.015468732515970866, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.0159530242284139, 0.015909361839294433, 0.015864359537760418, 0.015818182627360025, 0.015771358807881674, 0.015724528630574545, 0.015677851041158042, 0.01563191254933675, 0.015587128003438314, 0.015545206069946289, 0.01550671895345052, 0.015474618275960287, 0.015448408126831055, 0.015429841677347818, 0.01542067845662435, 0.015421136220296224, 0.015434559186299641, 0.015465105374654134, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.016135811805725098, 0.01607155164082845, 0.016007297833760578, 0.01594334125518799, 0.015880929629007976, 0.015818659464518228, 0.015756986935933432, 0.01569610595703125, 0.015634838740030924, 0.015579401652018229, 0.015529294013977051, 0.015482552846272786, 0.015444536209106446, 0.015416704813639322, 0.015401972134908041, 0.015401031176249186, 0.015415484110514324, 0.015452397664388022, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016005786259969075, 0.015948880513509116, 0.01588976542154948, 0.01583064079284668, 0.015772995948791505, 0.01571733315785726, 0.015664701461791993, 0.01561721960703532, 0.015573781331380208, 0.01553357760111491, 0.015496671994527181, 0.01546804904937744, 0.01544667402903239, 0.015431822141011556, 0.015424602826436361, 0.015425314903259277, 0.015438812573750814, 0.015469026565551759, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015005162556966146, 0.015012869834899903, 0.015029637018839519, 0.015051287015279134, 0.015076940854390462, 0.015106967290242513, 0.015139787991841635, 0.015172772407531739, 0.015204718907674154, 0.015234144528706868, 0.015261139869689942, 0.015288267135620117, 0.015314780871073404, 0.01534183661142985, 0.015368738174438477, 0.015395895640055338, 0.015427939097086589, 0.015467669169108073, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015825562477111817, 0.015802966753641765, 0.015776631037394205, 0.015746534665425617, 0.01571269512176514, 0.015675857861836753, 0.015637245178222656, 0.015598203341166178, 0.015558671951293946, 0.015518379211425782, 0.0154800812403361, 0.01544611930847168, 0.01541748841603597, 0.0153976837793986, 0.015388525327046713, 0.015390186309814454, 0.015408280690511068, 0.015448927879333496, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.016388338406880698, 0.016224629084269207, 0.01607621510823568, 0.015942282676696777, 0.015822296142578126, 0.01571508248647054, 0.015620965957641602, 0.015538794199625651, 0.015468392372131348, 0.015410396258036295, 0.015364529291788737, 0.015330775578816732, 0.015309804280598959, 0.01530248483022054, 0.015309712092081706, 0.015332628885904948, 0.015373601913452148, 0.01543401559193929, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015433783531188966, 0.015422588984171549, 0.015410399436950684, 0.015397405624389649, 0.015383591651916504, 0.015369348526000977, 0.01535554567972819, 0.015342613855997722, 0.01533019224802653, 0.015318088531494141, 0.015308310190836588, 0.015302632649739583, 0.0153024689356486, 0.015310149192810058, 0.015326123237609863, 0.015350659688313803, 0.015387851397196452, 0.015442001024881998, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.01580601692199707, 0.0157830015818278, 0.015756882031758627, 0.015727732976277668, 0.01569553852081299, 0.015660904248555502, 0.015624883969624838, 0.015588555335998535, 0.01555232048034668, 0.015515451431274413, 0.015480136871337891, 0.015449204444885255, 0.01542299747467041, 0.015404971440633138, 0.01539729118347168, 0.015399311383565267, 0.015416242281595867, 0.015453824996948242, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.01592514673868815, 0.015880886713663736, 0.015835742950439453, 0.015789909362792967, 0.015743603706359865, 0.01569705327351888, 0.015650571187337238, 0.01560478687286377, 0.01556088129679362, 0.015520329475402833, 0.015483787854512533, 0.015451515515645345, 0.01542561690012614, 0.015408933957417806, 0.015401465098063151, 0.01540416399637858, 0.015422306060791015, 0.015459162394205729, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.01658061981201172, 0.016516354878743488, 0.016450510025024415, 0.016382986704508464, 0.016313778559366863, 0.016242915789286296, 0.016170256932576496, 0.01609636942545573, 0.016023279825846354, 0.015951749483744303, 0.015880653063456217, 0.01581137498219808, 0.01574583371480306, 0.01568543275197347, 0.015629801750183105, 0.01558145840962728, 0.015544784863789877, 0.015522220929463704, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.01625592549641927, 0.01619225343068441, 0.016128079096476237, 0.016064138412475587, 0.01600069840749105, 0.015939218203226725, 0.015878084500630697, 0.015818198521931965, 0.015759819348653156, 0.01570468584696452, 0.015653214454650878, 0.015604753494262696, 0.015564053853352865, 0.015529225667317709, 0.015501310030619303, 0.015484007199605306, 0.015478405952453613, 0.015487513542175292, 0.01551544984181722], "lorahub/flan_t5_large-lambada+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015949641863505046, 0.015931061108907064, 0.015907341639200847, 0.015878491401672364, 0.015845030148824057, 0.015808175404866537, 0.015768783887227376, 0.015727394421895344, 0.015683814684549966, 0.015637121200561523, 0.015592436790466308, 0.015551931063334147, 0.015514806111653645, 0.0154840087890625, 0.015462954839070639, 0.015450396537780763, 0.0154512357711792, 0.01547160784403483, 0.01551544984181722], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-quail_no_prompt_text": [0.01599491755167643, 0.01598604202270508, 0.01597786585489909, 0.01597045103708903, 0.015963939030965168, 0.015958375930786133, 0.01595380624135335, 0.0159503444035848, 0.015947898228963215, 0.015946327845255535, 0.015946022669474282, 0.015947171847025553, 0.015949759483337402, 0.015953803062438966, 0.015959359804789224, 0.01596653461456299, 0.01597545305887858, 0.015986226399739584, 0.015998934110005695, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.01616403102874756, 0.01613162358601888, 0.016101978619893393, 0.01607420285542806, 0.016049745877583822, 0.016029526392618815, 0.016012139320373535, 0.015996958414713543, 0.01598430792490641, 0.015974270502726238, 0.01596666971842448, 0.01596170902252197, 0.01595973491668701, 0.01596071720123291, 0.015964674949645995, 0.01597180684407552, 0.015982267061869303, 0.01599618117014567, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.01604507287343343, 0.016027453740437826, 0.016007604598999022, 0.015987119674682616, 0.015967647234598797, 0.01595030148824056, 0.015936582883199057, 0.015926372210184732, 0.01592136065165202, 0.01591952641805013, 0.015920379956563313, 0.015924819310506187, 0.015931841532389322, 0.01594114621480306, 0.015951833724975585, 0.01596519152323405, 0.015980412165323893, 0.015996839205423993, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015009438196818034, 0.015029323895772299, 0.015066316922505697, 0.015117122332255045, 0.015176609357198079, 0.01524321715037028, 0.015313097635904948, 0.015384189287821452, 0.015455342928568523, 0.01552438259124756, 0.015591162045796712, 0.015654354095458983, 0.015714077949523925, 0.01577053387959798, 0.015824909210205077, 0.015876216888427733, 0.015924577713012696, 0.01597023646036784, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015842153231302898, 0.015840821266174317, 0.0158402681350708, 0.015840547879536947, 0.01584172248840332, 0.015843860308329263, 0.015847050348917643, 0.015851387977600096, 0.015856990814208983, 0.01586397171020508, 0.01587247053782145, 0.015882625579833984, 0.015894575119018553, 0.01590848922729492, 0.015924545923868817, 0.01594292640686035, 0.01596379280090332, 0.015987313588460287, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.016452364921569824, 0.01634925365447998, 0.016259002685546874, 0.016183985074361164, 0.016121676762898763, 0.01606998125712077, 0.0160263458887736, 0.015989883740743, 0.015960578918457032, 0.015938951174418133, 0.01592465877532959, 0.015916186968485513, 0.01591357390085856, 0.01591689427693685, 0.0159257713953654, 0.015939890543619793, 0.015959216753641765, 0.01598379929860433, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015460200309753418, 0.015478269259134928, 0.015497910181681314, 0.015519078572591145, 0.0155417267481486, 0.01556580384572347, 0.015591249465942383, 0.0156180206934611, 0.015646135012308757, 0.015675625801086425, 0.01570657253265381, 0.015739053090413412, 0.015773119926452635, 0.015808811187744142, 0.015846179326375325, 0.015885289510091147, 0.015926202138264973, 0.015968971252441407, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015823049545288084, 0.015821479161580405, 0.01582096258799235, 0.015821547508239747, 0.015823281606038412, 0.01582621892293294, 0.015830424626668293, 0.015835975011189777, 0.015842952728271485, 0.015851434071858725, 0.015861515998840333, 0.015873298645019532, 0.015886885325113932, 0.01590240955352783, 0.015919992129007975, 0.015939764976501465, 0.01596186637878418, 0.015986447334289552, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.01595993518829346, 0.015952130953470867, 0.01594516436258952, 0.015939167340596517, 0.015934391021728514, 0.01593018849690755, 0.01592700163523356, 0.015925194422403973, 0.015925135612487793, 0.015926589965820314, 0.01592941919962565, 0.015933864911397297, 0.015940117835998534, 0.01594810962677002, 0.015957714716593425, 0.01596895694732666, 0.01598195234934489, 0.015996829668680827, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.01660403569539388, 0.016565942764282228, 0.01652885595957438, 0.01649242083231608, 0.01645639419555664, 0.01642062028249105, 0.016385075251261393, 0.01634978453318278, 0.01631479263305664, 0.01628009637196859, 0.01624579111735026, 0.01621208667755127, 0.01617919127146403, 0.016147295633951824, 0.016116665204366047, 0.016087632179260253, 0.01606054941813151, 0.016035780906677247, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016277558008829754, 0.016238624254862468, 0.016202220916748045, 0.01616873582204183, 0.016137887636820475, 0.016109913190205893, 0.016085554758707682, 0.01606463591257731, 0.016046290397644044, 0.016030327479044596, 0.016017022132873534, 0.016006104151407876, 0.015998118718465168, 0.015993183453877766, 0.015991183916727703, 0.01599218527475993, 0.01599626859029134, 0.016003432273864745, 0.016013663609822593], "lorahub/flan_t5_large-duorc_ParaphraseRC_movie_director+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.01596672534942627, 0.015969505310058595, 0.015971309343973797, 0.01597232977549235, 0.01597274621327718, 0.01597271124521891, 0.015972342491149902, 0.015971840222676593, 0.0159715477625529, 0.01597168763478597, 0.015972388585408528, 0.01597376346588135, 0.01597592035929362, 0.01597899119059245, 0.01598311424255371, 0.01598845958709717, 0.01599523385365804, 0.016003589630126953, 0.016013663609822593], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to": [0.016198655764261882, 0.01616109053293864, 0.016126190821329753, 0.016094845136006675, 0.01606691837310791, 0.016041768391927082, 0.016019670168558757, 0.016001035372416178, 0.015985666910807293, 0.015973132451375327, 0.01596314271291097, 0.01595560073852539, 0.015950644810994466, 0.01594847520192464, 0.015949228604634602, 0.015952874819437662, 0.015959300994873048, 0.015968470573425292, 0.015980335871378582, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016047836939493815, 0.016032222112019857, 0.01601393540700277, 0.01599488099416097, 0.015977174441019693, 0.015961527824401855, 0.015949769020080565, 0.015944012006123862, 0.015939359664916993, 0.015938623746236166, 0.015940368970235187, 0.015943862597147623, 0.015951670010884603, 0.01595915635426839, 0.01596683661142985, 0.015974984169006348, 0.01598265488942464, 0.01598933696746826, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015005629857381185, 0.01502654234568278, 0.015068427721659342, 0.015125517845153808, 0.015193835894266764, 0.015268708864847819, 0.015347479184468587, 0.015427125295003256, 0.015504937171936035, 0.015578873952229818, 0.015649317105611165, 0.015714888572692872, 0.015773506164550782, 0.015826144218444825, 0.01587216059366862, 0.015911612510681152, 0.015945456822713217, 0.015973121325174967, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.01584390163421631, 0.015844284693400067, 0.015845394134521483, 0.01584725538889567, 0.01584989865620931, 0.015853344599405926, 0.015857632954915366, 0.01586281140645345, 0.0158689546585083, 0.01587617874145508, 0.015884639422098796, 0.01589422067006429, 0.015904801686604818, 0.015916625658671062, 0.015929749806722005, 0.01594406445821126, 0.015959692001342774, 0.015976638793945314, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.016442508697509767, 0.01633254369099935, 0.016237576802571613, 0.01615855534871419, 0.016092503865559896, 0.0160376771291097, 0.015993024508158368, 0.015957446098327638, 0.01593043009440104, 0.015910361607869464, 0.015897372563680012, 0.015890084902445475, 0.015889210700988768, 0.015894447962443034, 0.015905636151631673, 0.015921490987141927, 0.015941559473673504, 0.01596605936686198, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015461983680725098, 0.015482165018717449, 0.015503824551900228, 0.015526512463887532, 0.015550387700398764, 0.01557551383972168, 0.015601832071940104, 0.015629340807596842, 0.015658081372578937, 0.01568777879079183, 0.015718267758687336, 0.015749754905700682, 0.015782260894775392, 0.015815685590108236, 0.015849963823954264, 0.015885055859883625, 0.01592092514038086, 0.015957544644673666, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015822073618570964, 0.015819724400838217, 0.01581860860188802, 0.015818751653035482, 0.015820180575052897, 0.015822922388712565, 0.015827008883158366, 0.015832476615905762, 0.015839385986328124, 0.01584785302480062, 0.015857915878295898, 0.015869383811950685, 0.01588234742482503, 0.015897010167439777, 0.01591332753499349, 0.015931224822998045, 0.015950803756713868, 0.015972038904825847, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.015954721768697104, 0.01594263712565104, 0.015932324727376303, 0.015924169222513836, 0.015917099316914877, 0.015911768277486166, 0.01590848922729492, 0.015906656583150228, 0.015907260576883953, 0.015909016927083332, 0.01591213544209798, 0.015916961034138997, 0.015923547744750976, 0.01593213399251302, 0.015941937764485676, 0.015953179995218912, 0.015965658823649087, 0.01597960154215495, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.01658491770426432, 0.01652972380320231, 0.01647762934366862, 0.016428419748942057, 0.016381902694702147, 0.016337933540344237, 0.01629641056060791, 0.016257314682006835, 0.016220660209655763, 0.016186496416727703, 0.016154901186625163, 0.01612574259440104, 0.016098893483479818, 0.01607478141784668, 0.01605353832244873, 0.01603481928507487, 0.016018617947896323, 0.01600529670715332, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016272287368774414, 0.016228901545206707, 0.016188718477884927, 0.016152041753133138, 0.016118790308634442, 0.01608874797821045, 0.016062127749125164, 0.016039172808329265, 0.01601984977722168, 0.016003864606221517, 0.015990997950236004, 0.01598114013671875, 0.01597425142923991, 0.015970319112141928, 0.015969349543253582, 0.015971341133117677, 0.015976277987162273, 0.01598414421081543, 0.01599491755167643], "lorahub/flan_t5_large-quail_no_prompt_text+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015961586634318035, 0.015959997177124024, 0.015958159764607748, 0.015956206321716307, 0.015954283078511555, 0.015952539443969727, 0.01595112959543864, 0.015950196584065754, 0.015949856440226236, 0.015950210889180503, 0.01595134735107422, 0.015953315099080403, 0.015956153869628908, 0.01595990816752116, 0.01596466064453125, 0.01597049554189046, 0.015977452596028646, 0.01598557472229004, 0.01599491755167643], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-newsroom": [0.016058756510416668, 0.016055219968159992, 0.016046624183654785, 0.01603505293528239, 0.016022431055704753, 0.016011091868082684, 0.01600080172220866, 0.01599570910135905, 0.01599435488382975, 0.01599800109863281, 0.016005045572916668, 0.01601640701293945, 0.016030484835306804, 0.016047608057657876, 0.016067428588867186, 0.016091071764628092, 0.016116240819295247, 0.016142988204956056, 0.016170353889465333, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014998885790506998, 0.015017476081848145, 0.015060284932454426, 0.015122445424397786, 0.0151972230275472, 0.015281931559244791, 0.015370143254597983, 0.015459898312886557, 0.015548391342163086, 0.01563446521759033, 0.015715354283650715, 0.015790605545043947, 0.015861001014709473, 0.015927945772806804, 0.015988858540852864, 0.01604706287384033, 0.01610174814860026, 0.016151979764302573, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015844248135884604, 0.015846093495686848, 0.015849782625834148, 0.015855310757954915, 0.01586263338724772, 0.015871742566426594, 0.015882709821065266, 0.015895708401997884, 0.015910844802856445, 0.0159281063079834, 0.015947656631469728, 0.01596944491068522, 0.015993102391560873, 0.01601920445760091, 0.016048982938130698, 0.016082407633463542, 0.01611821174621582, 0.016157169342041016, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.01646629492441813, 0.016378006935119628, 0.016304143269856772, 0.016244573593139647, 0.016197272936503092, 0.01616235891977946, 0.016133238474527994, 0.01611027717590332, 0.01609426498413086, 0.01608450730641683, 0.016078731218973796, 0.01607837518056234, 0.016084925333658854, 0.016094881693522134, 0.01610715707143148, 0.016122355461120605, 0.01614437421162923, 0.016169961293538412, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.01547437826792399, 0.015506434440612792, 0.015539849599202474, 0.015574413935343425, 0.015609844525655111, 0.015646007855733234, 0.015682940483093263, 0.01572068691253662, 0.0157593043645223, 0.01579901377360026, 0.015839564005533855, 0.015880672136942546, 0.01592301527659098, 0.015966928799947103, 0.01601160208384196, 0.016056931813557943, 0.016103418668111165, 0.016150830586751302, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015827476183573407, 0.015831136703491212, 0.015836642583211262, 0.015844022432963054, 0.01585329532623291, 0.015864359537760418, 0.015877070426940917, 0.0158915376663208, 0.01590806802113851, 0.015926624933878582, 0.015947208404541016, 0.015969953536987304, 0.015994424819946288, 0.016020933787027996, 0.016050904591878256, 0.016084582010904947, 0.016120155652364094, 0.01615831693013509, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.0159701935450236, 0.015973008473714193, 0.015976893107096355, 0.015981839497884114, 0.015987691879272462, 0.015994094212849936, 0.016001901626586913, 0.016011799176534017, 0.01602370580037435, 0.016036577224731445, 0.016049235661824545, 0.016062877972920737, 0.016077688535054525, 0.016093200047810872, 0.016110002199808758, 0.016130277315775553, 0.016151809692382814, 0.016174766222635906, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.01658788522084554, 0.016536197662353515, 0.01648816426595052, 0.01644348621368408, 0.016401875813802085, 0.01636318842569987, 0.01632747014363607, 0.016295010248819988, 0.016266077359517416, 0.01624059200286865, 0.016218959490458172, 0.01620115915934245, 0.016186664899190267, 0.016176122029622396, 0.016170781453450522, 0.016170945167541504, 0.016175295511881512, 0.016184736887613932, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.01626883347829183, 0.016223944028218588, 0.016184447606404622, 0.016149757703145345, 0.01611989180246989, 0.016095566749572753, 0.016076132456461587, 0.016061105728149415, 0.016050893465677896, 0.01604535897572835, 0.016044023831685385, 0.01604715665181478, 0.01605501174926758, 0.016067285537719727, 0.016083877881368003, 0.01610539436340332, 0.016132065455118815, 0.01616331100463867, 0.016198655764261882], "lorahub/flan_t5_large-dbpedia_14_given_a_list_of_category_what_does_the_title_belong_to+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015964272816975912, 0.0159658416112264, 0.015967750549316408, 0.015970204671223957, 0.01597338676452637, 0.015977509816487632, 0.0159828519821167, 0.015989665985107423, 0.01599812348683675, 0.016008240381876628, 0.01601991335550944, 0.016033298174540203, 0.016048946380615235, 0.01606765906016032, 0.016089291572570802, 0.016113046010335287, 0.01613911469777425, 0.016167829831441244, 0.016198655764261882], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014990243911743164, 0.014989533424377442, 0.015005393028259277, 0.015033987363179525, 0.015072353680928548, 0.015118058522542317, 0.015169397989908854, 0.01522642453511556, 0.015287761688232421, 0.015352919896443685, 0.01542181173960368, 0.015494116147359212, 0.0155692990620931, 0.015647794405619305, 0.015728732744852703, 0.015811254183451334, 0.01589443842569987, 0.015977304776509604, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015839087168375652, 0.015833918253580728, 0.01582862695058187, 0.01582309087117513, 0.01581907590230306, 0.015817610422770183, 0.015816926956176758, 0.015819188753763834, 0.015823779106140138, 0.015832306543986003, 0.015843100547790527, 0.01586061159769694, 0.015881171226501466, 0.015908438364664712, 0.015937631924947102, 0.015969311396280925, 0.016001326243082682, 0.016031813621520997, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.016399443944295246, 0.016248124440511068, 0.0161158816019694, 0.016001510620117187, 0.015905458132425943, 0.01582725683848063, 0.015765520731608074, 0.015718782742818196, 0.01568655808766683, 0.015668803850809734, 0.01566691239674886, 0.015678757031758625, 0.015705715815226236, 0.01574535369873047, 0.01579611619313558, 0.015855693817138673, 0.015921141306559247, 0.01598967711130778, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.01545234203338623, 0.015462474822998047, 0.015473899841308593, 0.015486968358357748, 0.015502546628316244, 0.015520021120707194, 0.015539329846700032, 0.015562057495117188, 0.015589011510213217, 0.015619775454203289, 0.0156542444229126, 0.01569446563720703, 0.015739177068074543, 0.015790079434712726, 0.015843205451965332, 0.015898826917012533, 0.015954631169637044, 0.016008647282918294, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015820563634236652, 0.01581555207570394, 0.015810370445251465, 0.015805312792460124, 0.0158022673924764, 0.015801140467325846, 0.01580093542734782, 0.015803837776184083, 0.015809264183044434, 0.015818843841552733, 0.0158305025100708, 0.01584933598836263, 0.015871583620707196, 0.015899949073791504, 0.01593093713124593, 0.01596426804860433, 0.015997970898946126, 0.016030157407124837, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.01594812552134196, 0.015929241180419922, 0.01591203212738037, 0.015896808306376138, 0.01588382085164388, 0.015873241424560546, 0.015865968068440754, 0.015861992835998536, 0.01586193561553955, 0.015865270296732584, 0.015875411033630372, 0.01588864803314209, 0.015908923149108887, 0.01593265374501546, 0.015959652264912923, 0.015987958908081055, 0.016015421549479165, 0.0160397736231486, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.01659540335337321, 0.016549075444539388, 0.016504152615865072, 0.016460394859313963, 0.016416842142740886, 0.016374680201212567, 0.016335886319478354, 0.016297589937845865, 0.01626215140024821, 0.016229888598124187, 0.016200237274169922, 0.016175044377644856, 0.0161530065536499, 0.01613525390625, 0.01612013339996338, 0.016106672286987304, 0.016093279520670575, 0.01607799212137858, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.01627576510111491, 0.016234774589538575, 0.016195157368977864, 0.016157921155293783, 0.016124122937520344, 0.01609277566274007, 0.016066311200459798, 0.016041471163431804, 0.016023089090983073, 0.016009236971537274, 0.01599978764851888, 0.01599365234375, 0.01599454402923584, 0.016000130971272786, 0.01601012388865153, 0.016022543907165527, 0.016036116282145182, 0.0160487699508667, 0.016058756510416668], "lorahub/flan_t5_large-newsroom+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015960984230041504, 0.015957380930582684, 0.015952340761820474, 0.01594689687093099, 0.01594046433766683, 0.015932812690734863, 0.01592805067698161, 0.015925273895263672, 0.015925569534301756, 0.0159283447265625, 0.01593444506327311, 0.015943719546000164, 0.015956616401672362, 0.015975022315979005, 0.015994227727254232, 0.016014248530069986, 0.016032958030700685, 0.01604844888051351, 0.016058756510416668], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015828204154968262, 0.01580652713775635, 0.015778830846150716, 0.0157446813583374, 0.015704340934753418, 0.015659019152323404, 0.015607396761576334, 0.015549430847167969, 0.015485178629557292, 0.01541675885518392, 0.015343763033548992, 0.015270069440205892, 0.015196393330891927, 0.015127034187316894, 0.015066186587015787, 0.015018248558044433, 0.014989148775736491, 0.014984463055928548, 0.015012313524881998], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.016426111857096356, 0.016290737787882488, 0.016162878672281902, 0.016041364669799805, 0.01592813809712728, 0.015820172627766926, 0.015715858141581218, 0.015613382657368977, 0.015514345169067382, 0.015419150988260905, 0.015328140258789062, 0.015242867469787598, 0.015165626207987467, 0.015098959604899088, 0.015044692357381186, 0.015005226135253907, 0.014983981450398764, 0.014984664916992187, 0.015012313524881998], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.01545604387919108, 0.015463428497314453, 0.015465216636657715, 0.015460912386576335, 0.015450814565022786, 0.015434050559997558, 0.015410348574320476, 0.015380042394002279, 0.015343213081359863, 0.01530145009358724, 0.015254507064819336, 0.01520549456278483, 0.015155229568481445, 0.015105706850687663, 0.015061977704366049, 0.01502570629119873, 0.015002363522847494, 0.014995814959208171, 0.015012313524881998], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015816179911295573, 0.01580085277557373, 0.015779242515563965, 0.01575088342030843, 0.015716357231140135, 0.01567630608876546, 0.015629386901855467, 0.015575582186381023, 0.015514861742655437, 0.015449193318684896, 0.015377866427103678, 0.01530470053354899, 0.015230312347412109, 0.015158912340799968, 0.015094833374023437, 0.015042352676391601, 0.015007232030232747, 0.014994627634684244, 0.015012313524881998], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.015929210980733237, 0.015886367162068683, 0.015839646657307943, 0.015788868268330893, 0.015734135309855145, 0.01567519664764404, 0.015612025260925293, 0.015545274416605631, 0.015475357373555501, 0.01540360927581787, 0.01533140500386556, 0.015259238878885905, 0.015191230773925781, 0.015129718780517578, 0.015076332092285157, 0.015033764839172363, 0.01500552495320638, 0.014996495246887207, 0.015012313524881998], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.016583229700724286, 0.016519234975179035, 0.016450819969177247, 0.016377302805582684, 0.01629778861999512, 0.016211217244466145, 0.016120063463846843, 0.016023489634195965, 0.015920406977335613, 0.015810823440551756, 0.0156975253423055, 0.01558293342590332, 0.015468511581420898, 0.015358104705810546, 0.015255484580993652, 0.015164321263631184, 0.01508912722269694, 0.01503586451212565, 0.015012313524881998], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016254356702168783, 0.016187483469645183, 0.016117900212605795, 0.016046695709228516, 0.01597332000732422, 0.01589643637339274, 0.015817198753356933, 0.0157331116994222, 0.01564583460489909, 0.01555771032969157, 0.015468022028605144, 0.015379017194112141, 0.015293307304382324, 0.015212677319844563, 0.015141345659891765, 0.01508077621459961, 0.015036023457845053, 0.015011094411214192, 0.015012313524881998], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015949710210164388, 0.015929845174153644, 0.015902355511983237, 0.015868007342020672, 0.01582603613535563, 0.01577646255493164, 0.015718172391255697, 0.015654462178548177, 0.015584823290506998, 0.015508864720662435, 0.015429139137268066, 0.015346419016520183, 0.015264949798583984, 0.015186357498168945, 0.015116209983825684, 0.015058075586954753, 0.01501765251159668, 0.014999883969624837, 0.015012313524881998], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-glue_sst2": [0.0165680201848348, 0.01644831657409668, 0.016342700322469074, 0.016251104672749837, 0.01617380142211914, 0.01610822041829427, 0.016054210662841798, 0.016007952690124512, 0.015969227155049642, 0.015936344464619955, 0.01590858777364095, 0.015886146227518716, 0.01586877663930257, 0.01585558255513509, 0.015846397082010907, 0.015840574900309243, 0.015837389628092446, 0.015836936632792155, 0.015839263598124185, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015468997955322266, 0.015494545300801596, 0.015520216623942058, 0.015545824368794758, 0.015571192105611165, 0.015596157709757487, 0.015620549519856771, 0.015644240379333495, 0.01566711743672689, 0.015689115524291992, 0.015710191726684572, 0.015730326970418294, 0.01574950377146403, 0.01576771895090739, 0.01578496297200521, 0.0158012326558431, 0.015816534360249837, 0.015830863316853842, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015824907620747883, 0.01582439422607422, 0.01582409063975016, 0.01582400639851888, 0.015824116071065267, 0.01582443078358968, 0.015824934641520183, 0.015825626055399576, 0.01582650343577067, 0.015827552477518717, 0.015828779538472493, 0.015830167134602866, 0.015831721623738606, 0.015833430290222168, 0.015835296312967935, 0.01583731174468994, 0.0158394718170166, 0.0158417812983195, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.015954686800638836, 0.01594169616699219, 0.01592951774597168, 0.01591815789540609, 0.01590777079264323, 0.015898151397705076, 0.01588886578877767, 0.0158802064259847, 0.0158723783493042, 0.0158656644821167, 0.01585989475250244, 0.01585496266682943, 0.01585102399190267, 0.015848048528035483, 0.015845770835876464, 0.0158441432317098, 0.015843292872111003, 0.015843313535054526, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.016573394139607747, 0.016507514317830405, 0.0164454984664917, 0.016387030283610025, 0.016331863403320313, 0.016279821395874024, 0.016230767567952473, 0.016184603373209636, 0.01614125887552897, 0.016100651423136395, 0.016062655448913575, 0.01602711836496989, 0.01599394639333089, 0.01596311092376709, 0.015934627850850425, 0.015908509890238443, 0.015884739557902018, 0.015863316853841146, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016266045570373536, 0.016216724713643393, 0.01617103417714437, 0.016129085222880046, 0.016090232531229653, 0.01605514685312907, 0.016024212837219238, 0.01599627176920573, 0.015970710118611654, 0.01594738483428955, 0.01592643737792969, 0.01590824604034424, 0.015892570813496907, 0.01587918440500895, 0.015867978731791178, 0.015858920415242513, 0.01585196812947591, 0.01584708531697591, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015956403414408366, 0.015949225425720213, 0.015941489537556967, 0.015933369000752765, 0.01592496713002523, 0.015916417439778646, 0.015908012390136717, 0.01589996655782064, 0.01589234193166097, 0.015885165532430013, 0.015878469149271646, 0.01587228457132975, 0.01586663246154785, 0.015861520767211913, 0.015856962203979492, 0.0158529535929362, 0.01584949334462484, 0.01584658940633138, 0.015844224294026692], "lorahub/flan_t5_large-glue_sst2+lorahub/flan_t5_large-wiqa_effect_with_label_answer": [0.015443763732910155, 0.015463021596272787, 0.015484652519226073, 0.015508817036946615, 0.015535701115926106, 0.01556533972422282, 0.015598537127176921, 0.015635541280110677, 0.015676298141479493, 0.015721561113993327, 0.01577156702677409, 0.015826390584309895, 0.015886276563008627, 0.01595279057820638, 0.016026129722595216, 0.016109978357950847, 0.016204768816630046, 0.016313145955403646, 0.016433998743693033, 0.0165680201848348], "lorahub/flan_t5_large-glue_sst2+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015822423299153645, 0.015821696917215983, 0.015823616981506347, 0.015828177134195962, 0.015835399627685546, 0.015845742225646973, 0.0158599328994751, 0.015878203709920248, 0.015901308059692382, 0.015929741859436033, 0.015963295300801594, 0.016002632776896158, 0.016049489974975586, 0.016104218165079752, 0.016170191764831542, 0.016248143513997396, 0.01634065310160319, 0.01644710699717204, 0.0165680201848348], "lorahub/flan_t5_large-glue_sst2+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.01594411373138428, 0.01592360814412435, 0.015907150904337565, 0.015894991556803385, 0.015887433687845866, 0.015884812672932944, 0.015887479782104492, 0.015895819664001463, 0.015910317103068033, 0.01593162218729655, 0.015960412025451662, 0.01599685033162435, 0.01604303201039632, 0.016099937756856284, 0.01616705576578776, 0.016247123082478842, 0.016339921951293947, 0.016446928977966308, 0.0165680201848348], "lorahub/flan_t5_large-glue_sst2+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.016596721013387043, 0.016552284558614096, 0.016510205268859865, 0.016470619837443034, 0.016433865229288736, 0.016400100390116374, 0.01636931578318278, 0.016341816584269205, 0.01631927172342936, 0.016301822662353516, 0.016290499369303386, 0.016286365191141763, 0.016290434201558433, 0.016303445498148602, 0.016327430407206217, 0.01636330763498942, 0.016415184338887532, 0.01648308277130127, 0.0165680201848348], "lorahub/flan_t5_large-glue_sst2+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.01626759688059489, 0.01622080643971761, 0.01617949644724528, 0.016143472989400227, 0.016115042368570965, 0.01609158992767334, 0.016073997815450033, 0.016063412030537922, 0.016060736974080402, 0.016065560976664225, 0.01607733408610026, 0.016098278363545736, 0.016129268010457356, 0.016169807116190593, 0.016220892270406087, 0.01628410498301188, 0.016362458864847818, 0.016456882158915203, 0.0165680201848348], "lorahub/flan_t5_large-glue_sst2+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.01595834255218506, 0.015954686800638836, 0.01595215638478597, 0.01595020612080892, 0.015950395266215008, 0.015953480402628582, 0.015959394772847493, 0.01596855322519938, 0.015981157620747883, 0.015999635060628254, 0.01602387269337972, 0.016055006980895997, 0.016092681884765626, 0.01613821824391683, 0.016194386482238768, 0.016263901392618817, 0.016349886258443195, 0.016451136271158854, 0.0165680201848348], "lorahub/flan_t5_large-wiqa_effect_with_label_answer+lorahub/flan_t5_large-super_glue_wsc.fixed": [0.015825645128885905, 0.015812562306722004, 0.015798595746358234, 0.015783748626708984, 0.015768019358317058, 0.015751420656840008, 0.015733962059020997, 0.015715646743774413, 0.015696498552958172, 0.015676530202229817, 0.015655757586161296, 0.015634222030639647, 0.015611947377522787, 0.015589006741841634, 0.015565493901570637, 0.015541510581970215, 0.015517199834187825, 0.015492712656656901, 0.015468190511067709, 0.015443763732910155], "lorahub/flan_t5_large-wiqa_effect_with_label_answer+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.01593639055887858, 0.015904630025227864, 0.01587319533030192, 0.015842089653015135, 0.01581140359242757, 0.015781105359395343, 0.015750781695048014, 0.015720828374226888, 0.015691375732421874, 0.015662598609924316, 0.015634676615397136, 0.015607692400614421, 0.015581603050231934, 0.015556263923645019, 0.015531598726908366, 0.01550778071085612, 0.015485097567240397, 0.015463711420694987, 0.015443763732910155], "lorahub/flan_t5_large-wiqa_effect_with_label_answer+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.016581576665242515, 0.016519778569539387, 0.016457913716634114, 0.016395821571350097, 0.01633342742919922, 0.016270680427551268, 0.01620757261912028, 0.016144142150878907, 0.01608044942220052, 0.01601648489634196, 0.015952207247416177, 0.015887603759765626, 0.015822776158650718, 0.015757907231648764, 0.01569326877593994, 0.015629210472106934, 0.015566070874532064, 0.015504153569539388, 0.015443763732910155], "lorahub/flan_t5_large-wiqa_effect_with_label_answer+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016252106030782063, 0.016187456448872883, 0.016124954223632814, 0.016064661343892415, 0.01600642999013265, 0.01595034122467041, 0.015896509488423666, 0.015845850308736167, 0.01579816500345866, 0.015752727190653484, 0.015709056854248046, 0.015667279561360676, 0.015628140767415366, 0.015591595967610677, 0.015557457605997721, 0.015525608062744141, 0.01549574057261149, 0.015468263626098632, 0.015443763732910155], "lorahub/flan_t5_large-wiqa_effect_with_label_answer+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015952351888020834, 0.015938742955525716, 0.01592228094736735, 0.015903266270955403, 0.015881964365641276, 0.015858577092488606, 0.015833250681559243, 0.015806277592976887, 0.01577798048655192, 0.015748492876688638, 0.015717889467875164, 0.015686248143513996, 0.015653669039408367, 0.015620250701904297, 0.015586082140604656, 0.015551095008850097, 0.015515421231587728, 0.015479528109232584, 0.015443763732910155], "lorahub/flan_t5_large-super_glue_wsc.fixed+lorahub/flan_t5_large-wiki_bio_who": [0.015968422889709472, 0.01595041751861572, 0.015933472315470376, 0.015917677879333497, 0.015903004010518394, 0.015889705022176105, 0.015877199172973634, 0.015865548451741537, 0.01585503896077474, 0.015845972696940103, 0.015838402112325033, 0.0158320411046346, 0.015826958020528158, 0.01582329273223877, 0.015820879936218262, 0.01581950823465983, 0.01581920305887858, 0.015820085207621258, 0.0158222230275472, 0.015825645128885905], "lorahub/flan_t5_large-super_glue_wsc.fixed+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.01657397747039795, 0.01650809129079183, 0.01644555727640788, 0.01638615131378174, 0.016329720815022788, 0.016276183128356932, 0.016225461959838868, 0.016177544593811034, 0.016132392883300782, 0.016089922587076824, 0.016050025622049966, 0.016012678146362303, 0.015977923075358072, 0.015945816040039064, 0.015916382471720378, 0.0158896271387736, 0.015865570704142254, 0.015844232241312664, 0.015825645128885905], "lorahub/flan_t5_large-super_glue_wsc.fixed+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016262091000874838, 0.01620904286702474, 0.016159785588582356, 0.01611450990041097, 0.01607265790303548, 0.016034523646036785, 0.01600094477335612, 0.015971096356709798, 0.015944148699442547, 0.01591991424560547, 0.01589827219645182, 0.01587959289550781, 0.015863914489746094, 0.015850985844930013, 0.01584073543548584, 0.015833142598470053, 0.015828140576680503, 0.015825664202372233, 0.015825645128885905], "lorahub/flan_t5_large-super_glue_wsc.fixed+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.01595657189687093, 0.015949509938557944, 0.015941826502482097, 0.015933677355448404, 0.015925092697143553, 0.015916166305541993, 0.015907139778137208, 0.01589824676513672, 0.015889576276143392, 0.015881171226501466, 0.01587308883666992, 0.015865397453308106, 0.015858139991760254, 0.01585136890411377, 0.015845108032226562, 0.015839389165242513, 0.015834225018819172, 0.015829641024271646, 0.015825645128885905], "lorahub/flan_t5_large-wiki_bio_who+lorahub/flan_t5_large-wiki_qa_automatic_system": [0.016643497149149578, 0.016598024368286134, 0.016555213928222658, 0.016514577865600587, 0.016475687026977538, 0.016438180605570476, 0.016401734352111817, 0.016365817387898763, 0.016330369313557944, 0.016295851071675617, 0.016261911392211913, 0.016228278477986652, 0.016195281346638998, 0.0161625067392985, 0.016129581133524577, 0.01609648068745931, 0.01606397787729899, 0.016031781832377117, 0.01599988301595052, 0.015968422889709472], "lorahub/flan_t5_large-wiki_bio_who+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.016276987393697102, 0.016237517992655437, 0.016200960477193195, 0.016167106628417968, 0.016136473019917805, 0.016109720865885416, 0.016084645589192707, 0.016061736742655437, 0.01604133129119873, 0.016023308436075846, 0.01600778102874756, 0.01599414666493734, 0.01598380406697591, 0.015975368817647297, 0.01596981684366862, 0.01596586227416992, 0.015964455604553222, 0.015965356826782226, 0.015968422889709472], "lorahub/flan_t5_large-wiki_bio_who+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015957444508870443, 0.015952723821004232, 0.01594855308532715, 0.015944374402364094, 0.015940887133280436, 0.01593807061513265, 0.01593585968017578, 0.015934343338012694, 0.015933435757954917, 0.01593274434407552, 0.015933264096577963, 0.015934871037801106, 0.015937029520670574, 0.01594044049580892, 0.015944318771362306, 0.015948686599731445, 0.015954294204711915, 0.015960899988810222, 0.015968422889709472], "lorahub/flan_t5_large-wiki_qa_automatic_system+lorahub/flan_t5_large-definite_pronoun_resolution": [0.016318893432617186, 0.01632196585337321, 0.0163266388575236, 0.016332648595174155, 0.016340697606404622, 0.016350348790486652, 0.016361748377482097, 0.016375228563944497, 0.01639044761657715, 0.01640657424926758, 0.016424099604288738, 0.016442694664001466, 0.016462613741556803, 0.016484014193216958, 0.016506687800089518, 0.0165305757522583, 0.01655607223510742, 0.016583399772644045, 0.016612528165181478, 0.016643497149149578], "lorahub/flan_t5_large-wiki_qa_automatic_system+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015996155738830568, 0.01602874755859375, 0.01606057325998942, 0.016091826756795248, 0.016122822761535646, 0.016153864860534668, 0.01618518352508545, 0.016216924985249837, 0.01624923865000407, 0.016282358169555665, 0.01631649653116862, 0.016351792017618817, 0.01638842264811198, 0.016426547368367513, 0.016466259956359863, 0.016507635116577147, 0.016550842920939127, 0.01659607410430908, 0.016643497149149578], "lorahub/flan_t5_large-definite_pronoun_resolution+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.01596897602081299, 0.015975584983825685, 0.015982772509257, 0.01599068800608317, 0.01599950631459554, 0.016009445190429687, 0.016020689010620117, 0.0160333251953125, 0.016047406196594238, 0.016063017845153807, 0.01608047326405843, 0.016100385983784993, 0.016123169263203938, 0.016148660977681476, 0.01617681344350179, 0.01620779514312744, 0.016241730054219562, 0.016278676986694336, 0.016318893432617186]}, "seed:4": {"lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-yelp_polarity_reviews": [0.015029703776041667, 0.015043606758117676, 0.01506352424621582, 0.015089098612467449, 0.01511991818745931, 0.015155946413675944, 0.015197051366170248, 0.015242803891499837, 0.015290443102518718, 0.015343071619669597, 0.01539909839630127, 0.015455339749654134, 0.015512638092041016, 0.015569494565327963, 0.01563168207804362, 0.015691808064778646, 0.015756489435831706, 0.015822205543518066, 0.01587798595428467, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015884695053100587, 0.015874069531758628, 0.01586472193400065, 0.015857669512430828, 0.015852767626444497, 0.015848976771036784, 0.015847527186075846, 0.015847514470418295, 0.01584930419921875, 0.015853487650553385, 0.01586026350657145, 0.01586331844329834, 0.015869329770406088, 0.01587837855021159, 0.015886303583780924, 0.01589816729227702, 0.015914745330810547, 0.015922309557596843, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First": [0.01600484848022461, 0.015997851689656575, 0.0159918483098348, 0.015987119674682616, 0.01598352273305257, 0.01597937266031901, 0.015977071126302082, 0.015974218050638835, 0.015972169240315755, 0.01596989154815674, 0.015968427658081055, 0.015968449910481772, 0.01596465746561686, 0.01596116860707601, 0.01595942974090576, 0.015955262184143067, 0.015953106880187987, 0.01595308303833008, 0.015942249298095703, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation": [0.016054232915242512, 0.016044721603393555, 0.016036278406778973, 0.016028270721435547, 0.016020530064900715, 0.016014045079549153, 0.016006380716959635, 0.01599968910217285, 0.01599486986796061, 0.01598842938741048, 0.015984002749125162, 0.0159801451365153, 0.01597147305806478, 0.015966482162475586, 0.015963137944539386, 0.015958135922749837, 0.01595446268717448, 0.015953893661499022, 0.015942241350809735, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-quartz_having_read_above_passage": [0.015892011324564616, 0.015888571739196777, 0.015886502265930177, 0.01588509718577067, 0.0158836030960083, 0.0158836030960083, 0.0158845059076945, 0.015885702768961587, 0.015888261795043945, 0.01589098294576009, 0.015894769032796224, 0.015900529225667318, 0.015901994705200196, 0.0159059476852417, 0.015912025769551596, 0.015916840235392252, 0.01592386722564697, 0.01593371550242106, 0.015932571093241372, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-wmt16_translate_tr-en": [0.016640814145406087, 0.01655854066212972, 0.016479358673095704, 0.016405105590820312, 0.01634007930755615, 0.016283402442932127, 0.016229570706685383, 0.016180313428243002, 0.01613673528035482, 0.016099384625752767, 0.016065111160278322, 0.01603654384613037, 0.016009856859842936, 0.015985477765401206, 0.015968982378641763, 0.015955033302307128, 0.015946321487426758, 0.015944105784098307, 0.01593517303466797, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-true_case": [0.019832337697347005, 0.01945906162261963, 0.019110159873962404, 0.01878543694814046, 0.018482988675435384, 0.01819947083791097, 0.01793159008026123, 0.017684082984924316, 0.017454937299092612, 0.017244478861490886, 0.01704700311024984, 0.016864439646402996, 0.016699565251668293, 0.016553715070088706, 0.016419684092203776, 0.0162989075978597, 0.016194225947062175, 0.01609662055969238, 0.0160071070988973, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1": [0.014645047187805176, 0.014663426081339519, 0.014702665011088053, 0.014761201540629069, 0.014828845659891765, 0.014906878471374512, 0.014991264343261718, 0.015080464680989584, 0.015174930890401204, 0.015267271995544434, 0.015356496175130208, 0.015440270105997722, 0.015517838795979818, 0.015593975385030111, 0.015663471221923828, 0.015730268160502117, 0.015791346232096354, 0.015850098927815755, 0.015892070134480796, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-qasc_is_correct_1": [0.0162496821085612, 0.016257405281066895, 0.016262337366739908, 0.01626400152842204, 0.016261607805887857, 0.016257376670837403, 0.016249879201253255, 0.01623918374379476, 0.016225001017252605, 0.016209576924641925, 0.016190829277038573, 0.016170533498128255, 0.016147150993347167, 0.01611896514892578, 0.01609202226003011, 0.016063701311747232, 0.01603498140970866, 0.016007021268208823, 0.015969915390014647, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.014363663991292318, 0.014486680030822754, 0.014606153170267741, 0.01472158432006836, 0.014832797050476075, 0.014940361976623535, 0.015042211214701335, 0.015140978495279948, 0.015231792132059734, 0.015319809913635254, 0.015406662623087566, 0.015482668876647948, 0.015555659929911295, 0.015628994305928547, 0.015699702898661294, 0.015765283902486164, 0.015829803148905437, 0.015881675084431966, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.01597095330556234, 0.0159775972366333, 0.015983146031697593, 0.015986933708190917, 0.015989743868509928, 0.015992147127787272, 0.015992156664530435, 0.01599197228749593, 0.01599081039428711, 0.01598913351694743, 0.01598806381225586, 0.0159816042582194, 0.0159774382909139, 0.01597304662068685, 0.01596651554107666, 0.01596114953358968, 0.01595836639404297, 0.015944465001424154, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015593066215515136, 0.01560679276784261, 0.01562063694000244, 0.01563679059346517, 0.015654568672180177, 0.015672057469685873, 0.015689139366149903, 0.01570724805196126, 0.01572393258412679, 0.01574193000793457, 0.015761481920878093, 0.015783424377441405, 0.01580501397450765, 0.015828959147135415, 0.015852856636047363, 0.01587781588236491, 0.015898253122965497, 0.015914007822672525, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015948673884073894, 0.015936301549275715, 0.015926068623860676, 0.015917464892069497, 0.01591001033782959, 0.01590486685434977, 0.01589993476867676, 0.01589744249979655, 0.015896112124125162, 0.01589614391326904, 0.015899208386739094, 0.015898707707722982, 0.015900766054789225, 0.015905764897664387, 0.015910547574361167, 0.015918448766072592, 0.015929563840230306, 0.015929988225301107, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.016020787556966145, 0.0160079288482666, 0.0159964386622111, 0.01598676045735677, 0.015977710088094076, 0.015969525973002115, 0.01596249262491862, 0.015955888430277506, 0.015950636863708498, 0.015947631200154622, 0.01594327131907145, 0.01593807538350423, 0.01593620777130127, 0.01593532880147298, 0.015934845606486003, 0.0159356419245402, 0.015940635999043783, 0.015934921900431314, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016210551261901854, 0.01616862138112386, 0.016131380399068196, 0.016097052892049154, 0.016067134539286296, 0.01604087988535563, 0.01601667881011963, 0.01599604606628418, 0.015978800455729168, 0.015964303016662598, 0.015950692494710286, 0.015941845575968425, 0.01593384106953939, 0.015928163528442382, 0.01592915693918864, 0.01593043327331543, 0.015934540430704754, 0.015930838584899902, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.01644392490386963, 0.016395564079284667, 0.016349933942159018, 0.016307531992594403, 0.016269065539042154, 0.01623305638631185, 0.016199116706848146, 0.01616706689198812, 0.01613869349161784, 0.01611293156941732, 0.01608617146809896, 0.016059449513753255, 0.016036233901977538, 0.01601759910583496, 0.01599914232889811, 0.015982470512390136, 0.015970156987508137, 0.015949490865071615, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.01610435644785563, 0.01607590675354004, 0.016050386428833007, 0.016027663548787433, 0.01600693702697754, 0.01598827838897705, 0.01597343921661377, 0.015960488319396973, 0.01594895839691162, 0.015941076278686524, 0.015935354232788086, 0.015927583376566568, 0.01592292308807373, 0.015922943751017254, 0.015922147432963052, 0.01592544714609782, 0.015932780901590983, 0.015931296348571777, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.01594078222910563, 0.01591918627421061, 0.01590019226074219, 0.0158842929204305, 0.015870498021443684, 0.0158597199122111, 0.01585281213124593, 0.01584882100423177, 0.015846142768859862, 0.01584654966990153, 0.015848588943481446, 0.015855908393859863, 0.01585918426513672, 0.015867576599121094, 0.015877782503763836, 0.015893983840942382, 0.015912264188130697, 0.01592168172200521, 0.015930376052856444], "lorahub/flan_t5_large-super_glue_wic+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015511759122212728, 0.015532286961873372, 0.015554620424906412, 0.015578392346700033, 0.015603647232055665, 0.015629870096842448, 0.015655385653177898, 0.015679299036661785, 0.015703186988830567, 0.015728933016459147, 0.0157569948832194, 0.015783836046854655, 0.015808951059977212, 0.015832980473836262, 0.015855844815572104, 0.01588170051574707, 0.015900171597798666, 0.015915101369222005, 0.015930376052856444], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015857750574747722, 0.015816235542297365, 0.015772453943888345, 0.015726865132649738, 0.015679821968078614, 0.015631445248921714, 0.015581650733947754, 0.015530503590901693, 0.015478693644205729, 0.01542678197224935, 0.01537477175394694, 0.01532365640004476, 0.015274135271708171, 0.01522616704305013, 0.01518002986907959, 0.015136737823486329, 0.015096991856892904, 0.015061136881510416, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First": [0.01600484848022461, 0.015966854095458984, 0.01592660427093506, 0.015884009997049968, 0.015838985443115235, 0.015791393915812173, 0.015741152763366698, 0.015688490867614747, 0.01563383420308431, 0.015577327410380046, 0.01551941712697347, 0.015460983912150065, 0.015402515729268393, 0.015344279607137044, 0.015286548932393392, 0.015229768753051758, 0.015174956321716308, 0.01512296994527181, 0.015074311892191569, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation": [0.016054232915242512, 0.016018009185791014, 0.01597836971282959, 0.015935425758361817, 0.015889285405476888, 0.015840039253234864, 0.01578782558441162, 0.01573293368021647, 0.015675827662150064, 0.01561696211496989, 0.015556694666544597, 0.015495357513427734, 0.015433266957600911, 0.0153708283106486, 0.01530866781870524, 0.015247658093770345, 0.015188563664754231, 0.015132031440734862, 0.015078802108764649, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-quartz_having_read_above_passage": [0.015892011324564616, 0.015859063466389975, 0.01582282066345215, 0.015783464113871257, 0.0157412052154541, 0.015696349143981932, 0.01564921220143636, 0.015600045522054037, 0.015549135208129884, 0.015497037569681803, 0.015444475809733073, 0.015391958554585776, 0.015339813232421874, 0.015288352966308594, 0.015238110224405925, 0.015189895629882813, 0.015144437154134115, 0.015102229118347167, 0.015063784917195637, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-wmt16_translate_tr-en": [0.016640814145406087, 0.01652750333150228, 0.016416853268941243, 0.01630862553914388, 0.016202189127604166, 0.016098332405090333, 0.0159978183110555, 0.015901083946228026, 0.01580757776896159, 0.01571682294209798, 0.015629746119181314, 0.015546237627665202, 0.015466192563374836, 0.0153897492090861, 0.015317363739013672, 0.015249606768290201, 0.015186770757039388, 0.015129017829895019, 0.01507656733194987, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-true_case": [0.019832337697347005, 0.019415537516276043, 0.01901705265045166, 0.01863651752471924, 0.0182745885848999, 0.017930466334025064, 0.017604349454243978, 0.01729662895202637, 0.01700757662455241, 0.01673727512359619, 0.01648542086283366, 0.016252029736836753, 0.016037114461263022, 0.01584050178527832, 0.015661872227986654, 0.015500774383544922, 0.015356923739115397, 0.015230557123819988, 0.015121685663859049, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1": [0.014645047187805176, 0.014652414321899414, 0.014671390851338704, 0.014699373245239258, 0.01473270575205485, 0.0147673765818278, 0.014804054896036783, 0.014841523170471192, 0.01487699826558431, 0.01491037686665853, 0.014940865834554036, 0.014966974258422852, 0.014988665580749511, 0.015005823771158854, 0.015018523534138998, 0.015027043024698893, 0.015031795501708984, 0.015033354759216308, 0.015032402674357096, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-qasc_is_correct_1": [0.0162496821085612, 0.016221415201822915, 0.01618951479593913, 0.0161535120010376, 0.016112877527872722, 0.016067004203796385, 0.01601533571879069, 0.015957492192586263, 0.015893362363179526, 0.015823281606038412, 0.015748289426167805, 0.01566987673441569, 0.01558921496073405, 0.015507078170776368, 0.01542413870493571, 0.015341324806213379, 0.015259855588277181, 0.015180425643920898, 0.01510351022084554, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.014335681597391764, 0.014426010449727376, 0.014508376121520996, 0.014582943916320801, 0.014651689529418945, 0.014711936314900717, 0.014764219919840494, 0.014810336430867514, 0.014849630991617839, 0.014883273442586263, 0.014912066459655761, 0.014936312039693197, 0.014956610997517904, 0.014973115921020509, 0.0149869966506958, 0.014999020894368489, 0.015009800593058268, 0.015019855499267577, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015936517715454103, 0.015906111399332682, 0.01587168057759603, 0.015833107630411784, 0.01579006830851237, 0.01574281056722005, 0.015691887537638345, 0.01563771883646647, 0.015580835342407227, 0.015521764755249023, 0.01546083927154541, 0.015399552981058757, 0.015339121818542481, 0.015279939969380697, 0.015222360293070475, 0.015167463620503743, 0.015116559664408365, 0.015070335070292155, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.01556125005086263, 0.015538471539815267, 0.015511616071065267, 0.015483579635620116, 0.015455166498819986, 0.015425508817036946, 0.015393699010213216, 0.015359792709350586, 0.015324897766113281, 0.015289939244588217, 0.015255187352498372, 0.015220859845479329, 0.015187397003173828, 0.015155224800109864, 0.015124773979187012, 0.015096510251363118, 0.015070923169453939, 0.015048494338989258, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015916388829549155, 0.015868171056111654, 0.01581818103790283, 0.015766574541727703, 0.015713547070821125, 0.01565936247507731, 0.015604337056477865, 0.015548861821492514, 0.015493356386820475, 0.015438202222188314, 0.015383761723836263, 0.015330360730489096, 0.015278380711873372, 0.015228360493977865, 0.015181016921997071, 0.015136998494466146, 0.01509676456451416, 0.01506080945332845, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.015978689193725585, 0.01592161814371745, 0.01586340109507243, 0.015804190635681153, 0.01574422518412272, 0.015683884620666503, 0.015623558362325032, 0.015563421249389649, 0.015503671964009603, 0.015445016225179036, 0.0153881041208903, 0.01533311367034912, 0.015280132293701171, 0.015229506492614746, 0.015181887944539387, 0.015137796401977538, 0.015097510019938152, 0.015061349868774413, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016184101104736327, 0.016112618446350098, 0.01604211171468099, 0.0159726349512736, 0.015902700424194335, 0.015833717981974284, 0.015764252344767252, 0.015695193608601887, 0.01562710444132487, 0.015560007095336914, 0.015494120915730795, 0.015428977012634277, 0.015365161895751954, 0.015303020477294921, 0.015242881774902343, 0.015185097058614094, 0.015130035082499186, 0.01507809321085612, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.016395360628763834, 0.01629668394724528, 0.01619951566060384, 0.016103439331054688, 0.016008377075195312, 0.015916409492492675, 0.01582783063252767, 0.01574202060699463, 0.015658928553263347, 0.015577624638875326, 0.015499687194824219, 0.015425599416097006, 0.015354587237040201, 0.015288435618082682, 0.015226550102233886, 0.015169157981872558, 0.01511716365814209, 0.01507059415181478, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016073837280273437, 0.01601103146870931, 0.015947481791178386, 0.01588334878285726, 0.015818819999694825, 0.01575411796569824, 0.015689371426900228, 0.01562459945678711, 0.015560207366943359, 0.015496891339619954, 0.015434980392456055, 0.01537460486094157, 0.01531603495279948, 0.015259788831075033, 0.015206416447957357, 0.015156318346659342, 0.015109874407450359, 0.015067518552144369, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015910784403483074, 0.015855786005655924, 0.01579991022745768, 0.015743629137674967, 0.015686667760213217, 0.015629541079203287, 0.015572911898295084, 0.015516525904337565, 0.015461867650349934, 0.015407773653666178, 0.015354617436726888, 0.015303366978963217, 0.015254093805948893, 0.015208032925923666, 0.0151645294825236, 0.015124478340148927, 0.015088380177815755, 0.015056656201680502, 0.015029703776041667], "lorahub/flan_t5_large-yelp_polarity_reviews+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015481212933858235, 0.015465879440307617, 0.015449328422546387, 0.01543093204498291, 0.015410343805948893, 0.0153890593846639, 0.015368029276529948, 0.015345010757446289, 0.015318428675333659, 0.015290540059407552, 0.015262571970621745, 0.015233608881632487, 0.015203065872192383, 0.01517187754313151, 0.015140665372212729, 0.015109941164652507, 0.015080572764078776, 0.01505351702372233, 0.015029703776041667], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First": [0.01600484848022461, 0.015989472071329752, 0.015975236892700195, 0.015962130228678387, 0.0159501314163208, 0.015939215024312336, 0.015929369926452636, 0.01592058817545573, 0.01591286341349284, 0.01590619087219238, 0.01590058167775472, 0.01589602788289388, 0.01589253266652425, 0.01589009602864583, 0.015888717969258625, 0.015888384183247884, 0.015889066060384115, 0.01589070955912272, 0.01589329242706299, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation": [0.016054232915242512, 0.016038079261779786, 0.01602277596791585, 0.016008350054423016, 0.015994822184244792, 0.015982197125752766, 0.01597046375274658, 0.015959595044453937, 0.015949541727701824, 0.01594028155008952, 0.015931825637817382, 0.0159242312113444, 0.015917553901672363, 0.01591184933980306, 0.015907114346822102, 0.01590332825978597, 0.01590044339497884, 0.015898431142171224, 0.01589722792307536, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-quartz_having_read_above_passage": [0.015892011324564616, 0.015886449813842775, 0.01588154474894206, 0.01587729295094808, 0.015873681704203287, 0.015870701471964517, 0.01586833953857422, 0.015866592725118003, 0.01586544672648112, 0.015864920616149903, 0.01586501916249593, 0.015865777333577472, 0.01586722215016683, 0.01586937109629313, 0.015872248013814292, 0.01587586243947347, 0.015880223910013834, 0.015885246594746907, 0.01589078426361084, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-wmt16_translate_tr-en": [0.016640814145406087, 0.016562995910644532, 0.01649035930633545, 0.016422192255655926, 0.01635769526163737, 0.01629771868387858, 0.01624321937561035, 0.01619370460510254, 0.016148770650227864, 0.016108163197835288, 0.016071640650431315, 0.01603887399037679, 0.016009564399719237, 0.015983595848083496, 0.0159609587987264, 0.015941656430562338, 0.015925647417704265, 0.015912874539693197, 0.015903271039326986, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-true_case": [0.019832337697347005, 0.019435025850931802, 0.019063318570454915, 0.018716570536295572, 0.018394088745117186, 0.018094650904337563, 0.017817250887552896, 0.01756131966908773, 0.017326288223266602, 0.017111167907714844, 0.016914588610331217, 0.016736199061075846, 0.01657543977101644, 0.016431660652160646, 0.01630427678426107, 0.01619277795155843, 0.016096760431925455, 0.016015915870666503, 0.01594954013824463, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1": [0.014645047187805176, 0.014663802782694498, 0.01470664660135905, 0.014769277572631835, 0.014842863082885743, 0.014927678108215332, 0.015017102559407552, 0.01511041800181071, 0.015203474362691243, 0.015294569333394369, 0.015382590293884278, 0.015466559727986653, 0.015543176333109537, 0.015613115628560385, 0.015676350593566896, 0.015732930501302082, 0.015783095359802247, 0.015827253659566245, 0.01586514949798584, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-qasc_is_correct_1": [0.0162496821085612, 0.01622610569000244, 0.016201915740966796, 0.016177212397257487, 0.016152140299479166, 0.016126869519551595, 0.01610162099202474, 0.016076645851135253, 0.016052228609720866, 0.01602864106496175, 0.01600616137186686, 0.015985050201416016, 0.015965579350789388, 0.015948007901509603, 0.015932602882385252, 0.015919639269510906, 0.01590937614440918, 0.015902032852172853, 0.015897782643636067, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.014387485186258951, 0.014530706405639648, 0.014667202631632487, 0.014797989527384441, 0.014920001029968261, 0.015034294128417969, 0.015141286849975587, 0.015240228970845541, 0.015331621170043946, 0.015416285196940105, 0.015493400891621907, 0.015563597679138183, 0.015628817876180014, 0.015688625971476237, 0.015741499265034993, 0.015788017908732098, 0.0158294153213501, 0.015866106351216634, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.01595713456471761, 0.015950833956400554, 0.01594408671061198, 0.015937083562215168, 0.015930015246073403, 0.015923082033793133, 0.01591645081837972, 0.015910277366638182, 0.015904682477315267, 0.015899790128072102, 0.015895654360453287, 0.015892370541890462, 0.015889983177185058, 0.01588853677113851, 0.015888079007466634, 0.01588864008585612, 0.01589026133219401, 0.01589296817779541, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015594642957051595, 0.015608439445495606, 0.015621315638224284, 0.015635172526041668, 0.015649917920430502, 0.015665450096130372, 0.015681115786234538, 0.01569629510243734, 0.015711596806844075, 0.015728349685668944, 0.01574527581532796, 0.015762519836425782, 0.015780467987060547, 0.01579918702443441, 0.0158179235458374, 0.01583664576212565, 0.01585622787475586, 0.01587653160095215, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015954100290934244, 0.01594603697458903, 0.015938520431518555, 0.01593157768249512, 0.015925230979919432, 0.015919493039449055, 0.01591433525085449, 0.01590972900390625, 0.015905637741088868, 0.015902042388916016, 0.015898965199788413, 0.015896445910135906, 0.015894530614217122, 0.01589328130086263, 0.015892728169759115, 0.015892914136250814, 0.015893829663594563, 0.01589518864949544, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.01601399580637614, 0.015995033582051597, 0.015977632204691568, 0.01596177101135254, 0.015947430928548178, 0.01593459447224935, 0.015923248926798503, 0.015913376808166502, 0.01590496063232422, 0.01589798291524251, 0.01589242935180664, 0.015888284047444662, 0.015885539054870605, 0.015884186426798504, 0.01588420073191325, 0.015885523160298665, 0.01588807741800944, 0.0158918301264445, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016220224698384602, 0.01618643124898275, 0.016157395044962566, 0.016128988265991212, 0.016102776527404786, 0.01607755502065023, 0.01605465094248454, 0.016032942136128745, 0.016013226509094237, 0.015994598070780436, 0.01597724755605062, 0.01596300443013509, 0.015950500170389813, 0.01593841552734375, 0.01592713197072347, 0.015917115211486817, 0.015908985137939452, 0.015902582804361978, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.0164313268661499, 0.016371396382649738, 0.01631553332010905, 0.01626366933186849, 0.01621524969736735, 0.01617018699645996, 0.016128652890523273, 0.01609085241953532, 0.01605706214904785, 0.016026906967163086, 0.01600010395050049, 0.015976449648539226, 0.015956026713053385, 0.015938849449157716, 0.015924725532531738, 0.015913500785827636, 0.01590511163075765, 0.015899543762207032, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016111056009928387, 0.01608771483103434, 0.016065764427185058, 0.016045220692952476, 0.016026074091593425, 0.016008310317993164, 0.01599189599355062, 0.01597678502400716, 0.01596297264099121, 0.01595043977101644, 0.015939227739969888, 0.015929354031880696, 0.015920820236206053, 0.0159136438369751, 0.01590781847635905, 0.015903326670328777, 0.01590005874633789, 0.01589789390563965, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015949700673421222, 0.015935599009195965, 0.015922935803731282, 0.015910800298055014, 0.015900193850199383, 0.01589275519053141, 0.01588496208190918, 0.015879427591959636, 0.015874212582906087, 0.015870118141174318, 0.01586772918701172, 0.015866031646728517, 0.015866897900899252, 0.015869361559549967, 0.015872461001078288, 0.01587620417277018, 0.015881314277648925, 0.015888633728027343, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015519903500874838, 0.015546269416809082, 0.01557242234547933, 0.015598308245340984, 0.01562333583831787, 0.015648398399353027, 0.01567351182301839, 0.015698033968607583, 0.01572123368581136, 0.015743322372436523, 0.01576453685760498, 0.015785026550292968, 0.015804956754048666, 0.01582390308380127, 0.01584144592285156, 0.01585745652516683, 0.015871973037719728, 0.015885071754455568, 0.01589679718017578], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation": [0.016054232915242512, 0.016038629213968914, 0.016024468739827474, 0.016011746724446614, 0.016000474294026693, 0.015990653038024903, 0.01598228613535563, 0.015975378354390463, 0.015969921747843424, 0.01596590836842855, 0.01596332391103109, 0.015962149302164715, 0.01596237818400065, 0.01596400260925293, 0.015967057545979817, 0.01597156047821045, 0.01597755750020345, 0.015985085169474285, 0.015994168917338052, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-quartz_having_read_above_passage": [0.015892011324564616, 0.01589304447174072, 0.015894606908162436, 0.015896689097086587, 0.015899298985799153, 0.01590243975321452, 0.01590610186258952, 0.015910304387410482, 0.01591502825419108, 0.015920286178588868, 0.015926084518432616, 0.015932421684265136, 0.015939313570658364, 0.015946771303812664, 0.015954817136128743, 0.01596347490946452, 0.01597277800242106, 0.015982753435770672, 0.015993432998657228, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-wmt16_translate_tr-en": [0.016640814145406087, 0.01656502882639567, 0.01649464766184489, 0.016429303487141927, 0.01636828899383545, 0.016311682065327963, 0.01626033941904704, 0.016214451789855956, 0.016173628171284992, 0.016137523651123045, 0.01610586961110433, 0.01607849438985189, 0.016055264472961427, 0.016036108334859214, 0.01602096398671468, 0.016009809176127116, 0.01600261370340983, 0.01599938710530599, 0.016000118255615235, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-true_case": [0.019832337697347005, 0.019452045758565267, 0.01909492015838623, 0.01876034418741862, 0.018447596232096353, 0.018156541188557942, 0.017886117299397788, 0.017635671297709148, 0.01740470091501872, 0.017192951838175454, 0.017000377972920734, 0.016825706164042154, 0.016668087641398113, 0.0165271520614624, 0.01640241305033366, 0.01629334290822347, 0.016199401219685872, 0.01612016518910726, 0.016055378913879394, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1": [0.014645047187805176, 0.014671866099039714, 0.014721159934997558, 0.014788681666056316, 0.014867412249247232, 0.014955449104309081, 0.015050071080525716, 0.015148032506306966, 0.015246488253275554, 0.015342698097229004, 0.0154351011912028, 0.015523230234781901, 0.015606161753336588, 0.015682970682779948, 0.01575294812520345, 0.015816156069437662, 0.015872713724772135, 0.015922853151957194, 0.01596683661142985, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-qasc_is_correct_1": [0.0162496821085612, 0.01623033841451009, 0.016210840543111164, 0.016191299756368002, 0.016171871821085614, 0.016152715682983397, 0.016133990287780762, 0.016115856170654298, 0.016098477045694986, 0.0160820213953654, 0.016066660881042482, 0.016052571932474773, 0.016039911905924478, 0.016028852462768556, 0.016019550959269206, 0.01601216475168864, 0.016006855964660643, 0.016003767649332683, 0.016003047625223796, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.014394838015238444, 0.014545825322469076, 0.014689664840698242, 0.014828461011250814, 0.014958071708679199, 0.015080215136210124, 0.015193994839986165, 0.015300723711649577, 0.015399023691813151, 0.015490368207295735, 0.015573633511861166, 0.015649352073669433, 0.015718544324239095, 0.01578162670135498, 0.0158392604192098, 0.015890440940856933, 0.015934715270996092, 0.015972631772359212, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015963370005289714, 0.015963420867919922, 0.015963099797566733, 0.015962562561035155, 0.01596195697784424, 0.015961414972941082, 0.015961052576700847, 0.015960968335469564, 0.015961276690165203, 0.015962090492248535, 0.015963511466979982, 0.015965617497762045, 0.015968470573425292, 0.015972131093343098, 0.015976659456888833, 0.015982117652893067, 0.015988577206929526, 0.01599612553914388, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015604098637898764, 0.015626761118570965, 0.015647910435994467, 0.01567057768503825, 0.0156941556930542, 0.015717430114746092, 0.015739614168802898, 0.0157605250676473, 0.015781849225362143, 0.01580438296000163, 0.0158272918065389, 0.015849773089090982, 0.015871763229370117, 0.015894068082173664, 0.015916709899902345, 0.015939046541849772, 0.015960952440897624, 0.01598283290863037, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015950821240743002, 0.01594050884246826, 0.01593178113301595, 0.015924631754557293, 0.015919071833292643, 0.015915112495422365, 0.01591276486714681, 0.01591201941172282, 0.015912869771321614, 0.01591529687245687, 0.015919265747070314, 0.015924752553304035, 0.015931727091471354, 0.01594017823537191, 0.015950109163920086, 0.015961531003316244, 0.015974454879760742, 0.01598888874053955, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.016020867029825848, 0.016008602778116863, 0.015997753143310547, 0.01598828951517741, 0.01598021666208903, 0.015973512331644693, 0.015968173344930014, 0.015964179039001464, 0.015961527824401855, 0.01596019744873047, 0.015960164070129394, 0.01596142292022705, 0.015963940620422362, 0.015967710812886556, 0.015972709655761717, 0.01597892920176188, 0.01598636786142985, 0.01599500815073649, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.01621699333190918, 0.01618127981821696, 0.016151111920674643, 0.016122924486796062, 0.016098570823669434, 0.01607600212097168, 0.016056203842163087, 0.0160392951965332, 0.016025071144104005, 0.016012679735819497, 0.0160023832321167, 0.015994478861490885, 0.015989651679992677, 0.015987615585327148, 0.015987730026245116, 0.01598934809366862, 0.015992563565572104, 0.015997648239135742, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.016437753041585287, 0.01638392925262451, 0.016333869298299154, 0.016287328402201335, 0.01624392032623291, 0.016204082171122233, 0.01616854508717855, 0.016137285232543944, 0.016109743118286134, 0.01608543554941813, 0.016064577102661133, 0.016046751340230307, 0.016031770706176757, 0.0160198179880778, 0.016010953585306804, 0.016005101203918456, 0.016002176602681478, 0.016002105077107746, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016111135482788086, 0.016088620821634928, 0.016068193117777508, 0.01604984124501546, 0.01603354771931966, 0.016019304593404133, 0.01600708802541097, 0.015996861457824706, 0.01598857879638672, 0.015982184410095215, 0.015977625846862794, 0.015974852244059246, 0.015973844528198243, 0.015974575678507488, 0.015977056821187337, 0.015981310208638508, 0.015987340609232584, 0.01599518140157064, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015954318046569823, 0.015944984753926594, 0.015937217076619468, 0.015930282274882, 0.01592488924662272, 0.015921705563863117, 0.015919397672017416, 0.01591888745625814, 0.015919747352600096, 0.015921161969502766, 0.015924652417500813, 0.01592873255411784, 0.01593451976776123, 0.015942087173461916, 0.015952102343241372, 0.01596367359161377, 0.015976246198018393, 0.015989753405253094, 0.01600484848022461], "lorahub/flan_t5_large-sciq_Multiple_Choice_Question_First+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015518120129903158, 0.015543025334676107, 0.015568749109903971, 0.015594236056009929, 0.015620096524556478, 0.01564723491668701, 0.01567492167154948, 0.015702064832051596, 0.015729126930236818, 0.015757060050964354, 0.01578547477722168, 0.015813212394714355, 0.015840471585591633, 0.015867708524068196, 0.01589512507120768, 0.015922616322835287, 0.01595005989074707, 0.015977452596028646, 0.01600484848022461], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-quartz_having_read_above_passage": [0.015892011324564616, 0.015895438194274903, 0.01589942773183187, 0.015903983116149902, 0.015909101168314618, 0.015914780298868815, 0.015921030044555664, 0.01592783768971761, 0.015935214360555013, 0.01594315528869629, 0.015951673189798992, 0.015960755348205565, 0.015970414479573567, 0.0159806489944458, 0.01599145571390788, 0.01600285212198893, 0.016014827092488606, 0.016027379035949706, 0.016040517489115398, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-wmt16_translate_tr-en": [0.016640814145406087, 0.016572615305582683, 0.016509103775024413, 0.01644979476928711, 0.01639402230580648, 0.016343005498250327, 0.016297343571980795, 0.016256462732950845, 0.016219971974690755, 0.01618752320607503, 0.016158881187438964, 0.016133837699890137, 0.016112257639567057, 0.016094061533610027, 0.016079233487447102, 0.016067744890848796, 0.016059563954671223, 0.016054625511169433, 0.01605286916097005, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-true_case": [0.019832337697347005, 0.019450572331746418, 0.019092726707458495, 0.01875810941060384, 0.018445876439412433, 0.018155911763509114, 0.01788769245147705, 0.017639792760213217, 0.017411672274271647, 0.017202828725179035, 0.017012739181518556, 0.016841190656026205, 0.016687506039937336, 0.016550567944844562, 0.01642987092336019, 0.01632497151692708, 0.016235329310099283, 0.016160529454549155, 0.01610026200612386, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1": [0.014645047187805176, 0.014678614934285482, 0.014734989802042643, 0.014809511502583821, 0.014895366032918295, 0.014989337921142577, 0.015090282758076985, 0.015192674001057943, 0.015295333862304687, 0.01539525826772054, 0.015490307807922363, 0.015579476356506347, 0.015662865638732912, 0.015739693641662597, 0.01580947717030843, 0.015872147878011066, 0.015927675565083822, 0.015976370175679523, 0.01601850668589274, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-qasc_is_correct_1": [0.0162496821085612, 0.016240981419881183, 0.01623027801513672, 0.016217867533365887, 0.016204080581665038, 0.01618924140930176, 0.016173680623372395, 0.0161577304204305, 0.016141727765401206, 0.016126020749409994, 0.01611094315846761, 0.016096824010213215, 0.016083998680114744, 0.01607277552286784, 0.01606345812479655, 0.016056321461995444, 0.016051618258158366, 0.016049580574035646, 0.016050405502319336, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.01439881165822347, 0.01455408255259196, 0.01470214049021403, 0.014845148722330729, 0.014978833198547363, 0.01510478178660075, 0.015221948623657227, 0.015331349372863769, 0.015432721773783365, 0.015526062647501627, 0.01561217466990153, 0.015690364837646485, 0.015761035283406576, 0.01582525889078776, 0.015882962544759113, 0.01593492031097412, 0.01598101615905762, 0.016020604769388835, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015964492162068685, 0.015965708096822104, 0.01596666971842448, 0.015967532793680825, 0.015968411763509115, 0.01596938451131185, 0.015970576604207358, 0.0159722105662028, 0.01597450892130534, 0.015977609952290854, 0.015981626510620118, 0.015986630121866862, 0.015992690722147623, 0.01599988301595052, 0.016008238792419433, 0.01601782004038493, 0.016028658548990885, 0.01604078451792399, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015607136090596517, 0.015632659594217935, 0.015656566619873045, 0.01568123499552409, 0.015707260767618816, 0.01573361078898112, 0.015759345690409342, 0.01578389644622803, 0.015807806650797528, 0.015831805864969888, 0.01585640589396159, 0.015881234804789226, 0.015905834833780923, 0.015930633544921875, 0.015955549875895182, 0.015980321566263833, 0.01600496768951416, 0.01602959632873535, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015958080291748045, 0.015954546928405762, 0.015952113469441732, 0.01595078150431315, 0.01595054308573405, 0.01595138867696126, 0.015953310330708823, 0.015956284205118815, 0.015960299173990885, 0.015965339342753092, 0.015971384048461913, 0.015978411038716635, 0.015986415545145672, 0.0159953769048055, 0.016005290349324543, 0.016016141573588053, 0.01602791945139567, 0.016040622393290203, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.016026921272277832, 0.01602036158243815, 0.016014823913574217, 0.01601029872894287, 0.01600674629211426, 0.016004169782002767, 0.01600254694620768, 0.016001863479614256, 0.016002111434936524, 0.016003284454345703, 0.01600537935892741, 0.016008378664652507, 0.016012282371520997, 0.016017082532246908, 0.016022768020629883, 0.01602933406829834, 0.016036771138509116, 0.016045068105061847, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016224149068196615, 0.01619507630666097, 0.016169994672139486, 0.016147424379984537, 0.016127438545227052, 0.01610937277475993, 0.016093007723490396, 0.016079166730244954, 0.016067352294921875, 0.016057785352071127, 0.01604977289835612, 0.01604334354400635, 0.016038633982340494, 0.016036621729532876, 0.016036399205525718, 0.016038428942362466, 0.01604214350382487, 0.016047306060791015, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.016441752115885416, 0.016391717592875162, 0.016345383326212565, 0.01630241870880127, 0.016262372334798176, 0.016225501696268716, 0.01619348367055257, 0.016165461540222168, 0.016140435536702472, 0.016118706067403156, 0.016100036303202312, 0.016084295908610026, 0.016071373621622722, 0.01606133778889974, 0.01605417569478353, 0.016049944559733072, 0.01604858080546061, 0.016050025622049966, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016116065979003905, 0.01609823226928711, 0.016082247098286945, 0.016068094571431477, 0.016055752436319987, 0.016045196851094564, 0.01603638490041097, 0.01602928320566813, 0.01602383772532145, 0.01602001190185547, 0.016017767588297527, 0.016017080942789714, 0.016017920176188152, 0.016020270983378094, 0.01602411111195882, 0.016029435793558755, 0.01603623072306315, 0.016044495900472005, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015959653854370117, 0.015955348014831543, 0.01595209280649821, 0.0159496275583903, 0.01594794273376465, 0.015947678883870442, 0.015950490633646647, 0.015952599843343098, 0.01595626990000407, 0.01596116860707601, 0.015966787338256835, 0.015973488489786785, 0.01598164876302083, 0.015990146001180015, 0.016000463167826336, 0.0160117769241333, 0.01602497895558675, 0.01603925069173177, 0.016054232915242512], "lorahub/flan_t5_large-wiqa_which_of_the_following_is_the_supposed_perturbation+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015529392560323079, 0.015564211209615071, 0.015599182446797689, 0.01563329855600993, 0.01566718578338623, 0.015700047810872395, 0.01573243459065755, 0.015765426953633626, 0.015797141393025717, 0.015827566782633463, 0.015857149759928385, 0.015886422793070475, 0.015914390881856283, 0.015940653483072918, 0.015965488751729328, 0.015989206631978354, 0.016011921564737956, 0.016033620834350587, 0.016054232915242512], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-wmt16_translate_tr-en": [0.016640814145406087, 0.01656754493713379, 0.01649885336558024, 0.0164345121383667, 0.016373782157897948, 0.01631648063659668, 0.01626340707143148, 0.01621492067972819, 0.016170601844787597, 0.016130110422770183, 0.01609314282735189, 0.016059460639953612, 0.016028892199198404, 0.01600127379099528, 0.01597647190093994, 0.01595437526702881, 0.01593491236368815, 0.01591805617014567, 0.015903768539428712, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-true_case": [0.019832337697347005, 0.0194353977839152, 0.019063496589660646, 0.0187159522374471, 0.018391871452331544, 0.01809104601542155, 0.017812503178914387, 0.017555127143859862, 0.017318385442097982, 0.017101621627807616, 0.01690438429514567, 0.01672616958618164, 0.016565802892049154, 0.01642236550649007, 0.016295409202575682, 0.01618450164794922, 0.016089154879252117, 0.016008896827697752, 0.015943295160929363, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1": [0.014645047187805176, 0.014674142201741536, 0.014726920127868652, 0.014798253377278647, 0.014880270957946777, 0.014970304171244304, 0.015066417058308919, 0.015163588523864745, 0.015260348320007324, 0.015352760950724284, 0.01543952465057373, 0.015519525210062663, 0.015592883427937826, 0.01565889835357666, 0.01571662743886312, 0.0157663361231486, 0.01580850601196289, 0.015843404134114582, 0.01587119261423747, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-qasc_is_correct_1": [0.0162496821085612, 0.016237120628356933, 0.01622268994649251, 0.016206560134887697, 0.016188920338948566, 0.016169991493225098, 0.016149999300638835, 0.016129171053568522, 0.01610774040222168, 0.01608592669169108, 0.016063950856526694, 0.01604202111562093, 0.01602034250895182, 0.015999108950297037, 0.01597851753234863, 0.015958765347798665, 0.015940057436625164, 0.015922571818033856, 0.015906503995259603, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.0143918244043986, 0.014539291063944498, 0.01467900276184082, 0.014813149770100911, 0.014937748908996582, 0.015054251352945964, 0.015161957740783692, 0.01526212215423584, 0.015353864034016926, 0.015438265800476074, 0.0155149507522583, 0.015584171613057455, 0.01564615567525228, 0.015701697667439778, 0.015751883188883462, 0.015796135266621908, 0.01583389123280843, 0.015865766207377115, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015962254206339517, 0.015960640907287597, 0.01595818519592285, 0.01595505396525065, 0.015951352119445802, 0.015947143236796062, 0.015942598978678387, 0.01593794345855713, 0.01593329111735026, 0.015928678512573242, 0.015924118359883627, 0.01591964562733968, 0.015915274620056152, 0.01591102441151937, 0.015906912485758463, 0.015902945200602214, 0.015899136861165366, 0.01589548428853353, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015599541664123535, 0.015617594718933106, 0.015633638699849448, 0.0156507142384847, 0.015668700536092123, 0.01568684260050456, 0.015704131126403807, 0.01572022755940755, 0.01573543071746826, 0.0157509978612264, 0.015767587025960286, 0.01578423023223877, 0.015800410906473796, 0.015816035270690917, 0.015831365585327148, 0.015846606890360514, 0.015861811637878417, 0.01587695598602295, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015949139595031737, 0.015936678250630696, 0.01592534859975179, 0.01591515064239502, 0.015906093915303548, 0.01589816729227702, 0.015891372362772625, 0.015885683695475262, 0.015881091753641764, 0.015877588589986166, 0.015875142415364585, 0.015873748461405435, 0.015873376528422037, 0.01587402025858561, 0.01587566375732422, 0.015878289540608725, 0.015881900787353517, 0.015886475245157877, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.016022146542867023, 0.016010359128316245, 0.015999170939127606, 0.015988569259643554, 0.015978541374206543, 0.015969074567159017, 0.01596015930175781, 0.01595178445180257, 0.015943930943806965, 0.015936594009399414, 0.015929756164550782, 0.015923409461975097, 0.01591754754384359, 0.015912156105041503, 0.01590722719828288, 0.015902752876281737, 0.015898733139038085, 0.015895152091979982, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016217870712280272, 0.01618224302927653, 0.016150856018066408, 0.016120988527933755, 0.016094109217325847, 0.0160685396194458, 0.01604466438293457, 0.0160232146581014, 0.016003236770629883, 0.0159853728612264, 0.015968705813090008, 0.015953461329142254, 0.015939698219299317, 0.015928468704223632, 0.01591890017191569, 0.01591034730275472, 0.015902881622314454, 0.015896778106689453, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.01643146832784017, 0.016371445655822756, 0.01631537914276123, 0.01626284122467041, 0.01621350606282552, 0.01616780916849772, 0.016127010981241863, 0.0160902738571167, 0.016056989034016925, 0.01602750301361084, 0.016000561714172364, 0.015976668993632, 0.015956058502197265, 0.015938491821289064, 0.0159237273534139, 0.01591170787811279, 0.015902434984842936, 0.01589587370554606, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016106845537821452, 0.01607980251312256, 0.016054649353027344, 0.016031368573506673, 0.016009944279988607, 0.015990365346272788, 0.015972617467244467, 0.015956672032674153, 0.015942494074503582, 0.015930069287618, 0.015919353167215985, 0.015910325050354005, 0.01590295155843099, 0.015897199312845865, 0.0158930508295695, 0.015890474319458007, 0.015889453887939452, 0.01588997522989909, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015949791272481282, 0.01593576431274414, 0.01592313766479492, 0.01591129461924235, 0.01590064525604248, 0.015891725222269695, 0.015884833335876467, 0.01587910016377767, 0.015874276161193846, 0.015870316823323568, 0.01586768627166748, 0.01586635907491048, 0.01586576779683431, 0.015866463979085286, 0.01586940129597982, 0.015873665809631347, 0.015878615379333497, 0.015884655316670736, 0.015892011324564616], "lorahub/flan_t5_large-quartz_having_read_above_passage+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015521189371744792, 0.015548138618469239, 0.01557543118794759, 0.015601903597513834, 0.01562839190165202, 0.015654497146606446, 0.0156794802347819, 0.0157037083307902, 0.015727593104044597, 0.015750376383463542, 0.015772151947021484, 0.01579289118448893, 0.01581217924753825, 0.015829604466756186, 0.015845165252685547, 0.015859088897705077, 0.0158715295791626, 0.01588252067565918, 0.015892011324564616], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-true_case": [0.019832337697347005, 0.019504443804423014, 0.01919757843017578, 0.018911042213439942, 0.018644089698791503, 0.018396682739257812, 0.018168133099873862, 0.01795724074045817, 0.017763805389404298, 0.017586900393168133, 0.0174258295694987, 0.017280996640523273, 0.01715177059173584, 0.017037340799967448, 0.016937748591105143, 0.01685231685638428, 0.016779886881510418, 0.016720293362935384, 0.016674044926961264, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1": [0.014645047187805176, 0.014690430959065755, 0.014759368896484375, 0.014847826957702637, 0.014948933919270834, 0.01505932331085205, 0.01517780621846517, 0.015299019813537597, 0.015422616004943848, 0.015545949935913086, 0.015668182373046874, 0.01578927993774414, 0.015907142957051593, 0.016022847493489582, 0.01613513469696045, 0.016243526140848796, 0.01634798208872477, 0.016448686917622884, 0.016546295483907063, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-qasc_is_correct_1": [0.0162496821085612, 0.01625936190287272, 0.016269950866699218, 0.016281412442525227, 0.016293719609578452, 0.016306899388631186, 0.016320972442626952, 0.016335999170939128, 0.016352066993713377, 0.016369282404581707, 0.016387802759806315, 0.01640784740447998, 0.01642967383066813, 0.016453380584716796, 0.01647890567779541, 0.016506231625874838, 0.01653557300567627, 0.01656743049621582, 0.016602409680684407, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.014389257431030273, 0.014538254737854004, 0.014683915774027506, 0.014828473726908365, 0.014968260129292806, 0.015104435284932454, 0.015236385663350423, 0.015365384419759114, 0.01549092928568522, 0.015613190333048503, 0.01573320706685384, 0.015850346883138022, 0.015966033935546874, 0.016081199645996094, 0.016195255915323892, 0.01630768140157064, 0.016418523788452148, 0.016529434521993, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.01597533384958903, 0.01598973592122396, 0.016006127993265788, 0.016024595896402996, 0.016045220692952476, 0.016068097750345865, 0.016093304951985677, 0.01612096627553304, 0.016151229540507, 0.016184306144714354, 0.016220482190450032, 0.01626009146372477, 0.016303494771321616, 0.016350954373677572, 0.016402109464009603, 0.01645634333292643, 0.016513803799947102, 0.01657514731089274, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015612338383992513, 0.01564583937327067, 0.01567965348561605, 0.015716649691263834, 0.015757721265157065, 0.015801806449890137, 0.015846967697143555, 0.015893840789794923, 0.01594424565633138, 0.015998665491739908, 0.016055294672648112, 0.016114821434020998, 0.016177269617716473, 0.016244136492411295, 0.016315514246622722, 0.01639156977335612, 0.016471869150797527, 0.016554563840230307, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.01595805009206136, 0.015957434972127277, 0.015960893630981444, 0.015968459447224935, 0.01598016421000163, 0.01599602699279785, 0.016016103426615396, 0.016040492057800292, 0.016069332758585613, 0.016102803548177082, 0.016141147613525392, 0.016184655825297038, 0.016233657201131183, 0.016288401285807292, 0.016348463694254557, 0.016413307189941405, 0.016483187675476074, 0.01655894120534261, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.01603398323059082, 0.016036712328592936, 0.016042715708414715, 0.016051993370056153, 0.016064600944519045, 0.016080582936604818, 0.016099953651428224, 0.01612266222635905, 0.016148710250854494, 0.0161782439549764, 0.016211590766906737, 0.0162491242090861, 0.016291128794352214, 0.016337796847025552, 0.01638981342315674, 0.016446555455525716, 0.016506861050923666, 0.016571435928344726, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016242818832397463, 0.01623351256052653, 0.016229186058044433, 0.016229159037272137, 0.016232852935791017, 0.016239407857259115, 0.016248373985290526, 0.016260774930318196, 0.016276583671569825, 0.016295922597249348, 0.01631820837656657, 0.016343990961710613, 0.01637518564860026, 0.01641043186187744, 0.016450438499450683, 0.01649240970611572, 0.016537599563598633, 0.016586976051330568, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.01646957079569499, 0.016447339057922363, 0.01642879009246826, 0.016413768132527668, 0.016401947339375812, 0.016392982800801596, 0.016387311617533366, 0.016385671297709146, 0.01638860861460368, 0.01639552434285482, 0.016405650774637858, 0.0164197572072347, 0.016438417434692383, 0.016461904843648276, 0.016490351359049478, 0.0165234104792277, 0.016559243202209473, 0.016598151524861653, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016137752532958984, 0.016141932805379233, 0.016148386001586915, 0.016157259941101076, 0.016168702443440756, 0.016182745297749837, 0.016199286778767905, 0.016218264897664387, 0.01623983383178711, 0.016264249483744303, 0.016291731198628742, 0.016322507858276367, 0.0163569180170695, 0.016395530700683593, 0.01643830458323161, 0.016484058698018392, 0.016532615025838217, 0.016584803263346354, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015968214670817056, 0.01597479820251465, 0.015984296798706055, 0.01599722385406494, 0.016013046900431316, 0.016031963030497233, 0.01605483373006185, 0.016082269350687663, 0.01611300468444824, 0.016147724787394204, 0.016186461448669434, 0.016228644053141277, 0.016274914741516114, 0.016325003306070965, 0.016379114786783854, 0.016438112258911133, 0.016500234603881836, 0.016567465464274088, 0.016640814145406087], "lorahub/flan_t5_large-wmt16_translate_tr-en+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015522244771321615, 0.015554431279500326, 0.015589812596638997, 0.01562823454538981, 0.015669727325439455, 0.015714739163716632, 0.01576403299967448, 0.01581756114959717, 0.015873589515686036, 0.01593269983927409, 0.015995192527770995, 0.016061007181803387, 0.016130884488423664, 0.016206072171529133, 0.016286067962646485, 0.01637107054392497, 0.016458579699198405, 0.01654822826385498, 0.016640814145406087], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1": [0.014645047187805176, 0.014702863693237304, 0.014798645973205566, 0.014928507804870605, 0.01508952299753825, 0.015278108914693196, 0.015490263303120932, 0.01572479248046875, 0.015980188051859537, 0.0162535301844279, 0.01654288450876872, 0.01684728781382243, 0.01716605027516683, 0.01749897321065267, 0.017846283912658693, 0.018208481470743814, 0.018586958249409993, 0.018982704480489096, 0.01939724604288737, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-qasc_is_correct_1": [0.0162496821085612, 0.01629037380218506, 0.016344518661499025, 0.016412429809570313, 0.016494450569152833, 0.01659101327260335, 0.01670257091522217, 0.016829633712768556, 0.01697265307108561, 0.017132035891215005, 0.017308808962504068, 0.017504140535990396, 0.017718488375345866, 0.01795257568359375, 0.01820729414621989, 0.018483827908833822, 0.018783702850341796, 0.019107572237650552, 0.019456758499145507, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.014431571960449219, 0.014635292689005534, 0.01484833558400472, 0.015070716540018717, 0.01530239741007487, 0.015544336636861165, 0.0157968012491862, 0.016059166590372723, 0.016331459681193036, 0.01661539395650228, 0.016911443074544272, 0.017220463752746582, 0.017543079058329265, 0.01788032054901123, 0.018233256340026857, 0.01860350767771403, 0.018992916742960612, 0.019401938120524088, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.016010538736979166, 0.01607157548268636, 0.01614641030629476, 0.01623509724934896, 0.0163388188680013, 0.016458353996276855, 0.01659416357676188, 0.016747026443481444, 0.016917834281921385, 0.017107478777567544, 0.017316888173421224, 0.017546552022298177, 0.017797908782958984, 0.01807266553243001, 0.01837149461110433, 0.018695165316263834, 0.019045713742574057, 0.019424484570821125, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015659470558166504, 0.015749796231587728, 0.015853559176127116, 0.01596954345703125, 0.01609992027282715, 0.016244627634684244, 0.016405102411905924, 0.016582314173380533, 0.01677658557891846, 0.01698830763498942, 0.017218000094095867, 0.01746648629506429, 0.017735071182250976, 0.018025328318277994, 0.018338065147399902, 0.018673632939656574, 0.01903384526570638, 0.01941953182220459, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.01600046952565511, 0.016053741772969563, 0.016122870445251465, 0.016208181381225584, 0.016310030619303386, 0.016428990364074705, 0.016565926869710288, 0.016721471150716146, 0.016896026929219564, 0.017090147336324055, 0.017304499944051106, 0.017539715766906737, 0.017796235084533693, 0.018075111707051596, 0.018377291361490886, 0.01870361010233561, 0.019054346084594727, 0.019430255889892577, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.016084707578023275, 0.016148943901062012, 0.016227518717447917, 0.01632078011830648, 0.016429171562194825, 0.016553165117899577, 0.016693275769551597, 0.016849964459737143, 0.017023423512776692, 0.01721409797668457, 0.017423243522644044, 0.017651503880818684, 0.01789921760559082, 0.018167087237040202, 0.018455510139465333, 0.018765646616617837, 0.01909802754720052, 0.01945341904958089, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016294450759887696, 0.01634752591451009, 0.016414812405904134, 0.01649668057759603, 0.01659442901611328, 0.016708250045776366, 0.016837987899780273, 0.016984203656514485, 0.017147084871927898, 0.017327605883280438, 0.017525830268859864, 0.017742287317911783, 0.017977565129597983, 0.018232512474060058, 0.018508100509643556, 0.018804934819539387, 0.0191242520014445, 0.019466241200764973, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.016553228696187337, 0.016622468630472818, 0.016704071362813315, 0.016797768274943035, 0.016903263727823893, 0.017021978696187337, 0.017153679529825848, 0.017297857602437336, 0.017456544240315754, 0.017629014650980632, 0.0178151798248291, 0.018014723459879558, 0.018229333559672038, 0.01845810890197754, 0.018701356252034507, 0.018960094451904295, 0.019234938621520994, 0.01952572027842204, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.01618256409962972, 0.016243398984273273, 0.016318496068318686, 0.016408162117004396, 0.016512444814046224, 0.016631399790445964, 0.01676627000172933, 0.01691789150238037, 0.017086488405863444, 0.017272475560506186, 0.01747637748718262, 0.01769876797993978, 0.01794005076090495, 0.018201133410135906, 0.01848310947418213, 0.018786768913269043, 0.019112335840861003, 0.019460539817810058, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.016019714673360188, 0.01608889102935791, 0.016171932220458984, 0.016269615491231283, 0.016382404963175456, 0.016510284741719564, 0.016654001871744793, 0.01681444009145101, 0.016991674105326336, 0.017186443010965984, 0.017401215235392252, 0.017632964452107748, 0.017884456316630045, 0.01815535545349121, 0.01844613234202067, 0.018758230209350586, 0.01909274737040202, 0.019450403849283853, 0.019832337697347005], "lorahub/flan_t5_large-true_case+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015584430694580077, 0.01568771044413249, 0.01580321470896403, 0.01593319574991862, 0.016077148119608562, 0.016234819094340006, 0.01640647570292155, 0.01659407138824463, 0.016797162691752115, 0.01701704502105713, 0.017253464063008626, 0.017507068316141763, 0.017777775128682453, 0.018067827224731447, 0.0183776330947876, 0.01870779355367025, 0.019059926668802896, 0.01943464756011963, 0.019832337697347005], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-qasc_is_correct_1": [0.0162496821085612, 0.01622012774149577, 0.016182104746500652, 0.01613534609476725, 0.01607966740926107, 0.016014822324117026, 0.015940434137980145, 0.015856583913167317, 0.015764172871907553, 0.015664507548014323, 0.015557457605997721, 0.01544441858927409, 0.015327054659525554, 0.015209248860677083, 0.01509195327758789, 0.014979831377665202, 0.014874773025512695, 0.014779518445332845, 0.01470141569773356, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.014354190826416015, 0.014459055264790853, 0.014551151593526204, 0.01462982177734375, 0.014694854418436687, 0.014746692975362142, 0.01478319009145101, 0.014805787404378256, 0.014815799395243327, 0.014814516703287761, 0.014803770383199057, 0.014785699844360352, 0.014762660662333171, 0.01473603089650472, 0.014707773526509604, 0.014680728912353516, 0.014658803939819337, 0.01464548905690511, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015940837860107422, 0.01591058890024821, 0.01587184429168701, 0.015824193954467772, 0.015768327713012696, 0.015703930854797363, 0.01563118616739909, 0.015550382932027181, 0.01546125094095866, 0.015366673469543457, 0.015268381436665852, 0.015167349179585775, 0.015066189765930176, 0.014969162940979004, 0.014877111117045084, 0.014796075820922851, 0.014725359280904134, 0.014673544565836588, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015580917994181315, 0.015572834014892577, 0.015555434226989746, 0.015530818303426107, 0.015499760309855143, 0.015461111068725586, 0.015414247512817383, 0.015358535448710124, 0.015295044581095377, 0.015225348472595214, 0.015150314966837565, 0.015071500142415364, 0.0149907652537028, 0.014912749926249186, 0.01483914852142334, 0.014770857493082682, 0.01471259593963623, 0.014669259389241537, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015925445556640626, 0.015882275899251303, 0.015833072662353516, 0.015777688026428222, 0.015715818405151367, 0.015647546450297038, 0.015573420524597169, 0.015493273735046387, 0.015407408078511556, 0.01531666914621989, 0.015221897761027019, 0.015125988324483235, 0.015030692418416342, 0.01493743101755778, 0.014851861000061035, 0.014774529139200847, 0.014710378646850587, 0.014665651321411132, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.015976359049479166, 0.015913764635721844, 0.015846624374389648, 0.015774890581766763, 0.015698617299397786, 0.015617915789286296, 0.015532541275024413, 0.015442948341369628, 0.01535153071085612, 0.01525882879892985, 0.015165756543477377, 0.015073664983113607, 0.014985365867614746, 0.014901504516601563, 0.014825401306152343, 0.014758922259012859, 0.014702994028727214, 0.014664090474446615, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.01617396672566732, 0.016090736389160157, 0.016005484263102214, 0.015918386777242024, 0.015830297470092774, 0.015739668210347495, 0.015646150906880697, 0.015550454457600912, 0.015452976226806641, 0.015354379018147787, 0.015255740483601888, 0.01515837828318278, 0.015063320795694987, 0.01497151533762614, 0.01488506317138672, 0.014806458155314128, 0.014738141695658366, 0.01468306064605713, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.016400993665059406, 0.016303278605143228, 0.016202837626139322, 0.0160990842183431, 0.01599165121714274, 0.015882585843404132, 0.015771808624267577, 0.015658364295959473, 0.01554288387298584, 0.015426255861918132, 0.01530906359354655, 0.015195364952087403, 0.015085905392964682, 0.014981490770975749, 0.014884848594665528, 0.014800672531127929, 0.014728056589762369, 0.014675075213114421, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.01607480525970459, 0.016009931564331056, 0.01594093958536784, 0.01586767832438151, 0.015790085792541503, 0.015708104769388834, 0.015621067682902019, 0.015530171394348145, 0.015437207221984862, 0.015342205365498861, 0.015245885848999023, 0.015149087905883788, 0.015053863525390626, 0.014961557388305664, 0.014875370661417643, 0.014797716140747071, 0.01472983678181966, 0.014677993456522624, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015913785298665363, 0.015859738985697428, 0.01580128351847331, 0.015738841692606607, 0.01567223866780599, 0.015600822766621907, 0.01552491823832194, 0.015445028940836589, 0.015361406008402507, 0.015274497667948405, 0.015185470581054688, 0.015095842679341635, 0.015007433891296386, 0.014922189712524413, 0.014842325846354167, 0.014770716031392416, 0.014710934956868489, 0.01466724395751953, 0.014645047187805176], "lorahub/flan_t5_large-wiki_hop_original_choose_best_object_interrogative_1+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.01548218568166097, 0.015465157826741537, 0.01544231096903483, 0.015413886706034342, 0.015379877090454101, 0.015339891115824381, 0.015292668342590332, 0.0152414337793986, 0.015185980796813965, 0.015124251047770182, 0.015058668454488118, 0.014992926915486654, 0.014926487604777019, 0.014862276713053386, 0.014800365765889485, 0.014745585123697917, 0.01469802220662435, 0.014663356145222982, 0.014645047187805176], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_": [0.01423896312713623, 0.014420836766560873, 0.014597514470418294, 0.014766252835591635, 0.014928881327311199, 0.015081249872843424, 0.015224550565083822, 0.015357861518859863, 0.015482412974039713, 0.015597016016642252, 0.01570262591044108, 0.015798436800638836, 0.015884742736816407, 0.015961546897888184, 0.016029911041259767, 0.01609017531077067, 0.01614274024963379, 0.016186494827270508, 0.016222000122070312, 0.0162496821085612], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015980243682861328, 0.015997079213460285, 0.01601330598195394, 0.01602900505065918, 0.01604429880777995, 0.016059303283691408, 0.01607411543528239, 0.016088774998982747, 0.01610332171122233, 0.016117784182230633, 0.016132264137268065, 0.016146844228108723, 0.01616153875986735, 0.016176307996114095, 0.01619110584259033, 0.01620589256286621, 0.016220606168111166, 0.016235218048095704, 0.0162496821085612], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015622859001159667, 0.015664342244466146, 0.015704615910847982, 0.01574769655863444, 0.015791789690653483, 0.015834161440531413, 0.015874457359313966, 0.015913828214009603, 0.015952779452006023, 0.015990926424662273, 0.01602802276611328, 0.016063939730326333, 0.016097742716471353, 0.016129043896993, 0.016158018112182617, 0.016184674898783367, 0.016208915710449218, 0.016230624516805015, 0.0162496821085612], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015953853925069175, 0.0159492826461792, 0.01594880739847819, 0.01595219612121582, 0.0159592072168986, 0.015969556172688804, 0.015982925097147625, 0.015998981793721518, 0.016017367045084635, 0.016037726402282716, 0.016059678395589194, 0.01608285903930664, 0.01610689957936605, 0.01613144556681315, 0.016156139373779296, 0.016180631319681803, 0.016204593976338704, 0.016227704683939616, 0.0162496821085612], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.016038570404052734, 0.01604451020558675, 0.016052193641662597, 0.016061450640360516, 0.016072076161702475, 0.016083881060282388, 0.016096634864807127, 0.016110105514526366, 0.016124053001403807, 0.01613826910654704, 0.01615256627400716, 0.016166764895121255, 0.016180702845255534, 0.016194198926289875, 0.016207087834676108, 0.01621921221415202, 0.01623042106628418, 0.016240599950154623, 0.0162496821085612], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016236015955607096, 0.016219666798909505, 0.01620757261912028, 0.0161991818745931, 0.016193563143412273, 0.016189978917439778, 0.01618781089782715, 0.01618779977162679, 0.01618895371754964, 0.016191776593526205, 0.016195160547892253, 0.01619921048482259, 0.016203625996907552, 0.01620962142944336, 0.01621679464975993, 0.016224530537923176, 0.01623237133026123, 0.016240727106730142, 0.0162496821085612], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.016456246376037598, 0.016421809196472167, 0.016391622225443523, 0.016365323066711426, 0.01634260336558024, 0.016323566436767578, 0.01630804220835368, 0.01629572868347168, 0.016286714871724447, 0.016279910405476886, 0.016274997393290202, 0.016271708806355794, 0.016269057591756186, 0.016266711552937827, 0.01626447359720866, 0.01626241366068522, 0.01625953197479248, 0.01625534216562907, 0.0162496821085612], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016120468775431315, 0.016108659108479816, 0.016100239753723145, 0.016095136006673175, 0.016093204816182455, 0.016094223658243815, 0.01609791119893392, 0.01610399087270101, 0.01611219882965088, 0.016122299830118814, 0.016134026845296225, 0.01614709218343099, 0.01616117318471273, 0.016175928115844725, 0.016191031138102215, 0.01620617707570394, 0.016221113204956054, 0.01623565355936686, 0.0162496821085612], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015977827707926433, 0.015991665522257486, 0.016006474494934083, 0.01602166493733724, 0.0160372257232666, 0.016053611437479656, 0.016071608861287435, 0.01608881950378418, 0.016106216112772624, 0.01612328370412191, 0.01613961378733317, 0.016156098047892253, 0.016171282132466634, 0.016185622215270996, 0.016200191179911297, 0.016214432716369628, 0.016227270762125653, 0.016238946914672852, 0.0162496821085612], "lorahub/flan_t5_large-qasc_is_correct_1+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015535451571146648, 0.015578374862670899, 0.015622344017028809, 0.015666782061258953, 0.015711072285970053, 0.015756392478942872, 0.01580214500427246, 0.015847414334615072, 0.01589196840922038, 0.015935848553975424, 0.01597882906595866, 0.016019743283589682, 0.016059250831604005, 0.016097469329833983, 0.01613346258799235, 0.01616690476735433, 0.016197527249654134, 0.016225131352742513, 0.0162496821085612], "lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_+lorahub/flan_t5_large-race_middle_Is_this_the_right_answer": [0.0159627898534139, 0.015933977762858074, 0.015899017651875815, 0.015857040087382, 0.015809154510498045, 0.015754783948262532, 0.015692820549011232, 0.015624690055847167, 0.015550494194030762, 0.015469662348429362, 0.015380984942118326, 0.015284043947855631, 0.015180055300394695, 0.01506766160329183, 0.014948229789733886, 0.014820117950439454, 0.01468411922454834, 0.014541648228963215, 0.014392879803975423, 0.01423896312713623], "lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015561704635620116, 0.015537068049112956, 0.015506291389465332, 0.015470147132873535, 0.015430089632670084, 0.01538578987121582, 0.015335582097371419, 0.015278608004252115, 0.015214935938517252, 0.015145300229390462, 0.015070203145345053, 0.014988271395365398, 0.014899112383524577, 0.01480332056681315, 0.014701209068298339, 0.014593118031819662, 0.014479351043701173, 0.014360761642456055, 0.01423896312713623], "lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015926982561747235, 0.01588594595591227, 0.015839769045511883, 0.015788081487019857, 0.01573114236195882, 0.015668907165527345, 0.015600446065266928, 0.015525595347086588, 0.01544374148050944, 0.015355644226074218, 0.015260343551635741, 0.015157761573791504, 0.015048274993896485, 0.014930783907572428, 0.014806060791015626, 0.014672509829203288, 0.014534227053324382, 0.014388933181762695, 0.01423896312713623], "lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.015987943013509115, 0.015936614672342937, 0.015880719820658366, 0.015819977124532064, 0.015754526456197102, 0.015685248374938964, 0.015611208279927572, 0.015531102816263834, 0.0154447603225708, 0.015352433522542317, 0.01525399367014567, 0.015149235725402832, 0.015038433074951172, 0.014920568466186524, 0.014795953432718913, 0.014664076169331868, 0.014527875582377116, 0.014385418891906738, 0.01423896312713623], "lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016167763074239096, 0.01607932726542155, 0.01598990281422933, 0.01589932441711426, 0.01580801486968994, 0.015715460777282714, 0.015621240933736165, 0.015525062878926596, 0.01542624314626058, 0.015324296951293946, 0.015218976338704428, 0.015109818776448567, 0.01499655564626058, 0.014879549344380696, 0.014758467674255371, 0.014633407592773437, 0.014504793485005697, 0.014372528394063314, 0.01423896312713623], "lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.016409138043721516, 0.016319483121236166, 0.01622624397277832, 0.0161292823155721, 0.016032360394795737, 0.01592953681945801, 0.0158250363667806, 0.015715376536051432, 0.015604562759399414, 0.01548939069112142, 0.01536898136138916, 0.015244216918945312, 0.015114347139994303, 0.014979594548543295, 0.014839925765991212, 0.014694161415100097, 0.01454621156056722, 0.014393717447916666, 0.01423896312713623], "lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016067983309427897, 0.015997600555419923, 0.015924612681070965, 0.015847676595052082, 0.015768195788065594, 0.0156869109471639, 0.015601730346679688, 0.01551252841949463, 0.015418782234191894, 0.015321170488993327, 0.015218744277954102, 0.015112155278523763, 0.015000754992167156, 0.014884390830993653, 0.014762608210245769, 0.0146365753809611, 0.014507465362548828, 0.014374151229858398, 0.01423896312713623], "lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.01591519355773926, 0.015862463315327962, 0.015805761019388836, 0.015745210647583007, 0.015680632591247558, 0.015611993471781412, 0.01553901195526123, 0.015461106300354004, 0.015378451347351075, 0.015290738741556804, 0.015197243690490723, 0.015097983678181966, 0.014992817242940267, 0.01488158384958903, 0.014764237403869628, 0.014640941619873046, 0.014511855443318684, 0.014377145767211915, 0.01423896312713623], "lorahub/flan_t5_large-sciq_Direct_Question_Closed_Book_+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.01546915054321289, 0.015440524419148763, 0.01540879249572754, 0.015372808774312336, 0.015332307815551758, 0.015286870002746582, 0.015238010088602701, 0.0151859982808431, 0.015128151575724284, 0.015065091451009115, 0.014996210734049479, 0.014922318458557128, 0.01484217643737793, 0.014756174087524413, 0.01466368834177653, 0.014564762115478516, 0.014460288683573404, 0.014351851145426432, 0.01423896312713623], "lorahub/flan_t5_large-race_middle_Is_this_the_right_answer+lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer": [0.01558108647664388, 0.015603109995524089, 0.015624896685282389, 0.015645848910013836, 0.015667729377746582, 0.01569016933441162, 0.015712725321451824, 0.015734186172485353, 0.01575533866882324, 0.015776740709940593, 0.015798481305440266, 0.015819834073384602, 0.01584048589070638, 0.015860490798950196, 0.015880106290181478, 0.015899518330891926, 0.015917601585388182, 0.015933977762858074, 0.01594910462697347, 0.0159627898534139], "lorahub/flan_t5_large-race_middle_Is_this_the_right_answer+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.015950943628946942, 0.015940758387247723, 0.015932159423828127, 0.015925148328145344, 0.015919721921284994, 0.015915837287902832, 0.015913429260253905, 0.015912423133850096, 0.01591272989908854, 0.015914249420166015, 0.015916876792907715, 0.015920510292053224, 0.015925073623657228, 0.015930534998575847, 0.01593661944071452, 0.015942943890889485, 0.01594947655995687, 0.015956164995829265, 0.0159627898534139], "lorahub/flan_t5_large-race_middle_Is_this_the_right_answer+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.01602400779724121, 0.016014660199483235, 0.016006433169047037, 0.015999285380045573, 0.015993167559305826, 0.015988022486368814, 0.01598381519317627, 0.015980475743611652, 0.015977950096130372, 0.015976141293843588, 0.015974880854288737, 0.015973987579345702, 0.015973307291666666, 0.015972690582275392, 0.0159719451268514, 0.01597084363301595, 0.01596912701924642, 0.015966540972391766, 0.0159627898534139], "lorahub/flan_t5_large-race_middle_Is_this_the_right_answer+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016216605504353842, 0.01618087609608968, 0.01615126132965088, 0.016123809814453126, 0.016099753379821776, 0.01607776959737142, 0.016058863004048664, 0.016042370796203614, 0.0160282293955485, 0.016015496253967285, 0.016004406611124674, 0.01599649906158447, 0.01599027156829834, 0.0159843905766805, 0.015979239145914714, 0.015974666277567547, 0.01597095807393392, 0.015966835021972655, 0.0159627898534139], "lorahub/flan_t5_large-race_middle_Is_this_the_right_answer+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.01644087314605713, 0.0163903013865153, 0.016343393325805665, 0.016299818356831867, 0.016259212493896485, 0.016221599578857424, 0.01618717670440674, 0.0161562442779541, 0.016128867467244467, 0.016104469299316405, 0.016082431475321454, 0.01606220245361328, 0.016044001579284668, 0.016027617454528808, 0.01601270039876302, 0.015999013582865398, 0.01598629633585612, 0.0159743070602417, 0.0159627898534139], "lorahub/flan_t5_large-race_middle_Is_this_the_right_answer+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016109460194905598, 0.01608572483062744, 0.01606448491414388, 0.016045668919881184, 0.016029189427693685, 0.016014962196350097, 0.01600286642710368, 0.015992790857950846, 0.01598458449045817, 0.015978097915649414, 0.015973153114318846, 0.015969581604003906, 0.015967178344726562, 0.015965614318847656, 0.01596458594004313, 0.01596392790476481, 0.015963524182637533, 0.015963207880655923, 0.0159627898534139], "lorahub/flan_t5_large-race_middle_Is_this_the_right_answer+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.01595336119333903, 0.01594327131907145, 0.015934926668802897, 0.015927561124165854, 0.015921874046325682, 0.015918889045715333, 0.015916579564412434, 0.015915635426839193, 0.015916015307108563, 0.015917202631632488, 0.015919440587361652, 0.015921982129414876, 0.015926701227823893, 0.015932765007019043, 0.01593838691711426, 0.015944320360819497, 0.015950789451599123, 0.015956934293111166, 0.0159627898534139], "lorahub/flan_t5_large-race_middle_Is_this_the_right_answer+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015516846974690756, 0.015540893872578938, 0.015565951665242514, 0.015591219266255696, 0.015616397857666015, 0.015642530123392742, 0.015669124921162923, 0.01569559097290039, 0.015721801122029623, 0.015748419761657716, 0.015775346755981447, 0.015801587104797364, 0.015826992988586426, 0.01585167407989502, 0.0158756955464681, 0.015898993810017904, 0.01592134475708008, 0.015942622820536295, 0.0159627898534139], "lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer+lorahub/flan_t5_large-quail_context_description_question_answer_text": [0.015962713559468586, 0.0159356419245402, 0.015909287134806317, 0.015883682568868, 0.01585887591044108, 0.015834967295328777, 0.01581195036570231, 0.015789788564046225, 0.015768604278564455, 0.015748159090677897, 0.015728432337443032, 0.015710056622823078, 0.01569253921508789, 0.015674610137939454, 0.015656255086263022, 0.01563851038614909, 0.015623048146565755, 0.015609625180562338, 0.015595347086588541, 0.01558108647664388], "lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.01600494384765625, 0.015975879033406575, 0.01594732443491618, 0.015919621785481772, 0.015892863273620605, 0.015866835912068684, 0.01584122021993001, 0.015816370646158855, 0.015792709986368815, 0.015770379702250162, 0.01574838638305664, 0.01572606086730957, 0.015703582763671876, 0.015681347846984862, 0.015660502115885416, 0.015640273094177246, 0.015621356964111328, 0.01560107707977295, 0.01558108647664388], "lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016203004519144693, 0.01615268071492513, 0.01610419750213623, 0.01605817159016927, 0.01601429303487142, 0.015972728729248046, 0.015932936668395997, 0.015895573298136394, 0.015859464009602864, 0.015824464162190754, 0.015790740648905437, 0.015758399963378907, 0.01572754700978597, 0.015698882738749188, 0.015672701199849447, 0.015648028055826824, 0.015624882380167644, 0.015602599779764812, 0.01558108647664388], "lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.01642719586690267, 0.016360805829366047, 0.016296648979187013, 0.0162346092859904, 0.016174848874409994, 0.01612016201019287, 0.016066072781880696, 0.016014987627665202, 0.015966488520304363, 0.015920532544453938, 0.015876601537068685, 0.015833280881245932, 0.01579181671142578, 0.015753129323323567, 0.01571601390838623, 0.015680108070373535, 0.01564656098683675, 0.015613206227620443, 0.01558108647664388], "lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016094061533610027, 0.01605400562286377, 0.0160155455271403, 0.015978644688924154, 0.015943276087443035, 0.0159091583887736, 0.015875906944274903, 0.015844327608744303, 0.015815258026123047, 0.01578775723775228, 0.015760966936747233, 0.015734650293986, 0.015708918571472167, 0.015684022903442382, 0.01566099484761556, 0.01563968022664388, 0.015620312690734862, 0.015600298245747884, 0.01558108647664388], "lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015940791765848797, 0.01591777801513672, 0.01589466412862142, 0.015871782302856446, 0.0158491579691569, 0.01582685629526774, 0.015805193583170573, 0.015783729553222655, 0.015762858390808106, 0.015742863019307454, 0.01572249412536621, 0.01570234457651774, 0.015684617360432942, 0.015666923522949218, 0.015647462209065755, 0.01562888781229655, 0.015613290468851725, 0.015598050753275554, 0.01558108647664388], "lorahub/flan_t5_large-social_i_qa_Generate_the_question_from_the_answer+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015506491661071778, 0.015518891016642252, 0.01553118069966634, 0.015542858441670736, 0.015553247133890788, 0.015563039779663087, 0.015572427113850911, 0.01558164914449056, 0.015589637756347656, 0.015595919291178385, 0.015600543022155761, 0.015604319572448731, 0.01560699462890625, 0.015608121554056803, 0.015606597264607747, 0.015602811177571615, 0.015596879323323569, 0.01558959166208903, 0.01558108647664388], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q": [0.016034536361694336, 0.016015521685282388, 0.015998223622639973, 0.015982629458109538, 0.0159687344233195, 0.01595654805501302, 0.01594605763753255, 0.015937275886535644, 0.01593020439147949, 0.015924833615620932, 0.01592117468516032, 0.0159192164738973, 0.01591894785563151, 0.015920360883076985, 0.01592343012491862, 0.015928128560384114, 0.01593442440032959, 0.01594230651855469, 0.015951733589172363, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.016213445663452147, 0.016174109776814778, 0.016139521598815917, 0.016107948621114095, 0.01607983112335205, 0.016054015159606933, 0.016030672391255697, 0.016010562578837078, 0.015992995897928873, 0.01597848892211914, 0.015966184933980308, 0.015956352551778158, 0.01594900925954183, 0.01594440460205078, 0.015942989985148114, 0.01594406763712565, 0.015947699546813965, 0.015953973134358725, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.016428359349568687, 0.01636594772338867, 0.016308298110961916, 0.016254868507385254, 0.016205379168192546, 0.016160993576049804, 0.01612213929494222, 0.016087652842203776, 0.016057761510213216, 0.016031281153361002, 0.016009133656819663, 0.015990796089172362, 0.01597606341044108, 0.01596489429473877, 0.0159573491414388, 0.015953450202941893, 0.01595309893290202, 0.01595617612202962, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016105527877807616, 0.01607765515645345, 0.0160521666208903, 0.016029078165690103, 0.01600840250651042, 0.015990131696065266, 0.015974257787068683, 0.015960745811462403, 0.015949557622273763, 0.015940653483072918, 0.01593401590983073, 0.015929640134175617, 0.015927522977193197, 0.015927681922912596, 0.01593011538187663, 0.01593482812245687, 0.015941834449768065, 0.015951124827067058, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015948282877604168, 0.015933324495951334, 0.015920246442159017, 0.015908557573954263, 0.015898494720458983, 0.015890588760375978, 0.015886327425638835, 0.015882401466369628, 0.015880317687988282, 0.015880414644877116, 0.015881632169087726, 0.015885098775227865, 0.015890305836995442, 0.015897056261698406, 0.015905625025431316, 0.015916883150736492, 0.015930039087931315, 0.015945288340250652, 0.015962713559468586], "lorahub/flan_t5_large-quail_context_description_question_answer_text+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015514025688171387, 0.015534642537434896, 0.015556842486063639, 0.01557905673980713, 0.015602668126424154, 0.015626673698425294, 0.0156510591506958, 0.015676420529683432, 0.015702713330586753, 0.015729432106018067, 0.015756203333536785, 0.01578266143798828, 0.015808496475219726, 0.01583413283030192, 0.01585990269978841, 0.01588575522104899, 0.01591154416402181, 0.01593719800313314, 0.015962713559468586], "lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q+lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering": [0.01625536918640137, 0.0162171729405721, 0.016181661287943523, 0.01615086237589518, 0.016122760772705077, 0.016098182996114097, 0.016075952847798666, 0.01605616887410482, 0.016039792696634927, 0.016025958061218263, 0.016015125910441082, 0.01600648562113444, 0.016000186602274577, 0.015996996561686197, 0.015997343063354492, 0.016000264485677082, 0.016005287170410155, 0.016012833913167317, 0.016022574106852212, 0.016034536361694336], "lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.01644286632537842, 0.016393489837646484, 0.0163474702835083, 0.01630458196004232, 0.01626437822977702, 0.016226922671000163, 0.01619375546773275, 0.01616431395212809, 0.016138030687967937, 0.016114913622538248, 0.016094795862833657, 0.01607714017232259, 0.01606256326039632, 0.01605098247528076, 0.01604228178660075, 0.01603636900583903, 0.016033150355021158, 0.016032554308573404, 0.016034536361694336], "lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.01610417366027832, 0.016075585683186847, 0.016050012906392415, 0.01602744738260905, 0.01600786844889323, 0.01599125544230143, 0.01597759246826172, 0.015966842969258627, 0.015958987871805826, 0.015953993797302245, 0.015951841672261557, 0.01595249811808268, 0.015955947240193686, 0.015962173144022623, 0.01597115198771159, 0.01598288377126058, 0.015997358957926432, 0.016014575958251953, 0.016034536361694336], "lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015948206583658853, 0.015933597882588704, 0.015921276410420737, 0.01591075579325358, 0.015902287165323895, 0.015896430015563966, 0.01589447021484375, 0.015893489519755045, 0.015894972483317057, 0.01589886665344238, 0.015904404322306314, 0.015912647247314452, 0.01592231273651123, 0.015934332211812337, 0.015949883460998536, 0.01596786657969157, 0.01598785400390625, 0.016010252634684245, 0.016034536361694336], "lorahub/flan_t5_large-adversarial_qa_dbert_answer_the_following_q+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015518474578857421, 0.015544387499491373, 0.015570743878682455, 0.015598079363505046, 0.015625576972961425, 0.015653985341389974, 0.015682915051778157, 0.015712199211120607, 0.01574135144551595, 0.015770249366760254, 0.015799498558044432, 0.015829111735026043, 0.01585868835449219, 0.015888325373331704, 0.015917922655741375, 0.015947357813517252, 0.015976622899373374, 0.016005690892537436, 0.016034536361694336], "lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering+lorahub/flan_t5_large-gem_web_nlg_en": [0.01649563153584798, 0.016452226638793945, 0.01641219139099121, 0.016374842325846354, 0.016341605186462403, 0.016313368479410808, 0.01628735542297363, 0.016265594164530436, 0.016246271133422852, 0.01623152256011963, 0.016220939954121907, 0.016212379137674968, 0.01620697498321533, 0.016204876899719237, 0.016205005645751953, 0.016208284695943195, 0.01621389389038086, 0.016224722862243652, 0.016238625844319662, 0.01625536918640137], "lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.01611573060353597, 0.016098650296529134, 0.01608458360036214, 0.01607298215230306, 0.016063388188680014, 0.016058435440063478, 0.016056811014811198, 0.01605780760447184, 0.01606144428253174, 0.01606733798980713, 0.016076345443725586, 0.016088461875915526, 0.016103715896606446, 0.016121277809143065, 0.0161416228612264, 0.01616434415181478, 0.0161914857228597, 0.0162221097946167, 0.01625536918640137], "lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015962068239847818, 0.0159621795018514, 0.015963330268859863, 0.015966189702351887, 0.015970964431762696, 0.01597759246826172, 0.015985819498697918, 0.015995874404907226, 0.016008113225301105, 0.016022491455078124, 0.01603890101114909, 0.01605743408203125, 0.016078087488810223, 0.0161009422938029, 0.01612616221110026, 0.01615402380625407, 0.016184786160786946, 0.016218570073445637, 0.01625536918640137], "lorahub/flan_t5_large-duorc_ParaphraseRC_question_answering+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015528141657511393, 0.015562068621317546, 0.015597853660583496, 0.01563420295715332, 0.015669965744018556, 0.015706896781921387, 0.015746744473775227, 0.0157862647374471, 0.01582660516103109, 0.015867608388264974, 0.01590835412343343, 0.01595040798187256, 0.015992341041564943, 0.016035048166910808, 0.01607730229695638, 0.016120711962382, 0.01616378943125407, 0.016209446589152018, 0.01625536918640137], "lorahub/flan_t5_large-gem_web_nlg_en+lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer": [0.016135783195495607, 0.016127346356709798, 0.01612177530924479, 0.016119076410929363, 0.016119287808736164, 0.01612242857615153, 0.01612851142883301, 0.01613756815592448, 0.01614969253540039, 0.01616459369659424, 0.016182142893473306, 0.0162029759089152, 0.016226760546366372, 0.0162544584274292, 0.016286460558573405, 0.016321775118509928, 0.016360088984171548, 0.016401729583740234, 0.01644692103068034, 0.01649563153584798], "lorahub/flan_t5_large-gem_web_nlg_en+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.015961386362711587, 0.01596066951751709, 0.015962918599446613, 0.015968179702758788, 0.01597618261973063, 0.015988990465799966, 0.016004605293273924, 0.01602430025736491, 0.016046260197957355, 0.016071815490722657, 0.01610105832417806, 0.016134894688924154, 0.016172974904378256, 0.016216222445170084, 0.016262327829996745, 0.01631454626719157, 0.016371105511983234, 0.016431185404459637, 0.01649563153584798], "lorahub/flan_t5_large-gem_web_nlg_en+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015523916880289713, 0.015557297070821126, 0.015593512852986654, 0.015632540384928385, 0.015674176216125487, 0.01571781317392985, 0.015763697624206544, 0.01581210772196452, 0.015862921078999836, 0.015916053454081217, 0.015971387227376302, 0.016028852462768556, 0.016088476181030275, 0.0161504062016805, 0.01621471087137858, 0.016281344095865884, 0.016350324948628744, 0.016421724955240885, 0.01649563153584798], "lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer+lorahub/flan_t5_large-quoref_Guess_Title_For_Context": [0.015964024861653645, 0.01594903310139974, 0.015935726165771484, 0.015924962361653645, 0.015916884740193683, 0.01591110388437907, 0.01590837001800537, 0.015909053484598795, 0.01591221332550049, 0.015918711026509602, 0.015927851994832355, 0.015938919385274253, 0.015953469276428222, 0.015970207850138345, 0.01598941961924235, 0.016011706988016763, 0.01603912830352783, 0.01606843630472819, 0.016100556055704752, 0.016135783195495607], "lorahub/flan_t5_large-duorc_SelfRC_generate_question_by_answer+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.015526180267333984, 0.015559021631876628, 0.015592188835144042, 0.015625678698221842, 0.015659042994181315, 0.015693100293477376, 0.015727200508117677, 0.015760652224222817, 0.01579468250274658, 0.015829381942749025, 0.015864272117614747, 0.01589862823486328, 0.01593234380086263, 0.01596627394358317, 0.016000369389851887, 0.016034291585286457, 0.01606803258260091, 0.016101841926574708, 0.016135783195495607], "lorahub/flan_t5_large-quoref_Guess_Title_For_Context+lorahub/flan_t5_large-anli_r1": [0.01549333095550537, 0.01551647981007894, 0.015539180437723796, 0.01556246280670166, 0.015585209528605143, 0.015607816378275553, 0.015635584195454914, 0.01566042423248291, 0.01568626403808594, 0.01571343739827474, 0.015740119616190592, 0.015766231218973796, 0.015790950457255044, 0.015816733042399087, 0.015840705235799155, 0.015866333643595378, 0.015891952514648436, 0.01591659228006999, 0.01594107151031494, 0.015964024861653645]}, "seed:5": {"lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-wiki_qa_found_on_google": [0.01600154399871826, 0.01598018010457357, 0.015958744684855142, 0.015937252044677733, 0.015915727615356444, 0.015894155502319336, 0.01587250550587972, 0.01585074742635091, 0.01582884629567464, 0.015806787808736164, 0.015784541765848797, 0.01576210657755534, 0.015739471117655435, 0.015716630617777505, 0.015693586667378745, 0.01567033926645915, 0.01564694881439209, 0.015623429616292317, 0.015599780082702637, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-quarel_logic_test": [0.015526941617329915, 0.015534423192342122, 0.015541359583536784, 0.015547746022542318, 0.015553576151529948, 0.015558835665384928, 0.01556354522705078, 0.015567692120869954, 0.015571292241414387, 0.015574337641398112, 0.015576834678649903, 0.015578784942626954, 0.01558019479115804, 0.015581064224243164, 0.015581398010253907, 0.01558122158050537, 0.015580573081970216, 0.015579477945963541, 0.015577937761942546, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-qasc_qa_with_separated_facts_5": [0.015047216415405273, 0.015089937845865885, 0.015130923589070639, 0.015170186360677084, 0.015207742055257161, 0.015243587493896484, 0.015277744928995769, 0.01531022866566976, 0.01534104824066162, 0.015370235443115235, 0.015397801399230956, 0.015423781077067057, 0.015448179244995117, 0.015471035639444988, 0.015492362976074219, 0.015512173970540364, 0.01553047021230062, 0.015547224680582682, 0.015562405586242676, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-paws_wiki": [0.01640289306640625, 0.01634809176127116, 0.016296696662902833, 0.016245134671529136, 0.016192698478698732, 0.016144901911417642, 0.016089401245117187, 0.016039530436197918, 0.015989414850870767, 0.01593931516011556, 0.01588829199473063, 0.01584450403849284, 0.015801652272542318, 0.015758721033732097, 0.015722273190816243, 0.01568738301595052, 0.01565513769785563, 0.01562553405761719, 0.015599336624145508, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.016037809054056804, 0.01599789301554362, 0.015959852536519367, 0.015923603375752767, 0.01588944911956787, 0.0158566951751709, 0.015825546582539877, 0.01579597473144531, 0.01576793988545736, 0.015741438865661622, 0.015716567039489746, 0.01569351037343343, 0.015672276814778646, 0.015652667681376138, 0.015634530385335285, 0.015617788632710775, 0.015602434476216634, 0.015588486989339193, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-duorc_SelfRC_question_answering": [0.016415851910909017, 0.0163316011428833, 0.016252837181091308, 0.016179097493489582, 0.01611043930053711, 0.01604663530985514, 0.015987475713094074, 0.015932812690734863, 0.015882657368977864, 0.015836884180704752, 0.015795143445332845, 0.015757225354512534, 0.015723042488098145, 0.015692496299743654, 0.015665380160013835, 0.015641496976216633, 0.015620673497517903, 0.015602820714314779, 0.015587906837463378, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.01564392407735189, 0.01563940366109212, 0.015635056495666502, 0.01563084920247396, 0.015626754760742188, 0.01562273661295573, 0.015618764559427897, 0.015614859263102214, 0.015611071586608887, 0.015607476234436035, 0.015604035059611002, 0.015600647926330567, 0.015597257614135742, 0.015593849817911783, 0.015590399106343588, 0.015586883227030435, 0.015583299001057942, 0.015579652786254884, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-squad_v1.1": [0.016428845723470052, 0.016365453402201333, 0.016302488644917807, 0.01624144713083903, 0.016182883580525716, 0.016125807762145995, 0.01607195218404134, 0.016020272572835285, 0.015970077514648438, 0.015922342936197917, 0.0158778174718221, 0.015835962295532226, 0.015796181360880533, 0.015758245786031088, 0.015722235043843586, 0.015688563982645672, 0.01565724531809489, 0.015628064473470052, 0.015600945154825846, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-race_middle_Select_the_best_answer": [0.01618571440378825, 0.016148989995320637, 0.016113684972127278, 0.016079459190368652, 0.016045509974161785, 0.016012253761291503, 0.015979572931925454, 0.01594725767771403, 0.015915346145629884, 0.01588374137878418, 0.015852204958597817, 0.015820690790812175, 0.015789316495259602, 0.015758174260457357, 0.01572727839152018, 0.015696595509847006, 0.015666144688924154, 0.01563591480255127, 0.015605872472127278, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.015578727722167968, 0.015580512682596843, 0.015582000414530436, 0.015583203633626303, 0.015584117571512858, 0.015584751764933269, 0.01558512846628825, 0.015585244496663412, 0.015585139592488606, 0.015584813753763834, 0.0155842924118042, 0.015583596229553222, 0.015582739512125651, 0.015581758817036946, 0.015580671628316244, 0.015579511324564616, 0.015578317642211913, 0.015577123959859213, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.01555095354715983, 0.01555251121520996, 0.015554227828979493, 0.015556092262268067, 0.015558087031046549, 0.015560166041056315, 0.015562270482381185, 0.01556436061859131, 0.015566379229227701, 0.015568297704060872, 0.01557008425394694, 0.015571703910827637, 0.01557313601175944, 0.015574342409769694, 0.0155752960840861, 0.015575950940450032, 0.015576289494832357, 0.015576302210489909, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.016052316029866537, 0.01601770242055257, 0.015984007517496745, 0.01595121224721273, 0.015919278462727865, 0.015888217290242514, 0.015858047803243, 0.015828814506530762, 0.015800538063049315, 0.015773255030314126, 0.01574700673421224, 0.015721821784973146, 0.01569770336151123, 0.015674651463826496, 0.01565267244974772, 0.01563179016113281, 0.015612058639526367, 0.015593469937642416, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015701336860656737, 0.01568960666656494, 0.015678604443868, 0.015668301582336425, 0.01565865675608317, 0.01564963181813558, 0.01564118544260661, 0.015633290608723958, 0.01562591075897217, 0.015619017283121745, 0.015612586339314779, 0.015606597264607747, 0.015601032574971517, 0.015595877965291341, 0.01559111754099528, 0.01558674176534017, 0.015582749048868815, 0.015579152107238769, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.01583151658376058, 0.015818519592285155, 0.015805246035257976, 0.015791713396708172, 0.015777931213378907, 0.015763916969299317, 0.015749704043070474, 0.015735313097635904, 0.015720772743225097, 0.015706117947896323, 0.01569138209025065, 0.015676600138346354, 0.015661816596984863, 0.015647072792053223, 0.015632437070210774, 0.015617966651916504, 0.015603707631429037, 0.015589698155721029, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.01534092903137207, 0.015355968475341797, 0.015370769500732422, 0.015385311444600423, 0.015399580001831054, 0.015413579940795898, 0.015427327156066895, 0.015440835952758789, 0.015454120635986328, 0.015467198689778645, 0.015480058987935384, 0.015492722193400065, 0.01550517717997233, 0.015517427126566568, 0.015529475212097167, 0.015541345278422037, 0.01555306116739909, 0.01556462287902832, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015861175855000815, 0.01584939956665039, 0.015837170282999673, 0.015824440320332846, 0.015811177889506024, 0.015797378222147624, 0.01578308582305908, 0.01576833407084147, 0.01575312614440918, 0.015737449328104655, 0.015721290906270346, 0.015704657236735028, 0.01568756103515625, 0.01566999117533366, 0.015651968320210773, 0.015633554458618165, 0.015614760716756186, 0.01559558391571045, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015872483253479005, 0.01584887186686198, 0.01582596143086751, 0.015803850491841635, 0.01578266461690267, 0.015762488047281902, 0.015743301709493, 0.01572488307952881, 0.01570706526438395, 0.015689940452575685, 0.01567367712656657, 0.01565831979115804, 0.015643863677978515, 0.0156303071975708, 0.015617623329162597, 0.015605823198954264, 0.015594965616861979, 0.015585041046142578, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016214172045389812, 0.01616308371225993, 0.01611079216003418, 0.016058303515116373, 0.0160046911239624, 0.01595176855723063, 0.01590169588724772, 0.01585524559020996, 0.01581168015797933, 0.015771923065185548, 0.01573577880859375, 0.015702912012736003, 0.01567326545715332, 0.015647915204366047, 0.01562627633412679, 0.015608277320861817, 0.015593964258829753, 0.015583225886027018, 0.015575966835021972], "lorahub/flan_t5_large-race_high_Select_the_best_answer+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014992629686991374, 0.014997919400533041, 0.01502165953318278, 0.015058878262837729, 0.015106485684712729, 0.015159576733907065, 0.015215339660644532, 0.015271094640096029, 0.015324654579162598, 0.015374709765116373, 0.01541989008585612, 0.015459467569986979, 0.015492895444234211, 0.01552032470703125, 0.015541906356811524, 0.01555843989054362, 0.015569955507914224, 0.015575744311014812, 0.015575966835021972], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-quarel_logic_test": [0.015526941617329915, 0.015553172429402668, 0.015579107602437338, 0.015604750315348307, 0.015630129178365072, 0.015655277570088704, 0.01568022569020589, 0.015705008506774903, 0.015729656219482423, 0.015754194259643556, 0.01577866236368815, 0.015803081194559733, 0.01582748254140218, 0.015851899782816568, 0.015876364707946778, 0.015900940895080568, 0.015925679206848144, 0.015950660705566406, 0.015975934664408366, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-qasc_qa_with_separated_facts_5": [0.015047216415405273, 0.015119434992472331, 0.01518929640452067, 0.015256737073262533, 0.015321723620096843, 0.015384213129679362, 0.015444192886352539, 0.015501646995544434, 0.01555656909942627, 0.015608970324198406, 0.015658864974975584, 0.015706281661987304, 0.015751256942749023, 0.01579383691151937, 0.015834067662556964, 0.015872006416320802, 0.01590768814086914, 0.015941162109375, 0.015972439448038736, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-paws_wiki": [0.01640289306640625, 0.01637845516204834, 0.016357280413309732, 0.016337757110595704, 0.01631538391113281, 0.016296127637227376, 0.016271821657816567, 0.016249515215555826, 0.01622710069020589, 0.016205426851908365, 0.01618143399556478, 0.016157089869181317, 0.01613498369852702, 0.01611403783162435, 0.01609223524729411, 0.016071942647298176, 0.01605327606201172, 0.016034693717956544, 0.016017603874206542, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.01606538931528727, 0.01605242888132731, 0.0160402250289917, 0.016029545466105143, 0.016019533475240072, 0.016010459264119467, 0.016002314885457357, 0.015995699564615884, 0.015990740458170574, 0.015987075169881185, 0.01598435084025065, 0.01598244031270345, 0.0159816312789917, 0.015981953938802085, 0.015983425776163736, 0.015986092885335288, 0.015990023612976075, 0.015995229085286458, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-duorc_SelfRC_question_answering": [0.016415851910909017, 0.01635681947072347, 0.016303075154622395, 0.016254315376281737, 0.01621027151743571, 0.01617083708445231, 0.016136258443196615, 0.0161056915918986, 0.016079467137654624, 0.016057071685791017, 0.016037742296854656, 0.016021706263224283, 0.016008969942728678, 0.015999396642049152, 0.01599282423655192, 0.015989136695861817, 0.01598823070526123, 0.01599002520243327, 0.015994443893432617, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015665707588195802, 0.015682795842488606, 0.01569989522298177, 0.01571699619293213, 0.01573408762613932, 0.015751193364461263, 0.015768599510192872, 0.015786674817403156, 0.015805201530456545, 0.01582392374674479, 0.015842672983805338, 0.01586143652598063, 0.01588040033976237, 0.015899621645609537, 0.015919130643208823, 0.01593897819519043, 0.01595926602681478, 0.015980156262715657, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-squad_v1.1": [0.016428845723470052, 0.016385838190714517, 0.01634311040242513, 0.016302061080932618, 0.016263742446899414, 0.016227423350016278, 0.016194024085998536, 0.016163371404012045, 0.01613482634226481, 0.016108775138854982, 0.016085338592529298, 0.01606490770975749, 0.01604740301767985, 0.016032632191975912, 0.01602037747701009, 0.01601063887278239, 0.01600371837615967, 0.015999851226806642, 0.015999131202697754, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-race_middle_Select_the_best_answer": [0.01618571440378825, 0.016156239509582518, 0.016130353609720868, 0.016107791264851887, 0.016087889671325684, 0.016070396105448404, 0.016055067380269367, 0.016041688919067383, 0.016030173301696777, 0.016020429929097493, 0.016012226740519206, 0.01600541591644287, 0.016000000635782878, 0.015996022224426268, 0.0159934933980306, 0.015992387135823568, 0.015992674827575683, 0.01599432945251465, 0.01599730650583903, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.015597583452860515, 0.015618457794189453, 0.015639247894287108, 0.015659974416097004, 0.015680648485819498, 0.015701359113057454, 0.01572217305501302, 0.01574317932128906, 0.01576444149017334, 0.015786016782124837, 0.01580795447031657, 0.015830284754435223, 0.01585304578145345, 0.015876264572143556, 0.015899974505106607, 0.015924253463745118, 0.01594921588897705, 0.015974985758463543, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015571347872416179, 0.0155934476852417, 0.015615839958190918, 0.01563854217529297, 0.015661514600118002, 0.01568466822306315, 0.015707934697469075, 0.015731274286905926, 0.01575476010640462, 0.015778435071309407, 0.015802337328592937, 0.015826446215311686, 0.01585076649983724, 0.01587528069814046, 0.015899990399678546, 0.01592490832010905, 0.015950105985005698, 0.01597568194071452, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.016072424252827962, 0.016058046023050943, 0.016044761339823407, 0.016032578150431315, 0.01602150281270345, 0.01601153373718262, 0.01600269794464111, 0.015994998613993328, 0.015988486607869466, 0.015983219146728515, 0.0159792693456014, 0.015976705551147462, 0.015975584983825685, 0.01597596009572347, 0.015977864265441896, 0.015981338818868002, 0.01598642031351725, 0.01599314053853353, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.01572352409362793, 0.015733712514241535, 0.0157443634668986, 0.01575552304585775, 0.01576720396677653, 0.01577941417694092, 0.015792198181152343, 0.01580559730529785, 0.015819648106892903, 0.015834377606709797, 0.01584981123606364, 0.015865964889526366, 0.015882840156555177, 0.015900444984436036, 0.015918822288513185, 0.015938053131103514, 0.015958210627237956, 0.015979371070861816, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015844287872314452, 0.015844923655192057, 0.015846184094746908, 0.015848129590352377, 0.015850809415181476, 0.015854287147521972, 0.0158586057027181, 0.015863839785257974, 0.01587004025777181, 0.01587727705637614, 0.015885616938273114, 0.01589512507120768, 0.015905887285868326, 0.01591797192891439, 0.0159314759572347, 0.01594649314880371, 0.015963147481282552, 0.015981502532958984, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015362938245137533, 0.015400005976359049, 0.015436844825744629, 0.015473448435465494, 0.015509796142578126, 0.015545881589253744, 0.015581701596577962, 0.015617280006408692, 0.015652637481689453, 0.0156878137588501, 0.01572285016377767, 0.015757781664530436, 0.015792630513509116, 0.01582743485768636, 0.015862207412719726, 0.015896976788838703, 0.015931771596272785, 0.015966612497965493, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015875819524129232, 0.015879502296447755, 0.015883509318033853, 0.015887845357259116, 0.01589250405629476, 0.01589748541514079, 0.01590279738108317, 0.015908459027608235, 0.015914491017659505, 0.015920923550923664, 0.015927780469258628, 0.015935093561808267, 0.015942877133687337, 0.01595117410024007, 0.01596001148223877, 0.015969430605570475, 0.015979468027750653, 0.01599016030629476, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015890040397644044, 0.015884482065836588, 0.01588015556335449, 0.015877102216084796, 0.015875380833943686, 0.015875004132588705, 0.01587598164876302, 0.015878327687581382, 0.015882047017415364, 0.015887111028035483, 0.015893527666727702, 0.015901350975036622, 0.015910662015279135, 0.015921552975972492, 0.01593408425649007, 0.015948309898376464, 0.015964261690775552, 0.015981990496317544, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.01625606695810954, 0.01624507427215576, 0.016231056849161783, 0.016215410232543945, 0.016196921666463217, 0.016176681518554687, 0.01615546703338623, 0.0161359437306722, 0.016117111841837565, 0.016099406878153484, 0.01608276685078939, 0.01606768767038981, 0.016053803761800132, 0.016041304270426434, 0.016030379931132, 0.016021016438802084, 0.01601311206817627, 0.01600660800933838, 0.01600154399871826], "lorahub/flan_t5_large-wiki_qa_found_on_google+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.01499610424041748, 0.015011626879374186, 0.015050492286682128, 0.015107054710388184, 0.01517569382985433, 0.0152531099319458, 0.015334733327229818, 0.01541642189025879, 0.015497042338053385, 0.015572849909464519, 0.01564418156941732, 0.015708969434102375, 0.015767701466878257, 0.01582161585489909, 0.0158686097462972, 0.015909446080525715, 0.015944921175638834, 0.015975507100423177, 0.01600154399871826], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-qasc_qa_with_separated_facts_5": [0.015047216415405273, 0.01509811560312907, 0.015146079063415528, 0.015191097259521485, 0.015233149528503418, 0.015272253354390463, 0.015308421452840169, 0.015341682434082031, 0.015372063318888346, 0.015399603843688965, 0.015424338976542155, 0.015446308453877768, 0.015465552012125652, 0.015482110977172852, 0.015496015548706055, 0.015507303873697916, 0.015516009330749512, 0.015522166887919108, 0.015525803565979004, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-paws_wiki": [0.01640289306640625, 0.016344404220581053, 0.016291410128275553, 0.01624015172322591, 0.016188392639160155, 0.016142212549845377, 0.016089851061503093, 0.01604171911875407, 0.015993919372558594, 0.015945382118225097, 0.01589659849802653, 0.015849889119466144, 0.015806066195170086, 0.015761957168579102, 0.015716959635416666, 0.01567651589711507, 0.015636787414550782, 0.015599204699198404, 0.015562465985616048, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.0160387913386027, 0.015999606450398763, 0.015961672465006512, 0.015925656954447427, 0.015890949567159016, 0.015857292811075847, 0.015824681917826336, 0.015793093045552573, 0.015762925148010254, 0.015734424591064455, 0.015707216262817382, 0.015681239763895672, 0.015656323432922364, 0.015632298787434894, 0.015609243710835774, 0.015587220191955567, 0.015566190083821615, 0.015546105702718098, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-duorc_SelfRC_question_answering": [0.016415851910909017, 0.016335601806640624, 0.016259932518005372, 0.01618854363759359, 0.01612144152323405, 0.016058390935262044, 0.015999261538187662, 0.015944236119588215, 0.01589295228322347, 0.01584503173828125, 0.015800623893737792, 0.015759572982788086, 0.015721422831217448, 0.015685936609903972, 0.01565311908721924, 0.015622954368591308, 0.015595348676045735, 0.015570205052693685, 0.015547426541646321, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.01564656734466553, 0.0156441068649292, 0.0156412140528361, 0.01563785394032796, 0.015633955001831054, 0.015629525184631347, 0.015624794960021973, 0.015619932810465495, 0.015614673296610515, 0.01560890515645345, 0.015602598190307617, 0.015595596631368001, 0.01558781623840332, 0.015579299926757812, 0.015570111274719238, 0.015560280481974284, 0.015549810727437337, 0.015538702011108399, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-squad_v1.1": [0.016428845723470052, 0.016355516115824382, 0.016282413800557453, 0.016212606430053712, 0.016144887606302897, 0.016081069310506183, 0.01601957162221273, 0.01596098264058431, 0.015906081199645997, 0.015854652722676596, 0.01580626646677653, 0.01576121966044108, 0.015720149676005046, 0.015682371457417806, 0.015647430419921875, 0.015615960756937664, 0.015588277180989584, 0.015564284324645995, 0.015543848673502603, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-race_middle_Select_the_best_answer": [0.01618571440378825, 0.016135617891947427, 0.016088520685831706, 0.016043833096822103, 0.01600100835164388, 0.015960620244344075, 0.015922129948933918, 0.01588528315226237, 0.01584998607635498, 0.015816059112548828, 0.01578327496846517, 0.015751495361328124, 0.015720656712849935, 0.015690709749857586, 0.015661603609720867, 0.015633290608723958, 0.015605707168579102, 0.015578813552856445, 0.015552566846211752, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.015574905077616373, 0.015573053359985352, 0.015571095148722331, 0.015569032033284505, 0.015566860834757487, 0.015564578374226888, 0.015562195777893067, 0.015559714635213216, 0.015557150840759277, 0.01555448849995931, 0.015551748275756836, 0.015548926989237467, 0.015546018282572429, 0.01554303487141927, 0.015539973576863608, 0.015536829630533855, 0.015533607800801595, 0.015530312856038411, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015553461710611978, 0.015557030042012532, 0.015560224850972493, 0.015563047726949056, 0.015565457344055176, 0.015567340850830079, 0.015568618774414062, 0.01556923230489095, 0.015569138526916503, 0.01556832790374756, 0.015566786130269369, 0.015564514795939127, 0.015561486879984538, 0.015557696024576823, 0.015553123156229655, 0.015547765096028647, 0.015541613896687826, 0.015534671147664388, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.01605788548787435, 0.016028043429056803, 0.01599830945332845, 0.015968647003173828, 0.015939030647277832, 0.01590944449106852, 0.015879886945088705, 0.015850361188252768, 0.015820865631103517, 0.015791405042012534, 0.01576197942097982, 0.015732571283976236, 0.015703182220458984, 0.015673793156941732, 0.01564440409342448, 0.01561500867207845, 0.015585625966389974, 0.015556265513102213, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.01570272127787272, 0.015691943168640136, 0.01568143367767334, 0.01567117691040039, 0.015661142667134604, 0.01565131187438965, 0.015641647974650064, 0.015632112820943195, 0.015622649192810058, 0.015613230069478352, 0.015603830019632975, 0.015594420433044433, 0.015584975878397623, 0.015575488408406576, 0.01556593418121338, 0.015556305249532065, 0.015546604792277019, 0.01553681214650472, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015834361712137857, 0.01582380771636963, 0.015812546412150064, 0.015800549189249675, 0.01578778584798177, 0.015774234135945638, 0.015759874979654948, 0.01574470043182373, 0.015728688240051268, 0.015711849530537923, 0.01569418430328369, 0.01567570686340332, 0.0156564458211263, 0.015636439323425292, 0.015615722338358562, 0.015594356854756674, 0.015572392145792643, 0.015549896558125813, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.01534576416015625, 0.015364853541056316, 0.015382927258809407, 0.015399975776672363, 0.015415970484415691, 0.015430905024210613, 0.0154447603225708, 0.015457541147867838, 0.015469236373901367, 0.015479842821756998, 0.01548937161763509, 0.015497817993164062, 0.0155051851272583, 0.015511476198832194, 0.015516699155171712, 0.015520852406819661, 0.015523940722147623, 0.015525967280069986, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.01585306485493978, 0.015833827654520672, 0.015814765294392904, 0.01579588572184245, 0.0157771635055542, 0.01575859546661377, 0.015740149815877277, 0.01572182019551595, 0.01570360024770101, 0.015685482025146483, 0.01566746711730957, 0.015649545987447104, 0.015631726582845052, 0.01561400572458903, 0.015596383412679037, 0.015578869183858236, 0.01556145191192627, 0.015544137954711913, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015871702829996746, 0.015847125053405763, 0.015823084513346353, 0.01579967180887858, 0.015776972770690918, 0.015754995346069337, 0.015733734766642252, 0.015713170369466147, 0.015693283081054686, 0.015674034754435223, 0.015655396779378255, 0.01563734531402588, 0.015619856516520182, 0.015602928797403971, 0.015586562156677246, 0.015570772488911947, 0.015555559794108073, 0.015540947914123535, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016228154500325522, 0.016188615163167316, 0.016146217981974284, 0.016101592381795246, 0.016054051717122396, 0.01600563685099284, 0.015957845052083332, 0.015910833676656088, 0.015865305264790852, 0.015821024576822915, 0.015779857635498048, 0.015740691820780438, 0.015703256924947104, 0.01566810448964437, 0.01563537915547689, 0.015604801177978515, 0.01557650089263916, 0.015550540288289389, 0.015526941617329915], "lorahub/flan_t5_large-quarel_logic_test+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014990188280741374, 0.014994575182596842, 0.015018307367960611, 0.015057136217753092, 0.015105147361755372, 0.015159107844034831, 0.01521485964457194, 0.01526948610941569, 0.015321332613627116, 0.01536839485168457, 0.015410270690917969, 0.01544568379720052, 0.015474645296732585, 0.015497965812683106, 0.015515748659769695, 0.015526989301045735, 0.01553227424621582, 0.015532174110412598, 0.015526941617329915], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-paws_wiki": [0.01640289306640625, 0.01633301575978597, 0.016265618006388347, 0.016200122833251954, 0.016132532755533856, 0.016065624554951984, 0.0159969695409139, 0.015927225748697916, 0.015858777364095054, 0.01578807195027669, 0.015716094970703125, 0.01564250946044922, 0.015569405555725098, 0.015497570037841796, 0.015424118041992188, 0.015347716013590494, 0.015272016525268555, 0.015197286605834961, 0.015122785568237304, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.01602657953898112, 0.015973711013793947, 0.0159207550684611, 0.01586784521738688, 0.015815067291259765, 0.015761914253234862, 0.01570857365926107, 0.015654961268107098, 0.015600996017456055, 0.01554688294728597, 0.01549303690592448, 0.015439222653706869, 0.01538482666015625, 0.015329624811808268, 0.015273903210957845, 0.015217798550923665, 0.015161317189534505, 0.015104454358418782, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-duorc_SelfRC_question_answering": [0.016415851910909017, 0.016307600339253745, 0.016204382578531903, 0.016105910936991374, 0.016012097994486493, 0.015922646522521972, 0.015837701161702473, 0.01575724919637044, 0.015680812199910483, 0.015608437856038411, 0.015539611180623372, 0.015473767916361491, 0.015410963694254558, 0.015351182619730631, 0.015294257799784343, 0.01524001916249593, 0.015188322067260743, 0.015139034589131673, 0.01509203592936198, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015629852612813314, 0.015609777768452963, 0.015588353474934896, 0.01556553840637207, 0.015541262626647949, 0.015515476862589517, 0.015488290786743164, 0.015459980964660645, 0.015430553754170736, 0.015399767557779947, 0.015367355346679688, 0.015333158175150553, 0.01529719352722168, 0.015259579022725423, 0.015220333735148112, 0.015179454485575358, 0.015136965115865071, 0.015092884699503581, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-squad_v1.1": [0.016428845723470052, 0.01632438023885091, 0.016222561200459798, 0.016124990781148273, 0.01603232542673747, 0.015943133036295572, 0.015858232180277508, 0.015777293841044107, 0.01569988250732422, 0.015626239776611327, 0.015555982589721679, 0.015488791465759277, 0.015424604415893555, 0.015363396008809408, 0.015305035909016928, 0.015249334971110026, 0.0151957639058431, 0.01514411449432373, 0.015094582239786785, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-race_middle_Select_the_best_answer": [0.01618571440378825, 0.01612959861755371, 0.016073708534240724, 0.016018182436625162, 0.01596247355143229, 0.01590637524922689, 0.015850089391072592, 0.015793571472167967, 0.015736613273620605, 0.01567906379699707, 0.015620740254720052, 0.01556151549021403, 0.015501286188761393, 0.015439963340759278, 0.01537749449412028, 0.015313852628072102, 0.015249010721842447, 0.015182960828145345, 0.015115694999694824, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.015571961402893067, 0.01556486447652181, 0.015555319786071777, 0.015543290774027507, 0.015528755187988281, 0.015511682828267415, 0.01549205462137858, 0.015469848314921061, 0.01544503370920817, 0.015417577425638835, 0.015387442906697591, 0.01535459836324056, 0.015319013595581054, 0.015280664761861166, 0.015239542325337727, 0.015195622444152831, 0.01514891783396403, 0.01509943962097168, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015530695915222168, 0.015511275927225749, 0.015491271018981933, 0.015470647811889648, 0.015449382464090984, 0.015427422523498536, 0.015404690106709798, 0.015381080309549967, 0.015356492996215821, 0.015330859820048014, 0.01530415693918864, 0.015276366869608562, 0.01524743398030599, 0.015217316945393881, 0.015185952186584473, 0.015153296788533529, 0.01511930783589681, 0.015083953539530437, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.016050643920898437, 0.016011465390523276, 0.015970354080200196, 0.01592730522155762, 0.01588231563568115, 0.015835380554199217, 0.015786485671997072, 0.015735623041788736, 0.015682773590087892, 0.01562793572743734, 0.015571099917093913, 0.0155122709274292, 0.015451466242472331, 0.015388712882995606, 0.015324047406514486, 0.01525750478108724, 0.015189146995544434, 0.01511902650197347, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015686432520548504, 0.015658493041992187, 0.015629865328470865, 0.015600533485412597, 0.015570462544759115, 0.015539620717366536, 0.015507963498433431, 0.015475441614786783, 0.015441991488138835, 0.015407543182373046, 0.015372052192687988, 0.015335472424825032, 0.0152977720896403, 0.01525891621907552, 0.015218895276387532, 0.015177702903747559, 0.015135345458984375, 0.015091838836669922, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.01582429091135661, 0.015801897048950197, 0.01577704429626465, 0.015749739011128742, 0.015719966888427736, 0.015687743822733562, 0.015653050740559896, 0.015615892410278321, 0.015576268831888835, 0.015534186363220214, 0.01548962910970052, 0.01544263203938802, 0.015393187204996744, 0.015341327985127768, 0.015287079811096192, 0.015230480829874675, 0.015171593030293782, 0.015110475222269694, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015330325762430827, 0.01533297061920166, 0.015333582560221354, 0.015332131385803223, 0.015328601201375325, 0.015322966575622559, 0.015315203666687012, 0.015305282274881999, 0.015293180147806803, 0.015278870264689128, 0.01526232878367106, 0.015243533452351889, 0.01522245724995931, 0.015199076334635417, 0.015173382759094238, 0.01514535109202067, 0.015114981333414714, 0.015082265535990397, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.0158511749903361, 0.01582746664683024, 0.01580134391784668, 0.015772795677185057, 0.015741817156473794, 0.015708406766255695, 0.015672532717386882, 0.015634193420410156, 0.015593369801839193, 0.015550042788187663, 0.015504202842712402, 0.015455834070841471, 0.015404938062032063, 0.015351510047912598, 0.015295565923055013, 0.015237123171488443, 0.015176218350728353, 0.015112897555033367, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015868570009867352, 0.01583857536315918, 0.01580681324005127, 0.01577326774597168, 0.015737929344177247, 0.015700790087382, 0.01566184679667155, 0.01562108834584554, 0.015578505198160807, 0.015534071922302247, 0.015487774213155111, 0.015439597765604655, 0.015389520327250163, 0.015337513287862143, 0.015283538500467935, 0.01522753397623698, 0.015169477462768555, 0.015109364191691082, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016204627354939778, 0.0161419153213501, 0.016077144940694173, 0.0160107421875, 0.015941904385884602, 0.015872031847635904, 0.015801275571187337, 0.015731377601623533, 0.015662274360656737, 0.015594140688578288, 0.015527213414510091, 0.015461880366007487, 0.015398406982421875, 0.015336589813232422, 0.015276106198628743, 0.015216751098632813, 0.01515891393025716, 0.015102426211039225, 0.015047216415405273], "lorahub/flan_t5_large-qasc_qa_with_separated_facts_5+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014972240130106607, 0.014953700701395671, 0.01495125929514567, 0.014961320559183757, 0.014979310035705566, 0.015003061294555664, 0.015029120445251464, 0.015054880777994792, 0.015079824129740398, 0.015101388295491536, 0.015117979049682618, 0.015129036903381347, 0.01513446013132731, 0.01513493537902832, 0.015129714012145997, 0.015117681821187338, 0.01509980042775472, 0.01507626215616862, 0.015047216415405273], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step": [0.01607987880706787, 0.016072392463684082, 0.01606770356496175, 0.016064709027608235, 0.016067887941996258, 0.016072314580281577, 0.01607758045196533, 0.01609013557434082, 0.01610459009806315, 0.016117645899454754, 0.01613923708597819, 0.0161602783203125, 0.01618244171142578, 0.016205933888753254, 0.01623469352722168, 0.016258672078450522, 0.016289798418680827, 0.01632298469543457, 0.016359270413716633, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-duorc_SelfRC_question_answering": [0.016415851910909017, 0.01637622038523356, 0.016340258916219076, 0.0163097620010376, 0.016285614967346193, 0.016266160011291504, 0.016250621477762857, 0.016242833137512208, 0.016235539118448893, 0.016232012112935384, 0.01623730182647705, 0.016244541803995767, 0.01625275135040283, 0.01626384417215983, 0.016282116572062175, 0.01629477659861247, 0.016316138903299967, 0.016339672406514485, 0.016367422739664714, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015662894248962403, 0.015679089228312175, 0.015698304176330568, 0.015721243222554526, 0.015745971997578937, 0.015773568153381348, 0.015805131594340008, 0.015840991338094076, 0.015879295667012534, 0.015919121106465657, 0.015965415636698406, 0.016012690862019858, 0.016060417493184407, 0.016112608909606932, 0.01616557439168294, 0.016218663851420085, 0.016276575724283853, 0.01633626619974772, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-squad_v1.1": [0.016428845723470052, 0.016399129231770834, 0.016369603474934897, 0.016346675554911295, 0.01632878303527832, 0.016312669118245443, 0.016300471623738606, 0.01628870646158854, 0.016283135414123535, 0.016282836596171062, 0.016283791859944663, 0.01628550370534261, 0.016288870175679523, 0.016298125584920248, 0.01630751450856527, 0.01632088502248128, 0.01633614699045817, 0.016354341506958008, 0.016378037134806313, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-race_middle_Select_the_best_answer": [0.01618571440378825, 0.016184444427490233, 0.016185995737711588, 0.016191237767537434, 0.01619815985361735, 0.016206560134887697, 0.016216309865315755, 0.01622705618540446, 0.01623902638753255, 0.016252031326293947, 0.016265811920166014, 0.016280473073323566, 0.016294018427530924, 0.016308356920878092, 0.016324677467346192, 0.01633773962656657, 0.016353710492451986, 0.016367581685384113, 0.016383728981018066, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.015606155395507812, 0.01563729763031006, 0.0156697416305542, 0.01570390542348226, 0.01574012597401937, 0.01577798843383789, 0.015820256868998208, 0.01586037000020345, 0.015902309417724608, 0.015948432286580404, 0.015995450019836426, 0.01604171593983968, 0.01608800729115804, 0.016138620376586914, 0.016185728708902995, 0.016236597696940105, 0.016288978258768717, 0.01634282112121582, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015569491386413574, 0.015593129793802897, 0.015618319511413575, 0.0156462828318278, 0.015677134195963543, 0.01571105162302653, 0.015751245816548666, 0.015790046056111652, 0.015832902590433757, 0.015880850156148273, 0.01593042055765788, 0.01598103205362956, 0.016033480962117513, 0.016091604232788086, 0.016145302454630535, 0.016205538113911948, 0.016267210642496744, 0.016331666310628254, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.01608046849568685, 0.016075747807820638, 0.016072678565979003, 0.016073409716288248, 0.016078945795694986, 0.016084918975830077, 0.016092413266499836, 0.0161020294825236, 0.01611596902211507, 0.016132041613260904, 0.016149903933207196, 0.016171460151672364, 0.016194524765014647, 0.01622300624847412, 0.016249125798543294, 0.016282548904418947, 0.01631661574045817, 0.01635636329650879, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015725026130676268, 0.015739703178405763, 0.015757503509521483, 0.015777376492818195, 0.015801037152608235, 0.015828054745992026, 0.01585819721221924, 0.01588838259379069, 0.015924126307169596, 0.015963088671366372, 0.016003909111022948, 0.016045390764872235, 0.01608964761098226, 0.01613878885904948, 0.016182513236999513, 0.01623328685760498, 0.016285889943440754, 0.0163412078221639, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015854756037394207, 0.015866228739420573, 0.0158800999323527, 0.015894877115885418, 0.015910959243774413, 0.015932572682698567, 0.01595495065053304, 0.015976673762003582, 0.016001489957173664, 0.01603142579396566, 0.016062256495157877, 0.016094024976094565, 0.016128164927164713, 0.016167996724446614, 0.016204829216003417, 0.016248841285705567, 0.016294886271158854, 0.016344908078511557, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015371009508768718, 0.015418200492858887, 0.015466599464416505, 0.015517285664876302, 0.015571858088175456, 0.01562548319498698, 0.01567967891693115, 0.015735341707865398, 0.015794623692830405, 0.015853091875712075, 0.015912009874979656, 0.015970377922058104, 0.01603028615315755, 0.016092201868693035, 0.016150530179341635, 0.016212499936421713, 0.01627297560373942, 0.016335983276367188, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015887641906738283, 0.01590401808420817, 0.01592231273651123, 0.015942083994547527, 0.01596643288930257, 0.015990463892618816, 0.016013739903767903, 0.016039320627848307, 0.01606849511464437, 0.01609790325164795, 0.016126909255981446, 0.016157485644022623, 0.016188685099283853, 0.016223491032918293, 0.016253326733907062, 0.016288922627766926, 0.016323251724243162, 0.0163605801264445, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015899984041849773, 0.015906713803609213, 0.015917628606160483, 0.015931881268819174, 0.015947790145874025, 0.015964991251627605, 0.01598495165506999, 0.01600716749827067, 0.016034820874532063, 0.016062803268432617, 0.016091705958048503, 0.016122299830118814, 0.016155722935994467, 0.016192418734232585, 0.016227347056070963, 0.01626769224802653, 0.016308229764302573, 0.01635266621907552, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016262259483337402, 0.01625849723815918, 0.016254029273986816, 0.016249690055847168, 0.016245252291361492, 0.016240981419881183, 0.016238234837849936, 0.01623809814453125, 0.016240549087524415, 0.016243168512980143, 0.01625004450480143, 0.01625887711842855, 0.016270241737365722, 0.01628313700358073, 0.01630138874053955, 0.016320972442626952, 0.01634427547454834, 0.016371410687764487, 0.01640289306640625], "lorahub/flan_t5_large-paws_wiki+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015018820762634277, 0.015053378740946451, 0.01510947068532308, 0.015183335940043131, 0.015269144376118978, 0.015362884203592936, 0.015461934407552084, 0.015564681688944499, 0.01566421667734782, 0.015762033462524413, 0.015859409968058267, 0.015948092142740886, 0.016030346552530925, 0.016109070777893066, 0.016177109082539876, 0.01624191125233968, 0.016299837430318195, 0.016351761817932128, 0.01640289306640625], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-duorc_SelfRC_question_answering": [0.016415851910909017, 0.016361865997314453, 0.016312615076700846, 0.016267701784769693, 0.016227006912231445, 0.016190495491027832, 0.016158105532328288, 0.016129757563273114, 0.01610539436340332, 0.016084973017374674, 0.016068429946899415, 0.016055696805318195, 0.01604663530985514, 0.016040980021158856, 0.0160386323928833, 0.01603978474934896, 0.016044410069783528, 0.0160525639851888, 0.016064440409342448, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.015662668546040853, 0.01567760149637858, 0.015693421363830565, 0.01571015516916911, 0.015727810859680176, 0.015746407508850098, 0.015765961011250815, 0.015786492029825846, 0.01580801486968994, 0.015830551783243815, 0.015854088465372722, 0.01587860584259033, 0.015904043515523273, 0.01593022664388021, 0.015957504908243814, 0.015986081759134928, 0.01601588249206543, 0.016047164599100747, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-squad_v1.1": [0.016428845723470052, 0.0163885768254598, 0.016348703702290853, 0.01631093184153239, 0.016276288032531738, 0.016243828137715657, 0.01621355374654134, 0.01618688424428304, 0.01616331418355306, 0.01614228089650472, 0.016123706499735515, 0.016107548077901206, 0.016094199816385903, 0.016083884239196777, 0.016076525052388508, 0.01607170581817627, 0.016069769859313965, 0.016070404052734376, 0.016073654492696127, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-race_middle_Select_the_best_answer": [0.01618571440378825, 0.01615957578023275, 0.016136824289957684, 0.01611646016438802, 0.016099289258321128, 0.01608505884806315, 0.01607306957244873, 0.016063048044840496, 0.016054519017537437, 0.016047884623209635, 0.016043256123860677, 0.016040921211242676, 0.016040862401326496, 0.01604236920674642, 0.016045262018839518, 0.01604945182800293, 0.01605475902557373, 0.016061851183573405, 0.01606998284657796, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.015593770345052084, 0.01561172326405843, 0.01563053290049235, 0.015650251706441243, 0.015670924186706542, 0.015692553520202636, 0.015715160369873048, 0.015738889376322427, 0.01576400438944499, 0.015790451367696128, 0.015818018913269043, 0.015846606890360514, 0.015876185099283853, 0.015906750361124676, 0.01593818187713623, 0.015971325238545737, 0.016005999247233074, 0.016042040189107258, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015564993222554524, 0.015581803321838379, 0.01559998353322347, 0.015619549751281738, 0.015640540122985838, 0.015663003921508788, 0.015686925252278647, 0.015712265968322755, 0.01573898792266846, 0.015767051378885906, 0.015796432495117186, 0.015827091534932454, 0.015858918825785318, 0.015891828536987306, 0.015926329294840495, 0.015962454477945965, 0.015999941825866698, 0.016039047241210937, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.01607564926147461, 0.01606470266977946, 0.01605497678120931, 0.016046387354532878, 0.016038872400919595, 0.016032484372456867, 0.016027345657348632, 0.01602338949839274, 0.016020593643188478, 0.016019439697265624, 0.016019878387451173, 0.01602231502532959, 0.016026514371236165, 0.016032026608784992, 0.016038835843404133, 0.016046655972798664, 0.01605633576711019, 0.016067145665486653, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.01572409470876058, 0.01573574701944987, 0.015748605728149415, 0.015762518246968588, 0.01577749729156494, 0.015793350537618, 0.015809739430745443, 0.015827232996622722, 0.015846061706542968, 0.015865495999654134, 0.015885847409566244, 0.015907402038574218, 0.015929532051086426, 0.015952324867248534, 0.015975637435913084, 0.016000229517618814, 0.01602575143178304, 0.01605226993560791, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015842733383178712, 0.015842444101969402, 0.015843404134114582, 0.015845662752787273, 0.015849194526672362, 0.015853950182596842, 0.015860047340393067, 0.015867703755696613, 0.015877060890197754, 0.015888442993164064, 0.015901959737141928, 0.01591722329457601, 0.01593418757120768, 0.01595300833384196, 0.015973642667134604, 0.015996565818786623, 0.016022011439005533, 0.01604955832163493, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015357500712076822, 0.015390140215555827, 0.015423595110575358, 0.01545777956644694, 0.015492663383483887, 0.015528281529744467, 0.015564708709716797, 0.015601991017659505, 0.015639780362447103, 0.015678375562032065, 0.015718216896057128, 0.015759784380594888, 0.01580261707305908, 0.015846293767293296, 0.01589088757832845, 0.01593619664510091, 0.015983099937438964, 0.01603072802225749, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015872732798258463, 0.015874088605244953, 0.015876665115356445, 0.015880401929219565, 0.015885205268859864, 0.015891056060791015, 0.01589804172515869, 0.01590624491373698, 0.015915679931640624, 0.015925965309143066, 0.015937132835388182, 0.015949894587198893, 0.015964813232421875, 0.01598100026448568, 0.015998298327128093, 0.01601651668548584, 0.016036340395609538, 0.016057270367940267, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.01589308738708496, 0.015890560150146484, 0.015889221827189128, 0.01588955243428548, 0.01589170773824056, 0.015895579655965168, 0.015900926589965822, 0.015907424290974935, 0.015915048917134602, 0.015923871994018554, 0.01593362808227539, 0.015945661862691245, 0.015960289637247722, 0.015976497332255046, 0.015994135538736978, 0.016012948354085288, 0.016033740043640138, 0.016055841445922852, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.01624619166056315, 0.0162266747156779, 0.016205948193868003, 0.016182462374369305, 0.016158593495686848, 0.016136422157287597, 0.016114947001139322, 0.016097195943196616, 0.016082393328348796, 0.0160689640045166, 0.01605741500854492, 0.016049672762552897, 0.01604625701904297, 0.016045236587524415, 0.01604678471883138, 0.01605065186818441, 0.016057602564493813, 0.016067261695861815, 0.01607987880706787], "lorahub/flan_t5_large-wiqa_what_is_the_missing_first_step+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014984946250915527, 0.014988360404968261, 0.015015681584676107, 0.01506101131439209, 0.015120131174723307, 0.015189746220906575, 0.015265355110168457, 0.015344521204630535, 0.015425469080607096, 0.015505229632059733, 0.015583513577779134, 0.015658523241678875, 0.01572989781697591, 0.015797367095947267, 0.015860912005106607, 0.0159207550684611, 0.015977115631103517, 0.01603014310201009, 0.01607987880706787], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-duorc_SelfRC_title_generation": [0.015648625691731772, 0.01565950075785319, 0.01567307154337565, 0.015689396858215333, 0.015708568890889486, 0.015730678240458172, 0.01575582186381022, 0.01578410466512044, 0.01581564426422119, 0.015850547154744467, 0.015888959566752115, 0.015931002298990884, 0.01597683270772298, 0.01602657636006673, 0.016080398559570313, 0.01613845984141032, 0.016200892130533853, 0.016267773310343424, 0.016339310010274253, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-squad_v1.1": [0.016428845723470052, 0.01640824317932129, 0.016387351353963218, 0.016369651158650717, 0.016354015668233236, 0.016341233253479005, 0.01633005936940511, 0.016321350733439127, 0.016315881411234537, 0.016312804222106934, 0.01631213665008545, 0.0163142728805542, 0.016318491299947103, 0.016324661572774252, 0.016333359082539876, 0.016345103581746418, 0.0163594388961792, 0.016375912030537922, 0.016394535700480144, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-race_middle_Select_the_best_answer": [0.01618571440378825, 0.016168649991353354, 0.016155513127644856, 0.016145081520080568, 0.01613862673441569, 0.016135457356770834, 0.016135082244873047, 0.01613782564798991, 0.016142908732096353, 0.016150752703348797, 0.016162161827087403, 0.016176953315734863, 0.01619489669799805, 0.016216408411661783, 0.016241307258605956, 0.01626940886179606, 0.01630084991455078, 0.016335755983988443, 0.016374011039733887, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.01559335708618164, 0.015612411499023437, 0.0156338898340861, 0.015657882690429687, 0.01568449815114339, 0.01571387767791748, 0.015746172269185385, 0.015781497955322264, 0.015819938977559407, 0.015861581166585287, 0.015906702677408853, 0.015955656369527182, 0.01600852648417155, 0.016065359115600586, 0.016126335461934406, 0.016191697120666503, 0.01626166343688965, 0.01633622169494629, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015568663279215494, 0.015589934984842936, 0.015613463719685873, 0.01563935915629069, 0.015667761166890462, 0.015698809623718262, 0.01573267618815104, 0.015769524574279783, 0.015809518496195475, 0.01585278511047363, 0.015899453163146973, 0.015949681599934897, 0.016003654797871907, 0.016061552365620933, 0.0161235507329305, 0.01618984540303548, 0.016260560353597006, 0.01633571942647298, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.016092939376831053, 0.016098845799764, 0.01610560735066732, 0.01611323038736979, 0.016121729214986166, 0.01613115151723226, 0.016141665776570637, 0.016153523127237956, 0.016166771252950032, 0.016181483268737792, 0.016198256810506184, 0.01621738910675049, 0.016238430341084797, 0.01626181125640869, 0.016287740071614584, 0.01631591002146403, 0.016346599260965985, 0.0163798729578654, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015726269086201984, 0.015741020838419596, 0.015758145650227866, 0.015777664184570314, 0.01579956849416097, 0.015823917388916017, 0.01585081100463867, 0.01588029702504476, 0.015912173589070638, 0.015946788787841795, 0.01598483403523763, 0.016026352246602375, 0.01607096036275228, 0.01611881415049235, 0.016170756022135416, 0.016226248741149904, 0.016285510063171388, 0.016348582903544108, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015845327377319335, 0.01584869384765625, 0.015854433377583823, 0.015862658818562827, 0.015873498916625976, 0.01588702360788981, 0.01590331713358561, 0.015922611554463704, 0.01594532330830892, 0.015971781412760417, 0.016002036730448404, 0.01603633721669515, 0.016075270970662435, 0.016118928591410318, 0.01616737683614095, 0.01622096061706543, 0.01628005345662435, 0.01634483496348063, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015344131787618, 0.015366242726643881, 0.015392058690388998, 0.015421597162882487, 0.01545491377512614, 0.015492149988810221, 0.015533515612284342, 0.015579204559326171, 0.015629235903422037, 0.015683452288309734, 0.015742562611897788, 0.01580707550048828, 0.015876660346984862, 0.015951965649922687, 0.01603307088216146, 0.016119802792867025, 0.0162124236424764, 0.016311039924621584, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015879998207092284, 0.015889253616333008, 0.01590038458506266, 0.015913437207539877, 0.01592845916748047, 0.015945526758829754, 0.015964775085449218, 0.015986350377400715, 0.016010368665059407, 0.016036704381306967, 0.016065243085225424, 0.016096998850504557, 0.01613192876180013, 0.016170188585917154, 0.016212201118469237, 0.016257592837015788, 0.016306591033935548, 0.016359281539916993, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015904404322306314, 0.015913461049397785, 0.01592408021291097, 0.015936659177144367, 0.015951333045959474, 0.015968201955159505, 0.015987132390340168, 0.016007951100667318, 0.016030901273091633, 0.016056199073791504, 0.016083617210388184, 0.016113944053649902, 0.01614720662434896, 0.016183727582295734, 0.016223630905151366, 0.016266616185506184, 0.01631293455759684, 0.016362643241882323, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016262812614440916, 0.016259743372599285, 0.01625534693400065, 0.016249794960021973, 0.016242891947428385, 0.016236437161763508, 0.016233011881510415, 0.01623046080271403, 0.01623051643371582, 0.016233485539754233, 0.016239689191182453, 0.01624884605407715, 0.01626062870025635, 0.0162766695022583, 0.016297041575113934, 0.016320967674255372, 0.016348692576090496, 0.016380163828531902, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_question_answering+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015031270980834961, 0.015069220860799154, 0.01512192408243815, 0.015186389287312826, 0.015260583559672037, 0.015341607729593913, 0.015427484512329101, 0.015516481399536132, 0.01560620148976644, 0.015696086883544923, 0.015784385999043783, 0.01587078094482422, 0.015954971313476562, 0.016036887168884278, 0.01611646016438802, 0.016193695068359375, 0.016268978118896483, 0.016342849731445314, 0.016415851910909017], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-squad_v1.1": [0.016428845723470052, 0.016361406644185384, 0.01629476229349772, 0.016232322057088217, 0.01617218017578125, 0.016116271018981932, 0.016063361167907714, 0.016013245582580566, 0.015966596603393553, 0.015923377672831217, 0.015882534980773924, 0.015844070116678873, 0.015809030532836915, 0.015776882171630858, 0.01574755350748698, 0.015721378326416017, 0.015698498090108235, 0.015678807894388833, 0.015662194887797038, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-race_middle_Select_the_best_answer": [0.01618571440378825, 0.016145555178324382, 0.016108210881551108, 0.016072284380594888, 0.016038381258646647, 0.0160059388478597, 0.015975019137064617, 0.01594520092010498, 0.015916028022766114, 0.015887870788574218, 0.015860792795817057, 0.015834554036458334, 0.015809329350789388, 0.015785163243611653, 0.015761569341023764, 0.01573833465576172, 0.015715432167053223, 0.01569286346435547, 0.015670599937438964, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.0155856720606486, 0.015593999226888021, 0.015601639747619628, 0.01560858726501465, 0.015614859263102214, 0.015620471636454265, 0.015625445048014323, 0.015629793802897137, 0.015633544921875, 0.015636792182922365, 0.01563968022664388, 0.015642261505126952, 0.015644434293111166, 0.015646125475565594, 0.01564736525217692, 0.015648198127746583, 0.01564866065979004, 0.01564879576365153, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015555710792541503, 0.015561823844909667, 0.015567859013875326, 0.015573801994323731, 0.01557965119679769, 0.015585393905639648, 0.015591052373250326, 0.015596648852030437, 0.015602197647094727, 0.015607686042785644, 0.015613058408101399, 0.015618268648783367, 0.015623278617858886, 0.015628078778584797, 0.015632651646931967, 0.015637006759643555, 0.01564112663269043, 0.01564500649770101, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.01606629212697347, 0.016044535636901856, 0.016022359530131022, 0.01599973678588867, 0.015976877212524415, 0.01595396041870117, 0.015930962562561036, 0.015907721519470217, 0.015884222984313964, 0.01586066246032715, 0.015837079683939617, 0.01581355094909668, 0.01579035758972168, 0.015767272313435873, 0.01574395179748535, 0.015720376968383788, 0.01569660981496175, 0.015672685305277507, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015702428817749022, 0.015692261060078937, 0.015683223406473795, 0.015675160090128582, 0.015667961438496907, 0.015661603609720867, 0.01565604050954183, 0.01565103848775228, 0.01564661184946696, 0.01564311345418294, 0.0156406831741333, 0.015638945897420247, 0.01563771883646647, 0.015637729962666828, 0.01563853899637858, 0.01563995679219564, 0.01564207871754964, 0.015644961992899577, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015834026336669922, 0.01582369804382324, 0.0158132537206014, 0.015802709261576335, 0.015792059898376464, 0.01578125, 0.015770265261332194, 0.015759135882059735, 0.01574799378712972, 0.01573694864908854, 0.015726057688395183, 0.01571552276611328, 0.015705453554789226, 0.01569559415181478, 0.015685823758443195, 0.01567618211110433, 0.01566673437754313, 0.015657531420389812, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015347498257954915, 0.015368819236755371, 0.015389560063680013, 0.01540966510772705, 0.015429174105326335, 0.015448169708251953, 0.015466707547505697, 0.015484763781229654, 0.015502293904622396, 0.015519097646077474, 0.015535122553507487, 0.015550638834635417, 0.015565759340922037, 0.01558090368906657, 0.015595787366231283, 0.015609971682230632, 0.015623472531636555, 0.01563635190327962, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015861660639444986, 0.01585078557332357, 0.015839821497599285, 0.015828696886698405, 0.01581746737162272, 0.015806183815002442, 0.015794814427693683, 0.015783300399780275, 0.01577163378397624, 0.01575966676076253, 0.015747267405192056, 0.015734667778015136, 0.015722147623697915, 0.015710153579711915, 0.01569828987121582, 0.01568615754445394, 0.01567380428314209, 0.015661287307739257, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.01588220755259196, 0.015867444674173992, 0.015852672259012858, 0.01583822727203369, 0.015824186007181804, 0.015810298919677734, 0.01579627513885498, 0.015782416661580402, 0.015768966674804687, 0.015755817095438638, 0.015742656389872232, 0.015729289054870605, 0.01571614424387614, 0.015703957875569663, 0.015692588488260904, 0.015681360562642414, 0.01567024866739909, 0.015659319559733074, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016226372718811034, 0.01618696689605713, 0.01614574114481608, 0.016102298100789388, 0.01605765183766683, 0.016013410886128742, 0.015971568425496418, 0.0159312105178833, 0.015893243153889975, 0.015857553482055663, 0.015823957125345865, 0.01579336166381836, 0.015764067967732748, 0.015737814903259276, 0.015715428988138835, 0.015695244471232096, 0.015677305857340496, 0.01566175142923991, 0.015648625691731772], "lorahub/flan_t5_large-duorc_SelfRC_title_generation+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014977002143859863, 0.014969733556111654, 0.014983924229939778, 0.01501423199971517, 0.015056432088216146, 0.015107510884602864, 0.015163278579711914, 0.015220592816670736, 0.015277469952901204, 0.015332471529642741, 0.015384612083435058, 0.015432387987772623, 0.015476036071777343, 0.015515750249226887, 0.015551184018452962, 0.015581730206807455, 0.015607978502909342, 0.015630202293395998, 0.015648625691731772], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-race_middle_Select_the_best_answer": [0.01618571440378825, 0.016173758506774903, 0.016165412267049154, 0.016160724957784017, 0.016159202257792157, 0.016160039901733397, 0.0161634095509847, 0.01616959571838379, 0.016178582509358722, 0.01619031588236491, 0.01620453675587972, 0.016220814387003582, 0.016239385604858398, 0.016260099411010743, 0.016283775965372723, 0.01630969524383545, 0.016337119738260904, 0.01636688709259033, 0.016397956212361654, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.015591878890991211, 0.015610427856445312, 0.015632232030232746, 0.015657386779785155, 0.015686225891113282, 0.015718722343444826, 0.015754028956095376, 0.015792368253072103, 0.01583458423614502, 0.015880212783813477, 0.015928765932718914, 0.015980641047159832, 0.016036291122436524, 0.016094719568888347, 0.016155471801757814, 0.01622020403544108, 0.016287403106689455, 0.01635800838470459, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015572856267293295, 0.015598495801289877, 0.015626603762308757, 0.015657351811726887, 0.015690658887227375, 0.01572611172993978, 0.01576396624247233, 0.015804912249247235, 0.0158483091990153, 0.015893845558166503, 0.01594178517659505, 0.015992790857950846, 0.016046374638875326, 0.01610222816467285, 0.016161362330118816, 0.016223901112874348, 0.01628944238026937, 0.01635865052541097, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.01609438419342041, 0.01610201835632324, 0.01611087958017985, 0.01612110455830892, 0.01613272984822591, 0.016145509084065757, 0.016159257888793944, 0.016174192428588866, 0.016190579732259115, 0.016208621660868328, 0.016228199005126953, 0.01624916712443034, 0.01627142906188965, 0.016295104026794432, 0.016320489247639975, 0.016346319516499837, 0.016373551686604818, 0.01640163580576579, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015717137654622397, 0.01572501500447591, 0.01573715845743815, 0.015753234227498372, 0.015773151715596515, 0.01579710006713867, 0.015825304985046387, 0.015857652028401694, 0.015893313090006512, 0.015932051340738933, 0.015974416732788085, 0.01602148373921712, 0.01607162316640218, 0.016123666763305664, 0.01617961565653483, 0.016237945556640626, 0.016299633979797362, 0.016364148457845052, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015846325556437175, 0.01585112730662028, 0.015858699480692545, 0.015868927637736004, 0.015881563822428387, 0.015896714528401693, 0.015915191968282064, 0.01593729813893636, 0.015962347984313965, 0.015990643501281737, 0.016022788683573406, 0.01605913321177165, 0.016099432309468586, 0.016143298149108885, 0.016191999117533367, 0.016245059967041016, 0.016302452087402344, 0.016364529927571616, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015343788464864096, 0.015366333325703939, 0.015393085479736328, 0.015423823992411295, 0.015458621978759766, 0.015498075485229492, 0.015542461077372232, 0.015591135025024414, 0.01564413865407308, 0.01570185343424479, 0.015764449437459308, 0.015831494331359865, 0.015903258323669435, 0.015979326566060385, 0.016060837109883628, 0.016146551767985025, 0.01623711109161377, 0.016331799825032554, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015887258847554524, 0.015903868675231934, 0.01592217763264974, 0.015941967964172365, 0.01596316973368327, 0.01598618507385254, 0.01601149559020996, 0.016038525899251303, 0.016066795984903973, 0.016096615791320802, 0.016128276189168293, 0.016161588033040363, 0.01619649410247803, 0.01623235861460368, 0.016270163853963217, 0.01630891482035319, 0.016348700523376464, 0.016389379501342772, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015912235577901203, 0.015929206212361654, 0.015947616895039877, 0.015967295964558918, 0.015988162358601888, 0.016010502179463704, 0.016034647623697915, 0.016060207684834796, 0.01608694871266683, 0.016115109125773113, 0.016144793828328452, 0.016175785064697266, 0.0162083101272583, 0.016241979598999024, 0.016277337074279787, 0.016313989957173664, 0.016351858774820965, 0.01639086882273356, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.01627190430959066, 0.016275253295898438, 0.016276969909667968, 0.01627735455830892, 0.01627701282501221, 0.016276008288065594, 0.016274674733479818, 0.01627453009287516, 0.016274542808532716, 0.016277653376261393, 0.016283955574035645, 0.016292421023050944, 0.016303106943766275, 0.016316803296407063, 0.016333589553833006, 0.016353613535563152, 0.016376970609029134, 0.016402867635091144, 0.016428845723470052], "lorahub/flan_t5_large-squad_v1.1+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015015438397725423, 0.0150410795211792, 0.01508392333984375, 0.015140631993611653, 0.015207718213399252, 0.015285557111104329, 0.015370601018269857, 0.015458753903706868, 0.015550381342569987, 0.015644003550211588, 0.01573723316192627, 0.01583070755004883, 0.015922338167826334, 0.016012059847513836, 0.016100611686706543, 0.016186474164326985, 0.0162704070409139, 0.01635190804799398, 0.016428845723470052], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-quarel_choose_between": [0.015576656659444172, 0.015596707661946615, 0.015617609024047852, 0.015639392534891765, 0.01566210428873698, 0.015685799916585287, 0.015710550944010415, 0.015736446380615235, 0.01576358636220296, 0.015792031288146973, 0.01582183361053467, 0.015853068033854167, 0.01588593006134033, 0.015920796394348145, 0.015957887967427573, 0.015997254053751627, 0.016039525667826335, 0.0160851780573527, 0.016133451461791994, 0.01618571440378825], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015575335820515951, 0.015601741472880045, 0.015628786087036134, 0.01565650463104248, 0.015684967041015626, 0.01571422259012858, 0.015744306246439615, 0.015775206883748373, 0.015806872049967446, 0.015839228630065916, 0.015872278213500977, 0.0159062655766805, 0.01594147046407064, 0.015977962811787923, 0.016015745798746744, 0.016055466334025065, 0.016097159385681153, 0.016140257517496745, 0.01618571440378825], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.016082315444946288, 0.016077629725138345, 0.01607383410135905, 0.016070946057637533, 0.01606899579366048, 0.01606802781422933, 0.016068073908487957, 0.01606920560201009, 0.016071483294169107, 0.016075008710225422, 0.0160798708597819, 0.016086173057556153, 0.016094075838724773, 0.016103806495666503, 0.016115555763244627, 0.016129355430603027, 0.016145369211832683, 0.016164170900980632, 0.01618571440378825], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015728729565938314, 0.015744531949361165, 0.015761211713155112, 0.015778748194376628, 0.015797133445739745, 0.01581641674041748, 0.015836655298868817, 0.01585792859395345, 0.015880276362101237, 0.015903725624084472, 0.015928271611531576, 0.015953942934672036, 0.01598086675008138, 0.016009416580200195, 0.016039953231811524, 0.016072754859924317, 0.016107627550760905, 0.016144976615905762, 0.01618571440378825], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015847934087117512, 0.01585273265838623, 0.01585865656534831, 0.015865761439005532, 0.015874096552530925, 0.01588371435801188, 0.015894673665364584, 0.015907025337219237, 0.01592082977294922, 0.01593618075052897, 0.015953248341878255, 0.015972359975179037, 0.015993804931640626, 0.01601772944132487, 0.01604433059692383, 0.016074334780375163, 0.016107770601908367, 0.01614452838897705, 0.01618571440378825], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015364654858907064, 0.015404105186462402, 0.015444037119547525, 0.015484471321105957, 0.015525418917338054, 0.015566879908243816, 0.015608879725138346, 0.01565144697825114, 0.015694621404012045, 0.015738499959309895, 0.01578319549560547, 0.01582883675893148, 0.015875558853149414, 0.0159234889348348, 0.015972719192504883, 0.016023273468017577, 0.016075331370035806, 0.016129477818806966, 0.01618571440378825], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015880091985066732, 0.01588828722635905, 0.015897113482157388, 0.015906608899434408, 0.015916810035705567, 0.015927756627400716, 0.015939507484436035, 0.01595213254292806, 0.015965723991394044, 0.015980380376180013, 0.015996206601460776, 0.0160133425394694, 0.01603195826212565, 0.016052289009094237, 0.016074474652608237, 0.016098647117614745, 0.016124939918518065, 0.016153950691223145, 0.01618571440378825], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015895724296569824, 0.01589605967203776, 0.015897817611694336, 0.01590106964111328, 0.015905895233154298, 0.01591234525044759, 0.01592046896616618, 0.01593031088511149, 0.015941940943400065, 0.01595544656117757, 0.015970935821533205, 0.015988529523213703, 0.016008400917053224, 0.016030782063802082, 0.016055854161580403, 0.01608358383178711, 0.01611422379811605, 0.016148279507954916, 0.01618571440378825], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016246272722880047, 0.01622671922047933, 0.016206865310668946, 0.016186405817667643, 0.01616548697153727, 0.016145064036051433, 0.016126354535420735, 0.01611010233561198, 0.016097021102905274, 0.016087581316630045, 0.016081980069478353, 0.016080029805501304, 0.016081937154134116, 0.01608801047007243, 0.016098408699035643, 0.016113239924112954, 0.016132631301879884, 0.016156776746114095, 0.01618571440378825], "lorahub/flan_t5_large-race_middle_Select_the_best_answer+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015022157033284505, 0.01505679448445638, 0.015109602610270183, 0.015176615715026855, 0.015252455075581869, 0.015335837999979654, 0.015421822865804036, 0.015508578618367514, 0.015593899091084799, 0.015675950050354003, 0.01575339476267497, 0.01582520643870036, 0.015890754063924154, 0.015952022870381673, 0.01600823402404785, 0.016057801246643067, 0.016103835105895997, 0.016146594683329265, 0.01618571440378825], "lorahub/flan_t5_large-quarel_choose_between+lorahub/flan_t5_large-quoref_Found_Context_Online": [0.015549538930257161, 0.015556826591491699, 0.015563689867655436, 0.015570073127746583, 0.015575944582621256, 0.015581256548563639, 0.015585970878601075, 0.015590049425760906, 0.015593442916870117, 0.015596110026041667, 0.015598012606302896, 0.01559911568959554, 0.015599392255147298, 0.015598812103271485, 0.015597357749938964, 0.015595016479492187, 0.015591773986816406, 0.015587630271911622, 0.015582585334777832, 0.015576656659444172], "lorahub/flan_t5_large-quarel_choose_between+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.016060940424601235, 0.016034143765767415, 0.016007415453592935, 0.015980693499247235, 0.015953952471415202, 0.015927165349324545, 0.015900335311889648, 0.015873495737711588, 0.015846654574076333, 0.015819819768269856, 0.015793004035949708, 0.015766180356343588, 0.01573932965596517, 0.01571241855621338, 0.015685418446858723, 0.015658326148986816, 0.015631152788798015, 0.01560391108194987, 0.015576656659444172], "lorahub/flan_t5_large-quarel_choose_between+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015703336397806803, 0.015693496068318685, 0.01568424065907796, 0.015675495465596517, 0.015667179425557454, 0.015659257570902505, 0.01565168857574463, 0.015644445419311523, 0.015637491544087726, 0.015630791982014974, 0.015624287923177084, 0.015617947578430175, 0.015611743927001953, 0.015605645179748535, 0.015599644978841146, 0.015593748092651367, 0.015587952931722006, 0.015582257906595866, 0.015576656659444172], "lorahub/flan_t5_large-quarel_choose_between+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015835803349812827, 0.01582687854766846, 0.01581740379333496, 0.015807358423868816, 0.015796701113382976, 0.015785401662190755, 0.01577342669169108, 0.0157607634862264, 0.015747377077738444, 0.015733267466227215, 0.01571842670440674, 0.01570286750793457, 0.015686602592468263, 0.01566966692606608, 0.015652092297871907, 0.01563394069671631, 0.015615264574686686, 0.015596143404642741, 0.015576656659444172], "lorahub/flan_t5_large-quarel_choose_between+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015347426732381184, 0.015368382136027018, 0.015388506253560384, 0.015407727559407553, 0.015425998369852702, 0.015443290074666341, 0.01545958677927653, 0.015474885304768881, 0.015489182472229003, 0.015502483050028482, 0.0155147918065389, 0.015526105562845866, 0.015536417961120605, 0.015545727411905925, 0.015554018020629883, 0.0155612579981486, 0.015567436218261718, 0.015572566986083985, 0.015576656659444172], "lorahub/flan_t5_large-quarel_choose_between+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015855166117350262, 0.015838141441345214, 0.015821436246236165, 0.01580499013264974, 0.015788755416870116, 0.015772695541381835, 0.015756785074869793, 0.015741024017333984, 0.01572540283203125, 0.015709935824076336, 0.015694608688354494, 0.0156794277826945, 0.015664401054382323, 0.01564951737721761, 0.015634775161743164, 0.015620134671529133, 0.015605565706888834, 0.015591063499450684, 0.015576656659444172], "lorahub/flan_t5_large-quarel_choose_between+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015874279340108235, 0.015852157274881998, 0.015830594698588052, 0.015809844334920248, 0.015789901415507, 0.01577073891957601, 0.015752328236897786, 0.01573459307352702, 0.01571747620900472, 0.01570089817047119, 0.015684836705525715, 0.015669294993082682, 0.015654314359029135, 0.015639934539794922, 0.015626158714294434, 0.015612964630126952, 0.015600318908691407, 0.015588202476501466, 0.015576656659444172], "lorahub/flan_t5_large-quarel_choose_between+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.01622854550679525, 0.0161898676554362, 0.01614837328592936, 0.016104232470194497, 0.016058135032653808, 0.01601147969563802, 0.015965997378031414, 0.015921931266784668, 0.015878566106160483, 0.015838781992594402, 0.01580047925313314, 0.015764506657918294, 0.015730849901835122, 0.015699227650960285, 0.01566998481750488, 0.015643078486124673, 0.0156185245513916, 0.015596386591593424, 0.015576656659444172], "lorahub/flan_t5_large-quarel_choose_between+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014984002113342285, 0.014984688758850097, 0.015006890296936035, 0.015045607884724935, 0.015095589955647786, 0.015152519543965657, 0.01521256446838379, 0.015271584192911783, 0.015329020818074544, 0.015381310780843099, 0.015428827603658041, 0.0154698912302653, 0.01550431251525879, 0.015531965891520182, 0.015553007125854492, 0.01556818167368571, 0.015577038129170736, 0.01557976245880127, 0.015576656659444172], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-dream_baseline": [0.01608787218729655, 0.016064023971557616, 0.016039565404256186, 0.016014480590820314, 0.01598876476287842, 0.015962432225545248, 0.015935502052307128, 0.015908010800679526, 0.01587999184926351, 0.015851502418518067, 0.01582257588704427, 0.015793261528015138, 0.015763562520345054, 0.015733504295349122, 0.01570311705271403, 0.01567251205444336, 0.01564180850982666, 0.015611090660095216, 0.01558034896850586, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015708298683166505, 0.015702501932779948, 0.015696428616841635, 0.015690024693806967, 0.01568323771158854, 0.01567606290181478, 0.015668520927429198, 0.015660616556803387, 0.015652333895365397, 0.01564363479614258, 0.015634469985961914, 0.01562486171722412, 0.015614879926045737, 0.015604605674743652, 0.015594093004862468, 0.015583362579345703, 0.015572381019592286, 0.015561110178629557, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.015829989115397135, 0.015815292994181315, 0.01580018361409505, 0.015784716606140135, 0.015768941243489584, 0.0157529083887736, 0.015736680030822753, 0.015720307032267254, 0.01570384343465169, 0.01568734327952067, 0.015670854250590005, 0.015654446283976237, 0.01563820521036784, 0.015622232755025228, 0.015606637001037598, 0.015591508547465006, 0.015576923688252767, 0.015562915802001953, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015341081619262696, 0.015356065432230632, 0.015370650291442871, 0.015384812355041504, 0.015398524602254231, 0.015411779085795085, 0.01542457103729248, 0.015436898867289226, 0.015448784828186036, 0.01546025276184082, 0.015471337636311849, 0.015482064882914225, 0.015492421785990397, 0.015502378145853679, 0.015512007077534994, 0.015521464347839355, 0.015530885060628255, 0.015540266036987304, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015861029624938964, 0.01584891478220622, 0.01583618958791097, 0.01582284132639567, 0.015808842976888022, 0.01579416275024414, 0.01577880064646403, 0.0157627534866333, 0.015746043523152668, 0.015728694597880045, 0.01571075439453125, 0.01569226264953613, 0.015673227310180664, 0.015653602282206216, 0.015633382797241212, 0.015612724622090658, 0.015591850280761719, 0.015570810635884603, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.01588226318359375, 0.01586703618367513, 0.015851217905680337, 0.01583509922027588, 0.015818732579549154, 0.015802078247070313, 0.015785123507181805, 0.015767809549967447, 0.015750069618225098, 0.01573185125986735, 0.01571311950683594, 0.015693899790445963, 0.015674233436584473, 0.015654095013936362, 0.01563354015350342, 0.015612719853719075, 0.01559179147084554, 0.015570756594340006, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016233617464701335, 0.016199700037638345, 0.016162678400675454, 0.016122760772705077, 0.016079856554667156, 0.0160354216893514, 0.015991352399190268, 0.01594821294148763, 0.015904696782430013, 0.01586324373881022, 0.015822661717732747, 0.015783708890279136, 0.01574598789215088, 0.015709403355916342, 0.015674095153808593, 0.01564033031463623, 0.015608437856038411, 0.01557822863260905, 0.015549538930257161], "lorahub/flan_t5_large-quoref_Found_Context_Online+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014971276919047039, 0.014956057866414388, 0.014960424105326334, 0.014980570475260416, 0.015010940233866373, 0.015049568812052409, 0.01509333610534668, 0.015138816833496094, 0.015186095237731933, 0.015232052803039551, 0.015276377995808919, 0.01531924565633138, 0.015359265009562174, 0.015396671295166016, 0.015431501070658367, 0.015463960965474447, 0.015494451522827149, 0.015523014068603515, 0.015549538930257161], "lorahub/flan_t5_large-dream_baseline+lorahub/flan_t5_large-gem_e2e_nlg": [0.015713674227396647, 0.015725463231404623, 0.015738234519958497, 0.015752073923746744, 0.015766971906026203, 0.01578291098276774, 0.015799878438313802, 0.015817777315775553, 0.01583656628926595, 0.015856207211812336, 0.015876646041870116, 0.015897817611694336, 0.015919647216796874, 0.015942068099975587, 0.01596503734588623, 0.015988529523213703, 0.016012541453043618, 0.01603709856669108, 0.01606220245361328, 0.01608787218729655], "lorahub/flan_t5_large-dream_baseline+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.0158488400777181, 0.01585435708363851, 0.015860773722330728, 0.0158681058883667, 0.015876350402832032, 0.015885515213012694, 0.015895597139994302, 0.01590659777323405, 0.015918510754903158, 0.015931337674458822, 0.01594507058461507, 0.01595970312754313, 0.01597523848215739, 0.015991671880086263, 0.016009017626444497, 0.01602728525797526, 0.016046504974365234, 0.016066692670186362, 0.01608787218729655], "lorahub/flan_t5_large-dream_baseline+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015362680753072103, 0.015400094985961914, 0.015437889099121093, 0.015476059913635255, 0.015514597892761231, 0.01555350144704183, 0.015592759450276692, 0.015632360776265463, 0.015672295888264975, 0.015712555249532065, 0.01575312614440918, 0.015793992678324383, 0.015835151672363282, 0.015876588821411134, 0.015918304125467936, 0.015960289637247722, 0.0160025421778361, 0.01604507287343343, 0.01608787218729655], "lorahub/flan_t5_large-dream_baseline+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015880773862202963, 0.015889455477396647, 0.01589850425720215, 0.01590792655944824, 0.0159177033106486, 0.015927842458089193, 0.01593832015991211, 0.01594912846883138, 0.015960257848103843, 0.015971701939900718, 0.015983444849650065, 0.015995492935180666, 0.016007827123006184, 0.016020450592041015, 0.01603335698445638, 0.01604655106862386, 0.016060031255086264, 0.016073808670043946, 0.01608787218729655], "lorahub/flan_t5_large-dream_baseline+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015904444058736165, 0.015912389755249022, 0.01592061678568522, 0.01592911720275879, 0.015937894185384115, 0.01594696044921875, 0.015956308046976727, 0.015965946515401206, 0.015975871086120606, 0.0159860626856486, 0.01599650541941325, 0.016007194519042967, 0.01601810932159424, 0.016029241879781088, 0.01604057788848877, 0.016052122116088866, 0.016063852310180662, 0.01607577164967855, 0.01608787218729655], "lorahub/flan_t5_large-dream_baseline+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016260706583658854, 0.016254952748616536, 0.01624759038289388, 0.01623886267344157, 0.01622767448425293, 0.016215039889017742, 0.016201343536376953, 0.016188670794169108, 0.016176301638285318, 0.016164050102233887, 0.016152156194051106, 0.016142085393269858, 0.01613319238026937, 0.016124622027079264, 0.016116366386413575, 0.016108344395955404, 0.016101016998291015, 0.016094271341959634, 0.01608787218729655], "lorahub/flan_t5_large-dream_baseline+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015006152788798015, 0.015031075477600098, 0.015079132715861003, 0.015144913991292318, 0.015222220420837403, 0.015307323137919108, 0.015394914944966634, 0.015483363469441732, 0.015568184852600097, 0.01564916769663493, 0.015723913510640463, 0.015791932741800945, 0.015854371388753254, 0.015910577774047852, 0.01595917224884033, 0.016000838279724122, 0.016035973230997723, 0.01606487274169922, 0.01608787218729655], "lorahub/flan_t5_large-gem_e2e_nlg+lorahub/flan_t5_large-wiki_qa_Jeopardy_style": [0.015844224294026692, 0.01583387533823649, 0.01582362492879232, 0.015813482602437336, 0.015803491274515788, 0.015793681144714355, 0.015784098307291668, 0.01577480634053548, 0.015765854517618815, 0.015757304827372233, 0.015749249458312988, 0.015741753578186034, 0.015734918912251792, 0.015728853543599448, 0.01572365125020345, 0.015719402631123862, 0.015716198285420736, 0.01571414311726888, 0.015713324546813966, 0.015713674227396647], "lorahub/flan_t5_large-gem_e2e_nlg+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015349748929341635, 0.015373422304789225, 0.015396671295166016, 0.015419472058614095, 0.015441795984903972, 0.015463631947835286, 0.015484978357950846, 0.015505849520365397, 0.015526278813680013, 0.015546309153238931, 0.015565986633300782, 0.015585338274637858, 0.015604408582051595, 0.015623226165771484, 0.015641810099283854, 0.015660147666931152, 0.015678259531656902, 0.015696123441060385, 0.015713674227396647], "lorahub/flan_t5_large-gem_e2e_nlg+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015858813921610513, 0.015845697720845542, 0.01583315054575602, 0.015821170806884766, 0.01580972989400228, 0.015798810323079428, 0.015788400967915853, 0.015778522491455078, 0.015769195556640626, 0.01576045036315918, 0.015752323468526206, 0.01574485460917155, 0.015738088289896646, 0.015732067426045736, 0.01572682857513428, 0.015722370147705077, 0.015718703269958497, 0.015715827941894533, 0.015713674227396647], "lorahub/flan_t5_large-gem_e2e_nlg+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.01588015874226888, 0.015864038467407228, 0.015848530133565266, 0.015833799044291177, 0.015819950103759764, 0.015806984901428223, 0.015794854164123535, 0.015783494313557942, 0.01577284018198649, 0.0157628599802653, 0.01575360298156738, 0.015745164553324382, 0.01573764642079671, 0.015731123288472492, 0.015725631713867188, 0.015721165339152018, 0.015717700322469077, 0.01571523189544678, 0.015713674227396647], "lorahub/flan_t5_large-gem_e2e_nlg+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016233914693196613, 0.016201055844624838, 0.016165982882181802, 0.01612910588582357, 0.016090140342712403, 0.016050259272257488, 0.016011702219645183, 0.015975642204284667, 0.015940605799357098, 0.015908161799112957, 0.01587783654530843, 0.01584915002187093, 0.015822475751241048, 0.015798409779866535, 0.01577672799428304, 0.01575735569000244, 0.01574040412902832, 0.015725868542989095, 0.015713674227396647], "lorahub/flan_t5_large-gem_e2e_nlg+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014978640874226888, 0.014974129994710287, 0.014991884231567382, 0.015026650428771972, 0.015075132052103679, 0.015131750106811524, 0.015193578402201334, 0.015256789525349935, 0.015319925944010417, 0.01538025697072347, 0.015437310536702473, 0.015489050547281901, 0.015536020596822103, 0.01557801087697347, 0.015615534782409669, 0.01564758618672689, 0.015674169858296713, 0.015695981979370117, 0.015713674227396647], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-quail_context_question_description_answer_id": [0.015325651168823243, 0.015360417366027833, 0.015394539833068847, 0.015428021748860677, 0.015460813840230306, 0.015492865244547526, 0.015524131457010905, 0.015554569562276204, 0.01558414618174235, 0.015612826347351075, 0.015640578269958495, 0.01566737174987793, 0.015693179766337075, 0.015717976888020832, 0.015741742451985678, 0.015764451026916503, 0.01578606923421224, 0.01580658753712972, 0.015825978914896646, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.015867142677307128, 0.0158624267578125, 0.015858310063680013, 0.015854770342508952, 0.015851736068725586, 0.01584916114807129, 0.015846991539001466, 0.015845203399658205, 0.015843752225240072, 0.015842620531717935, 0.015841779708862306, 0.01584121863047282, 0.01584092140197754, 0.015840875307718914, 0.015841073989868164, 0.015841514269510904, 0.015842188199361167, 0.01584308942159017, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015885793368021647, 0.015875781377156575, 0.015866756439208984, 0.015858821868896485, 0.01585201899210612, 0.01584631284077962, 0.015841630299886066, 0.015837918917338052, 0.015835105578104657, 0.01583312193552653, 0.015831894874572754, 0.015831365585327148, 0.0158314847946167, 0.01583221435546875, 0.015833524068196613, 0.015835396448771157, 0.01583781560262044, 0.015840768814086914, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.016240572929382323, 0.016215297381083172, 0.016188391049702964, 0.016160101890563966, 0.016129908561706544, 0.016099414825439452, 0.016070602734883626, 0.016043087641398113, 0.016016592979431154, 0.015991614659627278, 0.01596930662790934, 0.01594799995422363, 0.015928271611531576, 0.015910719235738117, 0.015894598960876465, 0.01587987263997396, 0.015866586367289225, 0.015854722658793133, 0.015844224294026692], "lorahub/flan_t5_large-wiki_qa_Jeopardy_style+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014984464645385743, 0.014989147186279297, 0.015018248558044433, 0.015066186587015787, 0.015127034187316894, 0.015196393330891927, 0.015270066261291505, 0.015343763033548992, 0.015416760444641114, 0.015485177040100098, 0.015549430847167969, 0.015607398351033528, 0.015659019152323404, 0.015704340934753418, 0.015744682947794596, 0.015778830846150716, 0.015806525548299154, 0.015828204154968262, 0.015844224294026692], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-quartz_read_passage_below_choose": [0.015872467358907065, 0.01585127830505371, 0.015829216639200845, 0.015806296666463215, 0.01578251043955485, 0.01575787862141927, 0.015732394854227703, 0.015706055959065754, 0.01567887465159098, 0.015650850931803385, 0.015621984799702962, 0.015592292149861653, 0.015561768213907878, 0.015530414581298828, 0.015498263041178385, 0.015465300877888997, 0.01543155034383138, 0.01539701779683431, 0.015361714363098144, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.01586261749267578, 0.01582888921101888, 0.015795607566833497, 0.015762778917948406, 0.015730404853820802, 0.015698494911193846, 0.01566705067952474, 0.015636070569356283, 0.015605557759602864, 0.01557551383972168, 0.01554592768351237, 0.015516800880432129, 0.01548813501993815, 0.015459917386372883, 0.01543216069539388, 0.015404850641886392, 0.015377998352050781, 0.015351595878601075, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.01620191733042399, 0.016137755711873373, 0.016072683334350586, 0.01600764274597168, 0.015942185719807943, 0.015877048174540203, 0.01581337769826253, 0.01575234095255534, 0.0156948455174764, 0.015640449523925782, 0.015589807828267415, 0.015543556213378907, 0.015501062075297037, 0.015462368329366049, 0.015427347819010416, 0.015396203994750977, 0.015368963877360026, 0.015345455805460612, 0.015325651168823243], "lorahub/flan_t5_large-quail_context_question_description_answer_id+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014980381329854329, 0.014972818692525229, 0.014983170827229818, 0.015006890296936035, 0.015039717356363932, 0.015078245798746745, 0.01511865456899007, 0.015160077412923178, 0.015199195543924968, 0.015235191980997721, 0.015266311963399252, 0.015292681058247885, 0.015315265655517578, 0.01533083438873291, 0.015340490341186524, 0.015344521204630535, 0.015343163808186849, 0.01533677895863851, 0.015325651168823243], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-quail_context_question_description_answer_text": [0.01589679718017578, 0.015887552897135417, 0.015879157384236654, 0.015871612230936687, 0.01586494445800781, 0.015859158833821614, 0.015854276021321615, 0.015850289662679037, 0.015847204526265462, 0.015845017433166506, 0.015843729972839355, 0.015843337376912434, 0.015843839645385743, 0.015845238367716473, 0.015847533543904623, 0.015850725173950194, 0.01585480848948161, 0.01585979461669922, 0.015865681966145833, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.01625291665395101, 0.016237730979919433, 0.01621893882751465, 0.016197670300801596, 0.016172989209493, 0.0161467440923055, 0.01611942450205485, 0.016092453002929687, 0.01606629212697347, 0.016040825843811037, 0.016016400655110678, 0.015993943214416505, 0.015972628593444824, 0.015952603022257487, 0.01593396027882894, 0.01591662089029948, 0.015900530815124513, 0.01588579495747884, 0.015872467358907065], "lorahub/flan_t5_large-quartz_read_passage_below_choose+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014999876022338867, 0.01501702626546224, 0.01505606969197591, 0.01511196772257487, 0.015178523063659667, 0.015252251625061036, 0.015327706336975097, 0.015403676033020019, 0.015475982030232748, 0.015544358889261882, 0.015606436729431152, 0.015662503242492676, 0.015713280042012532, 0.015755818684895832, 0.01579169273376465, 0.01582101821899414, 0.015843963623046874, 0.01586098353068034, 0.015872467358907065], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-quac": [0.016264020601908367, 0.01625306765238444, 0.016238527297973634, 0.016222187678019206, 0.016203420956929525, 0.016183029810587564, 0.01616045951843262, 0.016137471199035646, 0.016113591194152833, 0.016090025901794435, 0.016067577997843425, 0.01604557514190674, 0.016023998260498048, 0.01600316842397054, 0.015983036359151204, 0.015964139302571616, 0.015946455001831054, 0.015929468472798667, 0.015912950833638508, 0.01589679718017578], "lorahub/flan_t5_large-quail_context_question_description_answer_text+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.014990677833557129, 0.014999841054280599, 0.015032351811726888, 0.015082419713338216, 0.015144739151000976, 0.01521497408548991, 0.015288659731547038, 0.015364141464233398, 0.01543770949045817, 0.015508192380269369, 0.015573755900065104, 0.01563477357228597, 0.015690692265828452, 0.01573914845784505, 0.015781559944152833, 0.015818228721618654, 0.015849620501200357, 0.01587606906890869, 0.01589679718017578], "lorahub/flan_t5_large-quac+lorahub/flan_t5_large-wiki_hop_original_choose_best_object_affirmative_1": [0.015012313524881998, 0.015011725425720214, 0.0150351349512736, 0.015077889760335287, 0.015136772791544597, 0.015206244786580404, 0.01528435230255127, 0.015368754069010417, 0.015458443959554036, 0.015547569592793782, 0.015637779235839845, 0.015725231170654295, 0.0158093531926473, 0.015890909830729168, 0.015966784159342447, 0.016038190523783365, 0.01610419750213623, 0.01616320292154948, 0.01621667544047038, 0.016264020601908367]}}